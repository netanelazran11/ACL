{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuoXusr9B3nd"
      },
      "source": [
        "\n",
        "# PS2: Mini-batch SGD, CNN, and RNN\n",
        "\n",
        "Advanced Learning 2025/6.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRYKvBtcZj44"
      },
      "source": [
        "For SUBMISSION:   \n",
        "\n",
        "Please upload the complete and executed `ipynb` to your git repository. Verify that all of your output can be viewed directly from github, and provide a link to that git file below.\n",
        "\n",
        "~~~\n",
        "STUDENT ID: MISSING\n",
        "~~~\n",
        "\n",
        "~~~\n",
        "STUDENT GIT LINK: MISSING\n",
        "~~~\n",
        "In Addition, don't forget to add your ID to the files, and upload to moodle the html version:    \n",
        "  \n",
        "`PS2_CNN_RNN_2024_ID_[000000000].html`   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGu-_zVht05f"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpuwQ5_fuCgv"
      },
      "source": [
        "Imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2ZxCWBO_IIT"
      },
      "outputs": [],
      "source": [
        "import numpy as np # You are allowed to use  only numpy.\n",
        "import time, sys, cProfile\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeoCIfh04mvL"
      },
      "source": [
        "Please import the objects in `src.py` file into the workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYXteE-1_Z-d",
        "outputId": "1ecbbc2a-53ad-4a9d-ae1e-4ac7167f6776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35IavGc8A7y6"
      },
      "outputs": [],
      "source": [
        "your_drive_path_to_src_file = \"/content/drive/MyDrive/[PATH TO YOUR DIRECTORY WHERE SRC IS IN]]\"\n",
        "sys.path.append(your_drive_path_to_src_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgCYpnky_5Jl"
      },
      "outputs": [],
      "source": [
        "from  src import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqOOPqnIRySe"
      },
      "source": [
        "Note that now all of the network's objects from PS1 are loaded into the workspace."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, you can upload src.py in the files tab found on the left hand side if you are using colab."
      ],
      "metadata": {
        "id": "vs-9XA0i-JNl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBPK1TvV_VJ7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P11k0GECXiR-"
      },
      "source": [
        "### 0. Loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwLDOo7IXfcI"
      },
      "source": [
        "As in PS1, you will evaluate your home-made network on the `mnist` dataset.   \n",
        "The MNIST dataset is a large dataset of handwritten digits that is commonly used for training various image and vision models.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIxpddzDXgBN"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "# load MNIST from server\n",
        "# Using a standard library (keras.datasets) to load the mnist data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "pw_bRFEqLmHg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWY-bs-Wn1tN"
      },
      "source": [
        "## PS2 Part 1: Mini-batch SGD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnAz84ZL_9XQ"
      },
      "source": [
        "\n",
        "**Welcome back**.   \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKX6mRIrp1gB"
      },
      "source": [
        "Mini-batch Stochastic Gradient Descent (Mini-batch SGD) is an optimization algorithm used to train machine learning models, particularly neural networks. It strikes a balance between two other methods:\n",
        "\n",
        "    Batch Gradient Descent – Uses the entire dataset to compute gradients and update the model parameters.\n",
        "        ✅ Accurate gradients\n",
        "        ❌ Slow and memory-intensive for large datasets\n",
        "\n",
        "    Stochastic Gradient Descent (SGD) – Uses a single data point to compute gradients for each update.\n",
        "        ✅ Fast and efficient\n",
        "        ❌ Noisy updates, which can lead to instability\n",
        "\n",
        "  \n",
        "**Mini-batch SGD**.\n",
        "\n",
        "Mini-batch SGD computes gradients and updates the model parameters using small, randomly selected batches of data (typically 32, 64, or 128 samples).\n",
        "\n",
        "    ✅ Faster than batch gradient descent\n",
        "    ✅ Less noisy than pure SGD\n",
        "    ✅ Efficient use of memory\n",
        "    ✅ Enables vectorization for faster computation on GPUs\n",
        "\n",
        "**How it Works**.\n",
        "\n",
        "    Shuffle the dataset to avoid bias.\n",
        "\n",
        "    Divide the data into small batches (e.g., 64 samples per batch).\n",
        "\n",
        "    For each epoch, iterate through the mini-batches:\n",
        "        Perform forward pass to calculate predictions.\n",
        "        Compute the loss for the mini-batch.\n",
        "        Perform backpropagation to compute gradients.\n",
        "        Update model parameters using the gradients.\n",
        "\n",
        "    Repeat until the model converges.\n",
        "\n",
        "**Algorithm**\n",
        "\n",
        "For each mini-batch $B={x_1,x_2,...,x_m}B={x_1​,x_2​,...,x_m​}$ of size $m$, update the weights $w$ as:    \n",
        "\n",
        "$$\n",
        "w=w−η⋅\\frac{1}{m}∑_{i=1}^m ∇L(w,x_i)\n",
        "$$\n",
        "\n",
        "Where:   \n",
        "*  $η$ = learning rate.\n",
        "* $∇L(w,x_i)$ = gradient of the loss for sample $x_i$.   \n",
        "\n",
        "Advantages\n",
        "\n",
        "    Efficient and scalable – Works well with large datasets.\n",
        "    Smooth convergence – Less noisy than SGD but faster than full batch training.\n",
        "    Parallelization – Batches can be processed in parallel on GPUs.\n",
        "\n",
        "Disadvantages\n",
        "\n",
        "    Choosing batch size can affect performance. Small batches lead to noise, large batches consume more memory.\n",
        "    Convergence may be slower than batch gradient descent for some problems.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q85zSwVAuXrn"
      },
      "source": [
        "### Mini-batch Questions.\n",
        "**P1Q1**:  \n",
        "\n",
        "Please answer the following questions providing statistical justifications and mathematical formulas when needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjwcwcLFseeI"
      },
      "source": [
        "P1Q1a: Explain how the mini-batch size impacts convergence, model performance, and computational efficiency.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB1IuGyrsk5_"
      },
      "source": [
        "**MISSING - YOUR ANSWER HERE!! **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASW2z9RYsm_A"
      },
      "source": [
        "**P1Q1b:**   \n",
        "Why does mini-batch SGD require a learning rate schedule, and what are the common scheduling strategies?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS3IfSSWsrms"
      },
      "source": [
        "**MISSING - YOUR ANSWER HERE!! **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOKCe5R3st13"
      },
      "source": [
        "P1Q1c: What role does batch normalization play in mini-batch SGD, and why is it essential for deep neural networks?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYtQM2Mos0Pr"
      },
      "source": [
        "**MISSING - YOUR ANSWER HERE!! **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8f1jNLas61Q"
      },
      "source": [
        "P1Q1d: How does mini-batch SGD differ in performance compared to full-batch gradient descent when dealing with non-convex optimization problems?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcxQcUu2s7gU"
      },
      "source": [
        "**MISSING - YOUR ANSWER HERE!! **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwZ2bhJ6s_-g"
      },
      "source": [
        "P1Q1e: How does mini-batch SGD perform when training on imbalanced datasets, and what strategies can mitigate its challenges?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB82NmlatAlD"
      },
      "source": [
        "**MISSING - YOUR ANSWER HERE!! **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4-gXW6gtNrw"
      },
      "source": [
        "P1Q1f: Explain why larger mini-batch sizes are preferred during inference but not necessarily during training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qn0tM8ytOZD"
      },
      "source": [
        "**MISSING - YOUR ANSWER HERE!! **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyr7zKTZxZBv"
      },
      "source": [
        "### Applying mini-batch SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the data:"
      ],
      "metadata": {
        "id": "SzirCgDhAjP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZU4lXqKypnM"
      },
      "outputs": [],
      "source": [
        "# training data : 60000 samples\n",
        "# reshape and normalize input data\n",
        "x_train = x_train.reshape(x_train.shape[0], 1, 28*28)\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "# One-hot encoding of the output.\n",
        "# Currently a number in range [0,9]; Change into a vector of size 10\n",
        "# e.g. number 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "y_train = to_categorical(y_train)\n",
        "# same for test data : 10000 samples\n",
        "x_test = x_test.reshape(x_test.shape[0], 1, 28*28)\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpeKBQyK2kEx"
      },
      "source": [
        "P1Q2a:  \n",
        "\n",
        "Add a new function to the class `MyNetwork` named `fit_mini_batch`. This function should be similar to `fit`, just with a mini-batch SGD implementation. You can also make other code changes to the scripts in `src` if you think they are needed. In addition, add a suitable learning rate scheduler of your choice.   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOU SHOULD (a) add the missing script to the src code, and (b) make a copy of the function  below for review:"
      ],
      "metadata": {
        "id": "_pIJ7GUfAtbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### MISSING: YOUR CODE HERE"
      ],
      "metadata": {
        "id": "4RpP3DWdA_Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    Test the two networks below to compare the differences between GD and mini-batch SGD:"
      ],
      "metadata": {
        "id": "ayDt5sllA-dr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB0c0Jvq6Nwr"
      },
      "outputs": [],
      "source": [
        "#### GD implementaiton ####\n",
        "\n",
        "# Network Architecture\n",
        "netGD = MyNetwork()\n",
        "\n",
        "\n",
        "netGD.add(Affine_Layer(28*28, 128))\n",
        "netGD.add(ActivationLayer(tanh, tanh_grad))\n",
        "netGD.add(Affine_Layer(128, 64))\n",
        "netGD.add(ActivationLayer(tanh, tanh_grad))\n",
        "netGD.add(Affine_Layer(64, 10))\n",
        "netGD.add(ActivationLayer(tanh, tanh_grad))\n",
        "\n",
        "netGD.use_loss(mse, mse_grad)\n",
        "\n",
        "\n",
        "epoch_num = 10\n",
        "lr = 0.05\n",
        "t1 = time.time()\n",
        "netGD.fit(x_train[:10000], y_train[:10000], epochs=epoch_num, learning_rate=lr)\n",
        "print(f\"Total process time: {round(time.time() - t1,3)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02FkMpiE5HXT"
      },
      "outputs": [],
      "source": [
        "output_GD = netGD.predict(x_test ,y_test )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNB9h5MDywos"
      },
      "outputs": [],
      "source": [
        "#### mini-batch SGD implementaiton ####\n",
        "\n",
        "# Network Architecture\n",
        "netMiniGD = MyNetwork()\n",
        "\n",
        "\n",
        "netMiniGD.add(Affine_Layer(28*28, 128))\n",
        "netMiniGD.add(ActivationLayer(tanh, tanh_grad))\n",
        "netMiniGD.add(Affine_Layer(128, 64))\n",
        "netMiniGD.add(ActivationLayer(tanh, tanh_grad))\n",
        "netMiniGD.add(Affine_Layer(64, 10))\n",
        "netMiniGD.add(ActivationLayer(tanh, tanh_grad))\n",
        "\n",
        "netMiniGD.use_loss(mse, mse_grad)\n",
        "\n",
        "\n",
        "epoch_num = 10\n",
        "lr_sched = 0.05 # add a learning rate scheduler of your choice here\n",
        "t2 = time.time()\n",
        "netMiniGD.fit_mini_batch(x_train[:10000], y_train[:10000], batch_size=128, epochs=epoch_num, learning_rate=lr_sched)\n",
        "print(f\"Total process time: {round(time.time() - t2,3)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rACLtaI85Lmr"
      },
      "outputs": [],
      "source": [
        "outputMiniGSD = netMiniGD.predict(x_test ,y_test )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xy9f2FC4q1d"
      },
      "source": [
        "P1Q2b:   \n",
        "Please answer the following:\n",
        "* Which implementation was faster?\n",
        "* with lower training error?\n",
        "* with better test accuracy?    \n",
        "\n",
        "and explain how these results fit your answers in Q1A."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGhZfoR-65tB"
      },
      "source": [
        "ANSWER.  \n",
        "    ANSWER here.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HBQw0Mgnmtc"
      },
      "source": [
        "## PS2 Part 2: CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnuOiX-CorJ3"
      },
      "source": [
        "\n",
        "A Convolutional Neural Network (CNN) is a type of a deep neural network that can perform well at image recognition and analysis tasks.\n",
        "\n",
        "\n",
        "> In this problem set we will add CNN compatibility to our numpy-based neural network from PS 1.\n",
        "\n",
        "The main components needed to implement a CNN architecture:  \n",
        "\n",
        "**Convolution layer:** In the convolutional layers, filters are applied to the image to identify patterns and features. Imagine a sliding window that moves across the image, detecting edges, shapes, and other building blocks.  \n",
        "\n",
        "**Pooling layer:** Pooling layers downsample the data, reducing its complexity and computational cost. This helps prevent overfitting, where the model memorizes training data instead of learning generalizable patterns.  \n",
        "\n",
        "**Reshape layer:**\n",
        "Reshaping the output of the convolution and pooling layers into the fully connected layer.   \n",
        "\n",
        "\n",
        "A USEFUL HINT:\n",
        "\n",
        "*Keeping account of the input and output shapes along the CNN network is crucial for the model to work as intended*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRO7r5zSoz1-"
      },
      "source": [
        "Useful resource:  \n",
        "* [CS231](https://cs231n.github.io/convolutional-networks/).\n",
        "* [Convolutional Neural Network From Scratch](https://www.kaggle.com/code/lusfernandotorres/convolutional-neural-network-from-scratch).\n",
        "* [CNN with PyTorch](https://www.kaggle.com/code/sdelecourt/cnn-with-pytorch-for-mnist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_yaFDAtXj1h"
      },
      "source": [
        "#### Data transformations\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw09Gk2WtdKs"
      },
      "source": [
        "(Here I added a reshape that I originally intended for you to apply at model time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb4gtoTtuEEP"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "# load MNIST from server\n",
        "# Using a standard library (keras.datasets) to load the mnist data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PooYSGAgY4v"
      },
      "outputs": [],
      "source": [
        "# training data : 60000 samples\n",
        "# reshape and normalize input data\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "x_train = x_train.reshape(x_train.shape[0],1,\n",
        "                          x_train.shape[1],x_train.shape[2])\n",
        "# One-hot encoding of the output.\n",
        "# Currently a number in range [0,9]; Change into a vector of size 10\n",
        "# e.g. number 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "y_train = to_categorical(y_train)\n",
        "y_train = y_train.reshape(y_train.shape[0],1,\n",
        "                          y_train.shape[1])\n",
        "\n",
        "# same for test data : 10000 samples\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "x_test = x_test.reshape(x_test.shape[0],1,\n",
        "                          x_test.shape[1],x_test.shape[2])\n",
        "y_test = to_categorical(y_test)\n",
        "y_test = y_test.reshape(y_test.shape[0],1,\n",
        "                          y_test.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxtGbGcF3HBW"
      },
      "outputs": [],
      "source": [
        "print(\"x_train shape\",x_train.shape)\n",
        "print(\"x_test shape\",x_test.shape)\n",
        "print(\"y_train shape\",y_train.shape)\n",
        "print(\"y_test shape\",y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUf8Zwkt24xR"
      },
      "source": [
        "Unlike the multilayer perceptron (MLP) architecture, the input to the convolution net is not flattened. In our case, the size of a single `MNIST` datapoint is (1,28,28). The first dimension is the number of channels (e.g. RGB  for color images). During training the inputs and outputs often  change shape as they pass through the convolution, pooling, and the other layers of the network."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "0_ugZHGTL3wa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8HGS8h1uXAD"
      },
      "source": [
        "### A. Convolution Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtcgzvxyecNR"
      },
      "source": [
        "Here you are asked to implement a basic Convolution layer with the following components:\n",
        "\n",
        "\n",
        "\n",
        "1.   Layer initialization - initialize the layer's filters using Normalized Xavier/Hu weights\n",
        "2.   A generator function that yields all the available sliding windows in the input image.\n",
        "3.   Forward propogation for the convolution layer\n",
        "4.   Backward propogation for the convolution layer\n",
        "\n",
        "[CS231](https://cs231n.github.io/convolutional-networks/#conv) provides a great overview both mathematically and visually,   \n",
        "and [CS230](https://cs230.stanford.edu/section/4/) provides a good overview about Xavier initialization.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p8EJHRxA3nX"
      },
      "source": [
        "P2Q1a:  (10pts).   \n",
        "Please complete the missing code (`## SOLUTION REQUIRED!!`) so that the class works properly.    \n",
        "You can deviate slightly from the recommended structure below, but please remain true to the class structure and compatibility with the rest of the network classes and functions. The idea here is to write YOUR OWN version of CNN, so please try not to google the answers.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd8GIalsqKWI"
      },
      "outputs": [],
      "source": [
        "### MISSING: SOLUTION REQUIRED IN THIS CODE BLOCK\n",
        "\n",
        "class Convolution:\n",
        "    # convolution layer using num_filters x num_filters filters.\n",
        "    # size is the length/width of the filter window with shape (size x size)\n",
        "    # In this simple implementation, there is no padding.\n",
        "\n",
        "    def __init__(self, num_filters=3, size=3, activation=None):\n",
        "        self.stride = 1 # for simplicity, we keep the stride=1.\n",
        "        self.size = size\n",
        "        self.activation = activation\n",
        "        self.last_input = None\n",
        "\n",
        "\n",
        "        # Initialize the Convolution layer filters\n",
        "        ## SOLUTION REQUIRED!!\n",
        "        # self.filters =\n",
        "\n",
        "\n",
        "    def patch_generator(self, image):\n",
        "        # This generator (using yield) returns all the  possible patches of  the input image\n",
        "        # of shape  (h,w)  for each channel c, together with the relevant y,x coordinates of the patch.\n",
        "        # input_data/image must be shaped as (c,y,x), where c is the channel/filter\n",
        "        ch,h,w = image.shape\n",
        "\n",
        "        for y in range(0,h-self.size+1):\n",
        "            for x in range(0,w-self.size+1,self.stride):\n",
        "                ## SOLUTION REQUIRED!!\n",
        "                patch = ## SOLUTION REQUIRED!!\n",
        "                yield patch, y, x\n",
        "\n",
        "\n",
        "    def forward_propagation(self, image):\n",
        "        # Calculate the convolution forward pass using the filters together with a\n",
        "        # user specified activation function.\n",
        "\n",
        "        # If this is the first convolution layer, the input image is size (h,w) and must be expanded to (c,h,w).\n",
        "        if len(image.shape)==2:\n",
        "            image = np.expand_dims(image, axis=0)\n",
        "        # keep track of last input for later backward propagation\n",
        "        self.last_input = image\n",
        "        # Initializing the output array:\n",
        "        ## SOLUTION REQUIRED!!\n",
        "        # input_dimension = # the dimension of the input (current) image\n",
        "        # output_dimension =  # the dimension of the output of the layer\n",
        "\n",
        "        # compute output dimensions after the convolution layer\n",
        "        output = np.zeros((self.filters.shape[0], output_dimension, output_dimension))\n",
        "\n",
        "        # forward pass on each filter\n",
        "        for f in range(self.filters.shape[0]):\n",
        "            for patch, y, x in self.patch_generator(image):\n",
        "                ## SOLUTION REQUIRED!!\n",
        "                # output[f,y, x] =  # the output of the forward pass\n",
        "\n",
        "        # Applying activation function (this is a small cheat/simplification\n",
        "        #  because the activation should be a separate layer in itself.  )\n",
        "        if self.activation is not None:\n",
        "            output = self.activation.forward_propagation(output)\n",
        "        return output\n",
        "\n",
        "    def backward_propagation(self, grad_out, learning_rate):\n",
        "        # Calculate the SGD in-gradients of the filters and the layer.\n",
        "        # Update only the filters gradients.\n",
        "\n",
        "        # back propagate through activation (again, a bit of a cheat)\n",
        "        if self.activation is not None:\n",
        "            grad_out = self.activation.backward_propagation(grad_out,learning_rate)\n",
        "\n",
        "        ## SOLUTION REQUIRED!!\n",
        "        # grad_in = np.zeros(MISSING)  loss gradient of the input\n",
        "        # grad_filter = np.zeros(MISSING) # loss gradient of filter\n",
        "\n",
        "\n",
        "        for f in range(self.filters.shape[0]):\n",
        "            for patch, y, x in self.patch_generator(self.last_input):\n",
        "                ## SOLUTION REQUIRED!!\n",
        "                # grad_filter[f] +=.  # calculate the gradient of the filter\n",
        "                # grad_in[:, y:y + self.size, x:x + self.size] += # calculate the gradient of input\n",
        "\n",
        "\n",
        "        ## SOLUTION REQUIRED!!\n",
        "        # self.filters -=  # update filters using SGD\n",
        "\n",
        "        return grad_in    # return the loss gradient for this layer's inputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjVLDeFhBM68"
      },
      "source": [
        "### B. Max-pooling Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnAa9myxBndS"
      },
      "source": [
        "As with the convolution layer, here you are asked to implement a basic max-pooling layer with the following components:\n",
        "\n",
        "\n",
        "1.   A generator function that yields all the available sliding windows in the input image. You can reuse the generator from (1).\n",
        "2.   Forward propogation for the max-pooling layer\n",
        "3.   Backward propogation for the max-pooling layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKQ20gUHCTBp"
      },
      "source": [
        "The pooling layer is responsible for reducing the dimensionality of the input. As with the convolution layer, the pooling layer slides a filter across the entire image input to calculate the output. Note that this layer does not have any weights.  As the filter slides through the input image, it selects the pixel with the maximum value to populate the output array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRv351L9C181"
      },
      "source": [
        "P2Q1b: (10pts).       \n",
        "\n",
        "Please complete the missing code (`## SOLUTION REQUIRED!!`) so that the class works properly.  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBF5Oo7dqs-x"
      },
      "outputs": [],
      "source": [
        "### MISSING CODE IN THIS BLOCK\n",
        "\n",
        "class MaxPool:\n",
        "    def __init__(self,  size=2):\n",
        "        # max pooling layer\n",
        "\n",
        "        self.last_input = None\n",
        "        self.stride = 1\n",
        "        self.size = size\n",
        "\n",
        "    def patch_generator(self, image):\n",
        "        # returns a generator (using yield) of all  possible patches of size size x size\n",
        "        # input_data/image must be shaped as (c,y,x)\n",
        "        ch,h,w = image.shape\n",
        "\n",
        "        for c in range(ch):\n",
        "          for y in range(0,h-self.size+1):\n",
        "              for x in range(0,w-self.size+1,self.stride):\n",
        "                  patch = ## SOLUTION REQUIRED!!\n",
        "                  yield patch, c, y, x\n",
        "\n",
        "    def forward_propagation(self, image):\n",
        "        # keep track of last input for later backward propagation\n",
        "        self.last_input = image\n",
        "\n",
        "        # compute output dimensions after the max pooling\n",
        "        num_channels, h_prev, w_prev = image.shape\n",
        "        ## SOLUTION REQUIRED!!\n",
        "        # h_new =\n",
        "        # w_new =\n",
        "        # hold the values of the max pooling\n",
        "        output = np.zeros((num_channels, h_new, w_new))\n",
        "\n",
        "        # Calculate the max pool on all the image patches using the generator:\n",
        "        # CODE MISSING\n",
        "        for patch, c, y, x in self.patch_generator(image):\n",
        "            output[c ,y, x] =## SOLUTION REQUIRED!!\n",
        "        return output\n",
        "\n",
        "    def backward_propagation(self, grad_out, learning_rate):\n",
        "        # Calculate the gradients of the last input image\n",
        "        num_channels, orig_dim, *_ = self.last_input.shape\n",
        "        grad_in = np.zeros(self.last_input.shape)\n",
        "\n",
        "        # Using the generator, go over all the channels and calcualte the max-pooling input gradients\n",
        "        # for c in range(num_channels):\n",
        "        for patch, c, y, x in self.patch_generator(self.last_input):\n",
        "            (x, y) = np.unravel_index(np.nanargmax(patch), patch.shape)\n",
        "            ## SOLUTION REQUIRED!!\n",
        "            # grad_in[MISSING] +=\n",
        "\n",
        "\n",
        "        return grad_in\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtRd7DJfBW8J"
      },
      "source": [
        "### C. Reshape Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "652a1CJ6Il7e"
      },
      "source": [
        "A reshape layer in a neural network is a transformation layer that doesn't perform any computations itself (no weights).   \n",
        "Its purpose is to simply change the dimensionality (shape) of the data flowing through the network.\n",
        "\n",
        "Here's how reshape layers work:\n",
        "\n",
        "You define a target shape for the output of the reshape layer.   \n",
        "This target shape specifies the number of elements along each dimension (width, height, channels, etc.) for the new data format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPQ8w7rFff4F"
      },
      "source": [
        "P2Q1c:  (5pts).   \n",
        "Please complete the missing code (`## SOLUTION REQUIRED!!`) so that the class works properly.  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpSivJDwX_ZW"
      },
      "outputs": [],
      "source": [
        "### MISSING CODE IN THIS BLOCK ####\n",
        "class Reshape:\n",
        "    def __init__(self,input_shape,output_shape):\n",
        "        self.input_shape=input_shape\n",
        "        self.output_shape=output_shape\n",
        "    def forward_propagation(self,input_data):\n",
        "        ## SOLUTION REQUIRED!!\n",
        "        # return MISSING (use np.reshape)\n",
        "\n",
        "    def backward_propagation(self,output_gradient,learning_rate):\n",
        "        # you can ignore the learning_rate\n",
        "        ## SOLUTION REQUIRED!!\n",
        "        # return MISSING (use np.reshape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCXXcALGXSRb"
      },
      "source": [
        "### Testing Your Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KotuuqWKXt2r"
      },
      "source": [
        "### Defining our main neural network architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzatylPzQIdR"
      },
      "source": [
        "Define your CNN network's architecture:\n",
        "\n",
        "* A convolution layer with some filters `(f)` and a window size of `(w x w)`, with a `tanh` activation function.\n",
        "* A max pooling layer of a window size of `(p x p)`.  \n",
        "* First affine layer that takes your input and outputs 128 nodes\n",
        "* `tanh` activation layer following the first affine layer\n",
        "* Second affine layer that takes the first layer's input and outputs 64 nodes\n",
        "* `tanh` activation layer following the second affine layer\n",
        "* Third affine layer that takes your second layer's input and outputs nodes in the size of the Y labels.\n",
        "* `tanh` activation layer following the last affine layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh8uUSX8MFjX"
      },
      "source": [
        "You can compute the shapes of the convolution and max-pool layers' outputs  as a function of the input shape, the convolution sliding window size, and the number of filters for applied. ( the stride and padding are usually also used to calculate the output shapes, but in this simple implementation we set the stride to 1 with zero padding.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqVPvlDvdZJi"
      },
      "source": [
        "P2Q2a: (5pts).        \n",
        "Calculate the input and output shapes of each layer in the network below, up until the first affine layer (including).  (mathematically) explain your answer.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTCg_pA6fCz7"
      },
      "source": [
        "\n",
        "ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7YV_aivOf3v"
      },
      "outputs": [],
      "source": [
        "# MISSING CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRtnAEVhfHLs"
      },
      "source": [
        "P2Q2b:  (5pts).   \n",
        "\n",
        "Please complete the missing code (`## SOLUTION REQUIRED!!`) so that the network architecture works properly.  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O9Mi5Qmuvlp"
      },
      "outputs": [],
      "source": [
        "#### SOLUTION REQUIRED IN THIS BLOCK (in  reshape parameters) ####\n",
        "\n",
        "# Network Architecture\n",
        "CNNnet = MyNetwork()\n",
        "num_classes = 10\n",
        "# Reshape sizes:\n",
        "## SOLUTION REQUIRED!!\n",
        "# c = # output channels\n",
        "# x_new = # MISSING\n",
        "# y_new = # MISSING\n",
        "\n",
        "\n",
        "# Adding convolution and max-pool layers:\n",
        "CNNnet.add(Convolution(num_filters=12, size=3,\n",
        "                    activation=ActivationLayer(relu, relu_grad))) #\n",
        "CNNnet.add(MaxPool(size=3))\n",
        "\n",
        "# Reshaping for first affine layer:\n",
        "CNNnet.add(Reshape((c,y_new,x_new),(1,c*y_new*x_new)))\n",
        "\n",
        "# Adding affine layers and activation functions:\n",
        "CNNnet.add(Affine_Layer(c*y_new*x_new, 128))\n",
        "CNNnet.add(ActivationLayer(tanh, tanh_grad))\n",
        "CNNnet.add(Affine_Layer(128, 64))\n",
        "CNNnet.add(ActivationLayer(tanh, tanh_grad))\n",
        "CNNnet.add(Affine_Layer(64, num_classes))\n",
        "CNNnet.add(ActivationLayer(tanh, tanh_grad))\n",
        "\n",
        "# CNNnet.add(ActivationLayer(relu, relu_grad))\n",
        "# CNNnet.add(ActivationLayer(tanh, tanh_grad))\n",
        "# CNNnet.add(ActivationLayer(sigmoid, sigmoid_grad))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8_5gnOuuxWC"
      },
      "source": [
        "### Training!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no need to train the model on the entire dataset (you'l see why now...). Try to prove that your network works as expected by showing that your error decreases dramatically even on a small sample (say, around 1k)."
      ],
      "metadata": {
        "id": "nPrQ0BeU9EBN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QhWuBFBfg3SB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# While developing, it is recommended to train your model on a subset of the data... / or low epochs.\n",
        "# Training will be pretty slow if we update at each iteration on 60000 samples...]\n",
        "CNNnet.use_loss(mse, mse_grad)\n",
        "epoch_num = 20 #20\n",
        "lr = 0.1\n",
        "t1 = time.time()\n",
        "CNNnet.fit(x_train[:1000], y_train[:1000], epochs=epoch_num,\n",
        "           learning_rate=lr)\n",
        "print(f\"Total process time: {round(time.time() - t1,3)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQDk--PDWei3"
      },
      "source": [
        "Hurray - if you got to this point, your CNN model works, but is EXTREMELY slow.   \n",
        "Let's check why using a cProfiler:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9tpOFXZNT-lh"
      },
      "outputs": [],
      "source": [
        "# CNNnet.prof(x_train[:100], y_train[:100],epochs=4,learning_rate=lr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17d2RSa7YGcy"
      },
      "source": [
        "P2Q2c:  (5pts).     \n",
        "Why do you think our CNN implementation is slow? Your answer should relate to the  approximate `O(n)` time/computational complexity ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER MISSING"
      ],
      "metadata": {
        "id": "cV8MOVZoGrTD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXwnmpjlu5sa"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hhz13JznTujh"
      },
      "source": [
        "Exciting! Now is the time to test your model.     \n",
        "\n",
        "\n",
        "    May the gradients be always in your favor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwyHGkMpf4NB"
      },
      "source": [
        "P2Q2b (cont'd):\n",
        "\n",
        "**Try to limit the number of epochs and the size of the trained data, while still achieving an accuracy score of >85%.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BHDYRUoq54Fk",
        "outputId": "6224bf44-4f8b-40c4-f396-4695f259df9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 0.0302, Accuracy: 436/500 (87%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output = CNNnet.predict(x_test[:500] ,y_test[:500] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9HEZ6ElvVVj"
      },
      "source": [
        "### Benchmarking against PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-0UWnaYUNz7"
      },
      "source": [
        "How well your model performs against a similar-architecture PyTorch model?   \n",
        "It is time to find out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R2TeiObsnBr1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h8cCoV3ZSkt"
      },
      "source": [
        "**Prepare the data as tensors using PyTorch DataLoader:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# # training data : 60000 samples\n",
        "# # reshape and normalize input data\n",
        "# x_train = x_train.reshape(x_train.shape[0], 1, 28*28) not needed\n",
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "# # One-hot encoding of the output.\n",
        "# # Currently a number in range [0,9]; Change into a vector of size 10\n",
        "# # e.g. number 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "y_train = to_categorical(y_train)\n",
        "# # same for test data : 10000 samples\n",
        "# x_test = x_test.reshape(x_test.shape[0], 1, 28*28) not needed\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "S1vnaVP23Vzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1rqwlzUIvFCZ"
      },
      "outputs": [],
      "source": [
        "t_train =  TensorDataset(torch.Tensor(x_train),torch.Tensor(y_train))\n",
        "t_test =  TensorDataset(torch.Tensor(x_test),torch.Tensor(y_test))\n",
        "train_loader = torch.utils.data.DataLoader(dataset=t_train, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=t_test, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ngm-Gv_UsCV"
      },
      "source": [
        "Define a `PyTorchCNN` class with an identical architecture you used in your home-made network.  \n",
        "Hint: use `x = x.view()` to handle reshapes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJBs2JsyNxid"
      },
      "source": [
        "P2Q3a: (5pts).   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4Ed2P1LmUpgS"
      },
      "outputs": [],
      "source": [
        "#### SOLUTION REQUIRED  IN THIS BLOCK####\n",
        "\n",
        "class PyTorchCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PyTorchCNN, self).__init__()\n",
        "        # input_size = # FILL IN THE MISSING CODE\n",
        "        # num_classes = # FILL IN THE MISSING CODE\n",
        "        # SOLUTION REQUIRED\n",
        "        # THE REST IS MISSING\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = x.view(-1, (28,28) )\n",
        "        # x =  SOLUTION REQUIRED : THE REST IS MISSING\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fG-8BEdDlL4L"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "pt_learning_rate = 0.01\n",
        "pt_network = PyTorchCNN()\n",
        "optimizer = torch.optim.Adam(pt_network.parameters(), lr=pt_learning_rate)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Forward pass\n",
        "        # labels = labels.view(64,1,10)\n",
        "        outputs = pt_network(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward pass and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # A handy printout:\n",
        "        if (i + 1) % 500 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3rFfBfaV3Gt"
      },
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RsfDSk2IrXst"
      },
      "outputs": [],
      "source": [
        "pt_network.eval()\n",
        "test_losses = []\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = pt_network(data)\n",
        "        test_loss += criterion(output, target,)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.max(1,keepdim=True)[1]).sum()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "test_losses.append(test_loss)\n",
        "print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "  test_loss, correct, len(test_loader.dataset),\n",
        "  100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyKXHGW3XsAN"
      },
      "source": [
        "P2Q3b (5pts).   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI13KBVgrBkc"
      },
      "source": [
        "Time for some questions:\n",
        "1. Which one of the models performed better? Why?\n",
        "2. Which one of the models performed faster? Why?  \n",
        "3. What would you change in your network's architecture?   \n",
        "4. What would you change in your model's solution algorithm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb6AMtbuXvSR"
      },
      "source": [
        "Write your solutions here:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER MISSING"
      ],
      "metadata": {
        "id": "5QHGNNFLFgbt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN10lnDf9uAR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oU40LpgzQ-B"
      },
      "source": [
        "## PS2 Part 3: RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrli1fPPGF-D"
      },
      "source": [
        "In this part we are going to implement a simple time-series prediction using RNN on a noisy simulated funcitonal data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gTFdBWRgm9U"
      },
      "source": [
        "There are two main goals in time series prediction:\n",
        "\n",
        "**Understanding the data:** This involves identifying the patterns and trends that exist in the data over time.    \n",
        "By understanding these patterns, we can gain insights into the underlying processes that generate the data.    \n",
        "For instance, time series analysis might reveal seasonal trends in sales data or cyclical patterns in stock prices.\n",
        "\n",
        "**Forecasting future values:** This is the more commonly recognized goal of time series prediction.   \n",
        "By leveraging the patterns and trends identified in the data, we can make predictions about what the data will look like in the future.   \n",
        "This can be helpful for tasks like planning inventory levels, managing financial risk, or predicting weather patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLg_PtTJhKpj"
      },
      "source": [
        "**Recurrent Neural Networks (RNNs)** are a powerful tool for time series prediction because they can handle the sequential nature of time series data.   Unlike traditional neural networks, RNNs have internal memory that allows them to consider past information when making predictions. This is particularly useful for time series data where the value at any given point in time is often influenced by past values.\n",
        "\n",
        "*Here's a breakdown of how RNNs are used for time series prediction:*\n",
        "\n",
        "The Model Architecture:\n",
        "\n",
        "* A typical RNN model for time series prediction consists of an input layer, one or more hidden layers with special RNN cells (like LSTM or GRU), and an output layer.\n",
        "The hidden layers process the data sequences.   \n",
        "* Each cell in the hidden layer receives the current input and the output from the previous cell in the sequence. This allows the network to consider past information.\n",
        "\n",
        "**The Training Process:**\n",
        "\n",
        "* The RNN is trained on historical time series data. The model is presented with sequences of data points, and it learns to predict the next value in the sequence.  \n",
        "* During training, the RNN uses backpropagation through time (BPTT), a variant of the standard backpropagation algorithm, to adjust its internal parameters and improve its prediction accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5BYbS_kcQIj"
      },
      "source": [
        "### Simulating data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA8Vcfclie6Y"
      },
      "source": [
        "\n",
        "\n",
        "> In this example, each training step ($t$) consists of a sequence of target data of length $k$ ($t-k:t$), and a training sequence of the same length, but with a lag ($t-k-l:t-l$). Our RNN should predict the target sequence using the lagged training sequence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwHEbIsAQHt3"
      },
      "source": [
        "We simulate cyclical data using a function of `sin` and `cos`:\n",
        "\n",
        "*   As is, the output of our function is cyclical (recurring) in `t`.\n",
        "*   We also add a `sin` shift (`np.sin(s)`) that adds a small drift between steps.\n",
        "* Our target is defined as: $y(t,s) = sin(sin(s)*2*\\pi*t+\\pi/6)+cos(2*\\sqrt(3)*t) $\n",
        "*   Our training data (without lag) is defined as:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ctNC44cXkuJ"
      },
      "source": [
        "$$y_{\\alpha}(t,s) = sin(sin(s)*2*\\pi*t+\\pi/6)+cos(2*\\sqrt(3)*t) + N(0,1)*\\alpha$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNmFImFGk9yb"
      },
      "source": [
        "Image that we only observe the noisy training data and the target, without having any insight into the generating function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naXni9L9pzF2"
      },
      "source": [
        "P3Q1 (10pts)  \n",
        "Fill out the missing code according to the function definition above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4k8bMOqq82Vn"
      },
      "outputs": [],
      "source": [
        "## SOLUTION REQUIRED IN THIS BLOCK ##\n",
        "\n",
        "## Plotting simulated functional data\n",
        "\n",
        "t_line = np.arange(-5., 5., 1/100.) # line space\n",
        "alpha = 0.4\n",
        "## Creating a function to produce cyclical y data.\n",
        "# y_func = ## SOLUTION REQURIED HERE ##\n",
        "y = y_func(1)\n",
        "## Adding noise\n",
        "# y_noisy = ## SOLUTION REQURIED HERE ##\n",
        "\n",
        "\n",
        "## Plotting\n",
        "fig, ax = plt.subplots(2,1, figsize=(16,8))\n",
        "fval = np.arange(-1,1,0.1)\n",
        "\n",
        "for i in fval:\n",
        "    ax[0].plot(t_line, y_func(i), color='gray', alpha=.3,label=\"$sin(f)$ shift\")\n",
        "\n",
        "ax[0].plot(t_line, y, lw = 2,label = \"fixed $f$\",color=\"b\")\n",
        "ax[0].set_xlabel('Target, time (sec)')\n",
        "ax[1].plot(t_line, y_noisy, lw = 2,c=\"r\")\n",
        "ax[1].set_xlabel('Noisy Training Data, time (sec)')\n",
        "ax[0].legend([\"$y(t,s)$ shift\",\"$y(t,1)$\"],labelcolor=[\"gray\",\"b\"])\n",
        "ax[1].legend([\"$y_{\\\\alpha}(t,1)$\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgg3tZOPlPzG"
      },
      "source": [
        "In the figure above we can see the true output of the generating function, given a specific value of $s$ (blue), and various drifts according to different values of $s$ (gray).  In the bottom plot you can see the noisy data (training),  matching the blue graph in the top plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smIzKO1IcTQ2"
      },
      "source": [
        "### Creating PyTorch RNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTPP6rAhcZZh"
      },
      "source": [
        "Here we create a basic PyTorch RNN class (inherits from `nn.Module`).  \n",
        "\n",
        "* *input_size* – The number of expected features (dimensions) in the input t\n",
        "\n",
        "* *hidden_size* – The number of features in the hidden state h\n",
        "\n",
        "* *num_layers* – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results.    \n",
        "\n",
        "* batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Note that this does not apply to hidden or cell states.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDwWZ2X2ZnZx"
      },
      "source": [
        "\n",
        "For more information, please check the\n",
        "[PyTorch nn.RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN) documentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AGe1ChLa4X2H"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_dim=hidden_dim\n",
        "\n",
        "        # define an RNN with specified parameters\n",
        "        # batch_first means that the first dim of the input and output will be the batch_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
        "\n",
        "        # Adding a fully-connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x (batch_size, seq_length, input_size)\n",
        "        # hidden (n_layers, batch_size, hidden_dim)\n",
        "        # r_out (batch_size, time_step, hidden_size)\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # get RNN outputs\n",
        "        r_out, hidden = self.rnn(x, hidden)\n",
        "        r_out = r_out.view(-1, self.hidden_dim)\n",
        "\n",
        "        # get final output\n",
        "        output = self.fc(r_out)\n",
        "\n",
        "        return output, hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7qF9QdrgfZur"
      },
      "outputs": [],
      "source": [
        "\n",
        "# RNN Hyperparameters\n",
        "input_size=1 # our data is 1-dim\n",
        "output_size=1\n",
        "hidden_dim=16\n",
        "n_layers=2\n",
        "\n",
        "# instantiate an RNN model\n",
        "rnn = RNN(input_size, output_size, hidden_dim, n_layers)\n",
        "print(rnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOZ0RZE4d5zU"
      },
      "source": [
        "### RNN Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9pkc-rufDom"
      },
      "source": [
        "Now we need to define a training function that takes the following hyper-parameters:  \n",
        "\n",
        "* rnn : the RNN model object\n",
        "* n_steps = on how many steps ($t$) to train the model (equivalent to \"epochs\").\n",
        "* lag = the steps/datapoints lag between the training and target data.\n",
        "* alpha = how much noise to add to the training data\n",
        "* seq_length = how many datapoints  (time-series steps) to consider in each \"epoch\": $(t-k:t)$\n",
        "* stride = the window size of the function (of which the seq_length will be divided).\n",
        "* print_every = how often (in steps) to print a plot of the prediction against the target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN6NSAcCl_lR"
      },
      "source": [
        "At each step, we have a lagged value of x, noisy lagged value of x (training), and a value of y (target not lagged)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40jkrNu0qKRP"
      },
      "source": [
        "P3Q2:  (5pts)\n",
        "\n",
        "Fill out the missing code according to the function definition above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5tJElQY3iJ0r"
      },
      "outputs": [],
      "source": [
        "## SOLUTION REQUIRED IN THIS BLOCK##\n",
        "\n",
        "# As above, creating a simulated data generator from our function (not noisy)\n",
        "# this time, the function should depend on \"step\" as well (x_line is ever changing).\n",
        "\n",
        "# y_func = ## SOLUTION NEEDED\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iM0onmhu6lRL"
      },
      "outputs": [],
      "source": [
        "# train the RNN\n",
        "def train(rnn,y_func, n_steps, print_every,stride,seq_length,\n",
        "          alpha,lag):\n",
        "    # initialize the RNN hidden state\n",
        "    hidden = None\n",
        "    s = 1 # initialize f\n",
        "    for batch_i, step in enumerate(range(n_steps)):\n",
        "        # defining the training data\n",
        "\n",
        "        # t_line = np.linspace(y_func(s,step),y_func(s,step)+stride,seq_length+stride)\n",
        "        t_line =  np.linspace(step,step+stride, seq_length)\n",
        "        data = y_func(s,t_line)\n",
        "        noisy_data =  data + np.random.randn(len(t_line))*alpha\n",
        "        # update f\n",
        "        s += 0.05\n",
        "\n",
        "        # prepare data for training\n",
        "        data.resize((seq_length , 1)) # input_size=1\n",
        "        noisy_data.resize((seq_length , 1)) # input_size=1\n",
        "        # creating a lag in the noisy data aginst y\n",
        "        x = noisy_data[:-lag]\n",
        "        y = data[lag:]\n",
        "\n",
        "        # convert data into Tensors\n",
        "        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension\n",
        "        y_tensor = torch.Tensor(y)\n",
        "\n",
        "        # outputs from the rnn\n",
        "        prediction, hidden = rnn(x_tensor, hidden)\n",
        "\n",
        "        ## Representing Memory ##\n",
        "        # make a new variable for hidden and detach the hidden state from its history\n",
        "        # this way, we don't backpropagate through the entire history\n",
        "        hidden = hidden.data\n",
        "\n",
        "        # calculate the loss\n",
        "        loss = criterion(prediction, y_tensor)\n",
        "        # zero out gradients\n",
        "        optimizer.zero_grad()\n",
        "        # calculate backprop and update weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # plot loss and predictions\n",
        "        if batch_i%print_every == 0:\n",
        "            plt.plot(t_line[lag:], x, 'r.',label = \"training\")\n",
        "            plt.plot(t_line[lag:], y, 'b.',label = \"actual\")\n",
        "            plt.plot(t_line[lag:], prediction.data.numpy().flatten(), 'y.',label= \"prediction\") #\n",
        "            plt.title(\"Loss: {:,}\".format(loss.item()))\n",
        "            plt.legend(loc=\"upper left\")\n",
        "            plt.show()\n",
        "\n",
        "    return rnn\n",
        "\n",
        "# MSE loss and Adam optimizer with a learning rate of 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naCnkXNoprm-"
      },
      "source": [
        "    \n",
        "Train the RNN model on various hyper-parameters (defined below) and review the results.   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vHZWGVAN6nSy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# train the rnn and monitor results\n",
        "\n",
        "n_steps = 200\n",
        "stride = 10\n",
        "lag = 3\n",
        "alpha = 0.2\n",
        "seq_length = 500\n",
        "print_every = 20\n",
        "\n",
        "trained_rnn = train(rnn, y_func,  n_steps, print_every,\n",
        "                    stride,seq_length,alpha,lag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCVQDoK5qxU1"
      },
      "source": [
        "P3Q3: (10pts)\n",
        "\n",
        "(a) Do you think our model performs well?     \n",
        "(b) Write about the relationships and interplay between the different hyper-parameters, and explain how they effect the RNN model. Please relate also to the RNN architecture in our solution.\n",
        "\n",
        "(c) Can you give a real world example where this type of model can be applied?   \n",
        "(d) What would you change to improve it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nQO9CS2rFFx"
      },
      "source": [
        "Write your solution here!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER MISSING"
      ],
      "metadata": {
        "id": "zflZlw5hGfPL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv8crIYW924c"
      },
      "source": [
        "THE END!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}