<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>PS3_Attention_Please_2025_ID_314992595</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                messageStyle: 'none',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Neural-Machine-Translation-with-Attention">Neural Machine Translation with Attention<a class="anchor-link" href="#Neural-Machine-Translation-with-Attention"></a></h1><p>Advanced Learning Fall 2025</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>For SUBMISSION:</p>
<p>Please upload the complete and executed <code>ipynb</code> to your git repository. Verify that all of your output can be viewed directly from github, and provide a link to that git file below.</p>
<pre><code>STUDENT ID: 314992595
</code></pre>
<pre><code>STUDENT GIT LINK: https://github.com/netanelazran11/ACL/tree/main/HM3
</code></pre>
<p>In Addition, don't forget to add your ID to the files, and upload to moodle the html version:</p>
<p><code>PS3_Attention_2025_ID_[000000000].html</code></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>In this problem set we are going to jump into the depths of <code>seq2seq</code> and <code>attention</code> and build a couple of PyTorch translation mechanisms with some  twists.</p>
<ul>
<li>Part 1 consists of a somewhat unorthodox <code>seq2seq</code> model for simple arithmetics</li>
<li>Part 2 consists of an <code>seq2seq - attention</code> language translation model. We will use it for Hebrew and English.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>A <strong>seq2seq</strong> model (sequence-to-sequence model) is a type of neural network designed specifically to handle sequences of data. The model converts input sequences into other sequences of data. This makes them particularly useful for tasks involving language, where the input and output are naturally sequences of words.</p>
<p>Here's a breakdown of how <code>seq2seq</code> models work:</p>
<ul>
<li><p>The encoder takes the input sequence, like a sentence in English, and processes it to capture its meaning and context.</p>
</li>
<li><p>information is then passed to the decoder, which uses it to generate the output sequence, like a translation in French.</p>
</li>
<li><p>Attention mechanism (optional): Some <code>seq2seq</code> models also incorporate an attention mechanism. This allows the decoder to focus on specific parts of the input sequence that are most relevant to generating the next element in the output sequence.</p>
</li>
</ul>
<p><code>seq2seq</code> models are used in many natural language processing (NLP) tasks.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>imports: (feel free to add)</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># from __future__ import unicode_literals, print_function, division</span>
<span class="c1"># from io import open</span>
<span class="c1"># import unicodedata</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">unicodedata</span>

<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>


<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">RandomSampler</span> <span class="p">,</span> <span class="n">Dataset</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Part-1:-Seq2Seq-Arithmetic-model">Part 1: Seq2Seq Arithmetic model<a class="anchor-link" href="#Part-1:-Seq2Seq-Arithmetic-model"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><strong>Using RNN <code>seq2seq</code> model to "learn" simple arithmetics!</strong></p>
<blockquote>
<p>Given the string "54-7", the model should return a prediction: "47".<br/>
Given the string "10+20", the model should return a prediction: "30".</p>
</blockquote>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>Watch Lukas Biewald's short <a href="https://youtu.be/MqugtGD605k?si=rAH34ZTJyYDj-XJ1">video</a> explaining <code>seq2seq</code> models and his toy application (somewhat outdated).</li>
<li>You can find the code for his example <a href="https://github.com/lukas/ml-class/blob/master/videos/seq2seq/train.py">here</a>.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.1) Using Lukas' code, implement a <code>seq2seq</code> network that can learn how to solve <strong>addition AND substraction</strong> of two numbers of maximum length of 4, using the following steps (similar to the example):</p>
<ul>
<li>Generate data; X: queries (two numbers), and Y: answers</li>
<li>One-hot encode X and Y,</li>
<li>Build a <code>seq2seq</code> network (with LSTM, RepeatVector, and TimeDistributed layers)</li>
<li>Train the model.</li>
<li>While training, sample from the validation set at random so we can visualize the generated solutions against the true solutions.</li>
</ul>
<p>Notes:</p>
<ul>
<li>The code in the example is quite old and based on Keras. You might have to adapt some of the code to overcome methods/code that is not supported anymore. Hint: for the evaluation part, review the type and format of the "correct" output - this will help you fix the unsupported "model.predict_classes".</li>
<li>Please use the parameters in the code cell below to train the model.</li>
<li>Instead of using a <code>wandb.config</code> object, please use a simple dictionary instead.</li>
<li>You don't need to run the model for more than 50 iterations (epochs) to get a gist of what is happening and what the algorithm is doing.</li>
<li>Extra credit if you can implement the network in PyTorch (this is not difficult).</li>
<li>Extra credit if you are able to significantly improve the model.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.2).</p>
<p>a) Do you think this model performs well?  Why or why not?<br/>
b) What are its limitations?<br/>
c) What would you do to improve it?<br/>
d) Can you apply an attention mechanism to this model? Why or why not?</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.3).</p>
<p>Add attention to the model. Evaluate the performance against the <code>seq2seq</code> you trained above. Which one is performing better?</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.4)</p>
<p>Using any neural network architecture of your liking, build  a model with the aim to beat the best performing model in 1.1 or 1.3. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">40000</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">config</span><span class="p">[</span><span class="s2">"iterations"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">chars</span> <span class="o">=</span> <span class="s1">'0123456789-+ '</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>SOLUTION:</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">### MISSING SOLUTION</span>
<span class="sd">"""Seq2Seq Arithmetic in PyTorch (LSTM EncoderDecoder) for addition AND subtraction.</span>
<span class="sd">"""</span>

<span class="c1"># Internal defaults</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"seed"</span><span class="p">,</span> <span class="mi">123</span><span class="p">))</span>
<span class="n">VAL_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"val_size"</span><span class="p">,</span> <span class="mi">10_000</span><span class="p">))</span>
<span class="n">EMB_DIM</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"emb_dim"</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
<span class="n">LR</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"lr"</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">))</span>
<span class="n">PRINT_SAMPLES</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"print_samples"</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>

<span class="n">EPOCHS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"iterations"</span><span class="p">],</span> <span class="mi">50</span><span class="p">))</span>
<span class="n">DIGITS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">])</span>
<span class="n">TRAIN_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">])</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">])</span>
<span class="n">HIDDEN_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">])</span>

<span class="c1"># Reproducibility</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>


<span class="c1"># Task constants</span>
<span class="n">MAX_INT</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">DIGITS</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">MAX_QUERY_LEN</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">DIGITS</span> <span class="o">+</span> <span class="mi">1</span>   <span class="c1"># e.g., "9999+9999"</span>
<span class="n">MAX_ANS_LEN</span> <span class="o">=</span> <span class="n">DIGITS</span> <span class="o">+</span> <span class="mi">1</span>         <span class="c1"># e.g., "19998" or "-9999" (len 5)</span>

<span class="n">PAD</span> <span class="o">=</span> <span class="s2">" "</span>
<span class="n">SOS</span> <span class="o">=</span> <span class="s2">"^"</span>  <span class="c1"># decoder start token (internal)</span>

<span class="c1"># Use the notebook's chars and add SOS internally</span>
<span class="n">CHARS</span> <span class="o">=</span> <span class="n">chars</span> <span class="o">+</span> <span class="n">SOS</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Vocab</span>
<span class="c1"># -----------------------------</span>
<span class="k">class</span> <span class="nc">CharVocab</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chars_</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chars</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">chars_</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">itos</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">c</span> <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">PAD</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sos_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">SOS</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">s</span><span class="p">[:</span><span class="n">maxlen</span><span class="p">]]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">maxlen</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">maxlen</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">)</span>


<span class="n">vocab</span> <span class="o">=</span> <span class="n">CharVocab</span><span class="p">(</span><span class="n">CHARS</span><span class="p">)</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Dataset</span>
<span class="c1"># -----------------------------</span>
<span class="k">class</span> <span class="nc">ArithmeticSeq2SeqDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Returns (x, dec_in, y) index tensors.</span>

<span class="sd">    x:      (T_in,) query</span>
<span class="sd">    dec_in: (T_out,) decoder input = SOS + y[:-1]</span>
<span class="sd">    y:      (T_out,) target answer</span>

<span class="sd">    Loss ignores PAD positions in y.</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">questions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">answers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">seen</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">questions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">MAX_INT</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">b</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">MAX_INT</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">op</span> <span class="o">=</span> <span class="s2">"+"</span> <span class="k">if</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="s2">"-"</span>

            <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>  <span class="c1"># do NOT sort (subtraction not commutative)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">seen</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

            <span class="n">ans</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="s2">"+"</span> <span class="k">else</span> <span class="n">a</span> <span class="o">-</span> <span class="n">b</span>

            <span class="n">q</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">a</span><span class="si">}{</span><span class="n">op</span><span class="si">}{</span><span class="n">b</span><span class="si">}</span><span class="s2">"</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">MAX_QUERY_LEN</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">MAX_ANS_LEN</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">questions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">answers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">questions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">answers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">MAX_QUERY_LEN</span><span class="p">)</span>
        <span class="n">y_tgt</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">MAX_ANS_LEN</span><span class="p">)</span>

        <span class="n">dec_in_str</span> <span class="o">=</span> <span class="p">(</span><span class="n">SOS</span> <span class="o">+</span> <span class="n">y</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">MAX_ANS_LEN</span><span class="p">)</span>
        <span class="n">dec_in</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">dec_in_str</span><span class="p">,</span> <span class="n">MAX_ANS_LEN</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">,</span> <span class="n">y_tgt</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Model</span>
<span class="c1"># -----------------------------</span>
<span class="k">class</span> <span class="nc">Seq2SeqLSTM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># x: (B, T_in), dec_in: (B, T_out)</span>
        <span class="n">x_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x_emb</span><span class="p">)</span>

        <span class="n">dec_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">dec_in</span><span class="p">)</span>
        <span class="n">dec_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">dec_emb</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">dec_out</span><span class="p">)</span>  <span class="c1"># (B, T_out, V)</span>
        <span class="k">return</span> <span class="n">logits</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">greedy_decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">x_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x_emb</span><span class="p">)</span>

        <span class="n">B</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">B</span><span class="p">,</span> <span class="n">max_len</span><span class="p">),</span> <span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">vocab</span><span class="o">.</span><span class="n">sos_idx</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">):</span>
            <span class="n">prev_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">prev</span><span class="p">)</span>
            <span class="n">dec_out</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">prev_emb</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">dec_out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>      <span class="c1"># (B, V)</span>
            <span class="n">next_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>   <span class="c1"># (B,)</span>
            <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">next_idx</span>
            <span class="n">prev</span> <span class="o">=</span> <span class="n">next_idx</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">y_pred</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Utils</span>
<span class="c1"># -----------------------------</span>
<span class="k">def</span> <span class="nf">token_acc_ignore_pad</span><span class="p">(</span><span class="n">pred</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">pad_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">!=</span> <span class="n">pad_idx</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
    <span class="k">return</span> <span class="p">(((</span><span class="n">pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="o">/</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">eval_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">Seq2SeqLSTM</span><span class="p">,</span> <span class="n">loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">)</span>

    <span class="n">total_loss</span><span class="p">,</span> <span class="n">total_acc</span><span class="p">,</span> <span class="n">n_batches</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">dec_in</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">pred_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">token_acc_ignore_pad</span><span class="p">(</span><span class="n">pred_idx</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">)</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">total_acc</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>
        <span class="n">n_batches</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">total_acc</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">print_samples</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">Seq2SeqLSTM</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">ArithmeticSeq2SeqDataset</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">SEED</span> <span class="o">+</span> <span class="mi">999</span><span class="p">)</span>
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">xs</span><span class="p">,</span> <span class="n">qs</span><span class="p">,</span> <span class="n">ys_true</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idxs</span><span class="p">:</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">questions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">answers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">MAX_QUERY_LEN</span><span class="p">))</span>
        <span class="n">qs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
        <span class="n">ys_true</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>

    <span class="n">x_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">y_pred_idx</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">greedy_decode</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">MAX_ANS_LEN</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Samples from validation (greedy decode)"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">q</span><span class="p">,</span> <span class="n">y_t</span><span class="p">,</span> <span class="n">y_p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">ys_true</span><span class="p">,</span> <span class="n">y_pred_idx</span><span class="p">):</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">y_p</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">SOS</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">ok</span> <span class="o">=</span> <span class="s2">""</span> <span class="k">if</span> <span class="n">pred</span> <span class="o">==</span> <span class="n">y_t</span> <span class="k">else</span> <span class="s2">""</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">ok</span><span class="si">}</span><span class="s2">  Q: </span><span class="si">{</span><span class="n">q</span><span class="si">:</span><span class="s2">&gt;12</span><span class="si">}</span><span class="s2">   TRUE: </span><span class="si">{</span><span class="n">y_t</span><span class="si">:</span><span class="s2">&gt;6</span><span class="si">}</span><span class="s2">   PRED: </span><span class="si">{</span><span class="n">pred</span><span class="si">:</span><span class="s2">&gt;6</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Train</span>
<span class="c1"># -----------------------------</span>
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"chars:  </span><span class="si">{</span><span class="n">chars</span><span class="si">!r}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Vocab size: </span><span class="si">{</span><span class="n">vocab</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2">  |  Vocab: </span><span class="si">{</span><span class="n">vocab</span><span class="o">.</span><span class="n">chars</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"MAX_QUERY_LEN=</span><span class="si">{</span><span class="n">MAX_QUERY_LEN</span><span class="si">}</span><span class="s2">, MAX_ANS_LEN=</span><span class="si">{</span><span class="n">MAX_ANS_LEN</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"TRAIN_SIZE=</span><span class="si">{</span><span class="n">TRAIN_SIZE</span><span class="si">}</span><span class="s2">, VAL_SIZE=</span><span class="si">{</span><span class="n">VAL_SIZE</span><span class="si">}</span><span class="s2">, BATCH_SIZE=</span><span class="si">{</span><span class="n">BATCH_SIZE</span><span class="si">}</span><span class="s2">, EPOCHS=</span><span class="si">{</span><span class="n">EPOCHS</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">ArithmeticSeq2SeqDataset</span><span class="p">(</span><span class="n">TRAIN_SIZE</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">val_ds</span> <span class="o">=</span> <span class="n">ArithmeticSeq2SeqDataset</span><span class="p">(</span><span class="n">VAL_SIZE</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">Seq2SeqLSTM</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">EMB_DIM</span><span class="p">,</span> <span class="n">HIDDEN_SIZE</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">run_loss</span><span class="p">,</span> <span class="n">run_acc</span><span class="p">,</span> <span class="n">n_batches</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">dec_in</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">pred_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">acc</span> <span class="o">=</span> <span class="n">token_acc_ignore_pad</span><span class="p">(</span><span class="n">pred_idx</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">)</span>

            <span class="n">run_loss</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">run_acc</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>
            <span class="n">n_batches</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">run_loss</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">run_acc</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">eval_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">EPOCHS</span><span class="si">}</span><span class="s2">  |  "</span>
            <span class="sa">f</span><span class="s2">"train loss=</span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">  |  "</span>
            <span class="sa">f</span><span class="s2">"val loss=</span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> acc=</span><span class="si">{</span><span class="n">val_acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span>
        <span class="p">)</span>
        <span class="n">print_samples</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_ds</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">PRINT_SAMPLES</span><span class="p">)</span>

    <span class="c1"># Final sanity check</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">tests</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"54-7"</span><span class="p">,</span> <span class="s2">"10+20"</span><span class="p">,</span> <span class="s2">"9999+9999"</span><span class="p">,</span> <span class="s2">"0-9999"</span><span class="p">,</span> <span class="s2">"1234-9999"</span><span class="p">,</span> <span class="s2">"777+888"</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Final sanity check (greedy):"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tests</span><span class="p">:</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">MAX_QUERY_LEN</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">MAX_QUERY_LEN</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">greedy_decode</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">MAX_ANS_LEN</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">SOS</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Q: </span><span class="si">{</span><span class="n">t</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2">   PRED: </span><span class="si">{</span><span class="n">pred</span><span class="si">:</span><span class="s2">&gt;6</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Device: cpu
config: {'training_size': 40000, 'digits': 4, 'hidden_size': 128, 'batch_size': 128, 'iterations': 50}
chars:  '0123456789-+ '
Vocab size: 14  |  Vocab: [' ', '+', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '^']
MAX_QUERY_LEN=9, MAX_ANS_LEN=5
TRAIN_SIZE=40000, VAL_SIZE=10000, BATCH_SIZE=128, EPOCHS=50

Epoch 01/50  |  train loss=2.0806 acc=0.2155  |  val loss=1.9495 acc=0.2560

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  14444
  Q:    2565+6526   TRUE:   9091   PRED:  80442
  Q:     801-3219   TRUE:  -2418   PRED:  -2293
  Q:    3984+1770   TRUE:   5754   PRED:  64294
  Q:    3735+2615   TRUE:   6350   PRED:  64294
  Q:    5688+7759   TRUE:  13447   PRED:  14242
  Q:    2025+3260   TRUE:   5285   PRED:  42164
  Q:    8524+7403   TRUE:  15927   PRED:  14444
  Q:     980+5556   TRUE:   6536   PRED:  94444
  Q:    1911-2754   TRUE:   -843   PRED:  -1429
  Q:    1702+1297   TRUE:   2999   PRED:  42164
  Q:    6529+7415   TRUE:  13944   PRED:  14442

Epoch 02/50  |  train loss=1.8697 acc=0.2902  |  val loss=1.8017 acc=0.3222

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13055
  Q:    2565+6526   TRUE:   9091   PRED:  90150
  Q:     801-3219   TRUE:  -2418   PRED:  -2052
  Q:    3984+1770   TRUE:   5754   PRED:  55555
  Q:    3735+2615   TRUE:   6350   PRED:  55555
  Q:    5688+7759   TRUE:  13447   PRED:  13405
  Q:    2025+3260   TRUE:   5285   PRED:  55555
  Q:    8524+7403   TRUE:  15927   PRED:  15515
  Q:     980+5556   TRUE:   6536   PRED:  89555
  Q:    1911-2754   TRUE:   -843   PRED:  -1525
  Q:    1702+1297   TRUE:   2999   PRED:  45152
  Q:    6529+7415   TRUE:  13944   PRED:  13455

Epoch 03/50  |  train loss=1.7603 acc=0.3351  |  val loss=1.7229 acc=0.3442

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13055
  Q:    2565+6526   TRUE:   9091   PRED:  88355
  Q:     801-3219   TRUE:  -2418   PRED:  -2226
  Q:    3984+1770   TRUE:   5754   PRED:  60555
  Q:    3735+2615   TRUE:   6350   PRED:  66655
  Q:    5688+7759   TRUE:  13447   PRED:  13855
  Q:    2025+3260   TRUE:   5285   PRED:  55555
  Q:    8524+7403   TRUE:  15927   PRED:  15555
  Q:     980+5556   TRUE:   6536   PRED:  72655
  Q:    1911-2754   TRUE:   -843   PRED:  -1265
  Q:    1702+1297   TRUE:   2999   PRED:  35165
  Q:    6529+7415   TRUE:  13944   PRED:  13855

Epoch 04/50  |  train loss=1.6894 acc=0.3566  |  val loss=1.6623 acc=0.3645

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13485
  Q:    2565+6526   TRUE:   9091   PRED:  90108
  Q:     801-3219   TRUE:  -2418   PRED:  -2215
  Q:    3984+1770   TRUE:   5754   PRED:  57058
  Q:    3735+2615   TRUE:   6350   PRED:  65758
  Q:    5688+7759   TRUE:  13447   PRED:  13858
  Q:    2025+3260   TRUE:   5285   PRED:  54108
  Q:    8524+7403   TRUE:  15927   PRED:  15808
  Q:     980+5556   TRUE:   6536   PRED:  72108
  Q:    1911-2754   TRUE:   -843   PRED:  -1015
  Q:    1702+1297   TRUE:   2999   PRED:  30758
  Q:    6529+7415   TRUE:  13944   PRED:  14098

Epoch 05/50  |  train loss=1.6371 acc=0.3724  |  val loss=1.6141 acc=0.3769

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13222
  Q:    2565+6526   TRUE:   9091   PRED:  90222
  Q:     801-3219   TRUE:  -2418   PRED:  -2522
  Q:    3984+1770   TRUE:   5754   PRED:  55222
  Q:    3735+2615   TRUE:   6350   PRED:  62222
  Q:    5688+7759   TRUE:  13447   PRED:  13422
  Q:    2025+3260   TRUE:   5285   PRED:  52222
  Q:    8524+7403   TRUE:  15927   PRED:  15809
  Q:     980+5556   TRUE:   6536   PRED:  72222
  Q:    1911-2754   TRUE:   -843   PRED:  -1022
  Q:    1702+1297   TRUE:   2999   PRED:  32222
  Q:    6529+7415   TRUE:  13944   PRED:  14222

Epoch 06/50  |  train loss=1.5889 acc=0.3891  |  val loss=1.5637 acc=0.3960

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13008
  Q:    2565+6526   TRUE:   9091   PRED:  90108
  Q:     801-3219   TRUE:  -2418   PRED:  -2088
  Q:    3984+1770   TRUE:   5754   PRED:  58088
  Q:    3735+2615   TRUE:   6350   PRED:  63888
  Q:    5688+7759   TRUE:  13447   PRED:  13388
  Q:    2025+3260   TRUE:   5285   PRED:  52888
  Q:    8524+7403   TRUE:  15927   PRED:  15808
  Q:     980+5556   TRUE:   6536   PRED:  62888
  Q:    1911-2754   TRUE:   -843   PRED:  -1008
  Q:    1702+1297   TRUE:   2999   PRED:  30088
  Q:    6529+7415   TRUE:  13944   PRED:  13888

Epoch 07/50  |  train loss=1.5556 acc=0.3999  |  val loss=1.5560 acc=0.3960

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13187
  Q:    2565+6526   TRUE:   9091   PRED:  93307
  Q:     801-3219   TRUE:  -2418   PRED:  -2431
  Q:    3984+1770   TRUE:   5754   PRED:  60148
  Q:    3735+2615   TRUE:   6350   PRED:  64872
  Q:    5688+7759   TRUE:  13447   PRED:  13487
  Q:    2025+3260   TRUE:   5285   PRED:  52487
  Q:    8524+7403   TRUE:  15927   PRED:  16014
  Q:     980+5556   TRUE:   6536   PRED:  64872
  Q:    1911-2754   TRUE:   -843   PRED:  -1087
  Q:    1702+1297   TRUE:   2999   PRED:  32222
  Q:    6529+7415   TRUE:  13944   PRED:  14014

Epoch 08/50  |  train loss=1.5282 acc=0.4081  |  val loss=1.5191 acc=0.4081

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13012
  Q:    2565+6526   TRUE:   9091   PRED:  93114
  Q:     801-3219   TRUE:  -2418   PRED:  -2437
  Q:    3984+1770   TRUE:   5754   PRED:  57777
  Q:    3735+2615   TRUE:   6350   PRED:  63114
  Q:    5688+7759   TRUE:  13447   PRED:  13377
  Q:    2025+3260   TRUE:   5285   PRED:  52471
  Q:    8524+7403   TRUE:  15927   PRED:  15972
  Q:     980+5556   TRUE:   6536   PRED:  61147
  Q:    1911-2754   TRUE:   -843   PRED:  -1127
  Q:    1702+1297   TRUE:   2999   PRED:  32147
  Q:    6529+7415   TRUE:  13944   PRED:  14167

Epoch 09/50  |  train loss=1.5032 acc=0.4165  |  val loss=1.4959 acc=0.4144

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13000
  Q:    2565+6526   TRUE:   9091   PRED:  90277
  Q:     801-3219   TRUE:  -2418   PRED:  -2707
  Q:    3984+1770   TRUE:   5754   PRED:  55777
  Q:    3735+2615   TRUE:   6350   PRED:  62377
  Q:    5688+7759   TRUE:  13447   PRED:  13377
  Q:    2025+3260   TRUE:   5285   PRED:  50777
  Q:    8524+7403   TRUE:  15927   PRED:  15800
  Q:     980+5556   TRUE:   6536   PRED:  61877
  Q:    1911-2754   TRUE:   -843   PRED:  -1000
  Q:    1702+1297   TRUE:   2999   PRED:  29877
  Q:    6529+7415   TRUE:  13944   PRED:  14000

Epoch 10/50  |  train loss=1.4851 acc=0.4228  |  val loss=1.4857 acc=0.4185

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13011
  Q:    2565+6526   TRUE:   9091   PRED:  89114
  Q:     801-3219   TRUE:  -2418   PRED:  -2411
  Q:    3984+1770   TRUE:   5754   PRED:  57775
  Q:    3735+2615   TRUE:   6350   PRED:  61104
  Q:    5688+7759   TRUE:  13447   PRED:  13411
  Q:    2025+3260   TRUE:   5285   PRED:  51141
  Q:    8524+7403   TRUE:  15927   PRED:  16011
  Q:     980+5556   TRUE:   6536   PRED:  69111
  Q:    1911-2754   TRUE:   -843   PRED:  -1011
  Q:    1702+1297   TRUE:   2999   PRED:  30114
  Q:    6529+7415   TRUE:  13944   PRED:  14011

Epoch 11/50  |  train loss=1.4624 acc=0.4326  |  val loss=1.4717 acc=0.4198

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13222
  Q:    2565+6526   TRUE:   9091   PRED:  90257
  Q:     801-3219   TRUE:  -2418   PRED:  -2722
  Q:    3984+1770   TRUE:   5754   PRED:  57225
  Q:    3735+2615   TRUE:   6350   PRED:  61104
  Q:    5688+7759   TRUE:  13447   PRED:  13422
  Q:    2025+3260   TRUE:   5285   PRED:  50570
  Q:    8524+7403   TRUE:  15927   PRED:  15772
  Q:     980+5556   TRUE:   6536   PRED:  62955
  Q:    1911-2754   TRUE:   -843   PRED:  -7522
  Q:    1702+1297   TRUE:   2999   PRED:  32222
  Q:    6529+7415   TRUE:  13944   PRED:  14010

Epoch 12/50  |  train loss=1.4496 acc=0.4371  |  val loss=1.4477 acc=0.4368

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13009
  Q:    2565+6526   TRUE:   9091   PRED:  89955
  Q:     801-3219   TRUE:  -2418   PRED:  -2709
  Q:    3984+1770   TRUE:   5754   PRED:  59955
  Q:    3735+2615   TRUE:   6350   PRED:  65359
  Q:    5688+7759   TRUE:  13447   PRED:  13395
  Q:    2025+3260   TRUE:   5285   PRED:  53955
  Q:    8524+7403   TRUE:  15927   PRED:  15894
  Q:     980+5556   TRUE:   6536   PRED:  65355
  Q:    1911-2754   TRUE:   -843   PRED:  -8739
  Q:    1702+1297   TRUE:   2999   PRED:  30094
  Q:    6529+7415   TRUE:  13944   PRED:  13995

Epoch 13/50  |  train loss=1.4307 acc=0.4450  |  val loss=1.4334 acc=0.4409

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13207
  Q:    2565+6526   TRUE:   9091   PRED:  90118
  Q:     801-3219   TRUE:  -2418   PRED:  -2443
  Q:    3984+1770   TRUE:   5754   PRED:  55711
  Q:    3735+2615   TRUE:   6350   PRED:  63118
  Q:    5688+7759   TRUE:  13447   PRED:  13481
  Q:    2025+3260   TRUE:   5285   PRED:  52471
  Q:    8524+7403   TRUE:  15927   PRED:  15834
  Q:     980+5556   TRUE:   6536   PRED:  69181
  Q:    1911-2754   TRUE:   -843   PRED:  -1044
  Q:    1702+1297   TRUE:   2999   PRED:  29139
  Q:    6529+7415   TRUE:  13944   PRED:  14094

Epoch 14/50  |  train loss=1.4309 acc=0.4414  |  val loss=1.4137 acc=0.4518

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13207
  Q:    2565+6526   TRUE:   9091   PRED:  90118
  Q:     801-3219   TRUE:  -2418   PRED:  -2490
  Q:    3984+1770   TRUE:   5754   PRED:  57777
  Q:    3735+2615   TRUE:   6350   PRED:  63107
  Q:    5688+7759   TRUE:  13447   PRED:  13407
  Q:    2025+3260   TRUE:   5285   PRED:  52090
  Q:    8524+7403   TRUE:  15927   PRED:  15890
  Q:     980+5556   TRUE:   6536   PRED:  69000
  Q:    1911-2754   TRUE:   -843   PRED:  -8777
  Q:    1702+1297   TRUE:   2999   PRED:  30077
  Q:    6529+7415   TRUE:  13944   PRED:  14090

Epoch 15/50  |  train loss=1.4117 acc=0.4516  |  val loss=1.4146 acc=0.4476

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13000
  Q:    2565+6526   TRUE:   9091   PRED:  90169
  Q:     801-3219   TRUE:  -2418   PRED:  -2493
  Q:    3984+1770   TRUE:   5754   PRED:  58090
  Q:    3735+2615   TRUE:   6350   PRED:  64900
  Q:    5688+7759   TRUE:  13447   PRED:  13339
  Q:    2025+3260   TRUE:   5285   PRED:  52930
  Q:    8524+7403   TRUE:  15927   PRED:  15900
  Q:     980+5556   TRUE:   6536   PRED:  69930
  Q:    1911-2754   TRUE:   -843   PRED:  -8930
  Q:    1702+1297   TRUE:   2999   PRED:  30093
  Q:    6529+7415   TRUE:  13944   PRED:  13900

Epoch 16/50  |  train loss=1.3968 acc=0.4584  |  val loss=1.4013 acc=0.4564

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13077
  Q:    2565+6526   TRUE:   9091   PRED:  90167
  Q:     801-3219   TRUE:  -2418   PRED:  -2439
  Q:    3984+1770   TRUE:   5754   PRED:  57777
  Q:    3735+2615   TRUE:   6350   PRED:  63906
  Q:    5688+7759   TRUE:  13447   PRED:  13437
  Q:    2025+3260   TRUE:   5285   PRED:  52900
  Q:    8524+7403   TRUE:  15927   PRED:  15900
  Q:     980+5556   TRUE:   6536   PRED:  66067
  Q:    1911-2754   TRUE:   -843   PRED:  -8777
  Q:    1702+1297   TRUE:   2999   PRED:  30900
  Q:    6529+7415   TRUE:  13944   PRED:  14094

Epoch 17/50  |  train loss=1.3910 acc=0.4593  |  val loss=1.4021 acc=0.4505

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13055
  Q:    2565+6526   TRUE:   9091   PRED:  90828
  Q:     801-3219   TRUE:  -2418   PRED:  -2481
  Q:    3984+1770   TRUE:   5754   PRED:  58082
  Q:    3735+2615   TRUE:   6350   PRED:  64088
  Q:    5688+7759   TRUE:  13447   PRED:  13408
  Q:    2025+3260   TRUE:   5285   PRED:  52882
  Q:    8524+7403   TRUE:  15927   PRED:  15708
  Q:     980+5556   TRUE:   6536   PRED:  64888
  Q:    1911-2754   TRUE:   -843   PRED:  -9508
  Q:    1702+1297   TRUE:   2999   PRED:  30508
  Q:    6529+7415   TRUE:  13944   PRED:  14090

Epoch 18/50  |  train loss=1.3845 acc=0.4620  |  val loss=1.3927 acc=0.4505

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13011
  Q:    2565+6526   TRUE:   9091   PRED:  90118
  Q:     801-3219   TRUE:  -2418   PRED:  -2487
  Q:    3984+1770   TRUE:   5754   PRED:  57118
  Q:    3735+2615   TRUE:   6350   PRED:  62082
  Q:    5688+7759   TRUE:  13447   PRED:  13411
  Q:    2025+3260   TRUE:   5285   PRED:  51180
  Q:    8524+7403   TRUE:  15927   PRED:  15961
  Q:     980+5556   TRUE:   6536   PRED:  68167
  Q:    1911-2754   TRUE:   -843   PRED:  -8777
  Q:    1702+1297   TRUE:   2999   PRED:  30118
  Q:    6529+7415   TRUE:  13944   PRED:  13982

Epoch 19/50  |  train loss=1.3690 acc=0.4708  |  val loss=1.3849 acc=0.4583

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13001
  Q:    2565+6526   TRUE:   9091   PRED:  90105
  Q:     801-3219   TRUE:  -2418   PRED:  -2441
  Q:    3984+1770   TRUE:   5754   PRED:  57110
  Q:    3735+2615   TRUE:   6350   PRED:  61965
  Q:    5688+7759   TRUE:  13447   PRED:  13345
  Q:    2025+3260   TRUE:   5285   PRED:  52000
  Q:    8524+7403   TRUE:  15927   PRED:  15832
  Q:     980+5556   TRUE:   6536   PRED:  66100
  Q:    1911-2754   TRUE:   -843   PRED:  -8118
  Q:    1702+1297   TRUE:   2999   PRED:  30100
  Q:    6529+7415   TRUE:  13944   PRED:  13994

Epoch 20/50  |  train loss=1.3644 acc=0.4714  |  val loss=1.3845 acc=0.4554

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13122
  Q:    2565+6526   TRUE:   9091   PRED:  91100
  Q:     801-3219   TRUE:  -2418   PRED:  -2418
  Q:    3984+1770   TRUE:   5754   PRED:  56169
  Q:    3735+2615   TRUE:   6350   PRED:  63188
  Q:    5688+7759   TRUE:  13447   PRED:  13431
  Q:    2025+3260   TRUE:   5285   PRED:  52948
  Q:    8524+7403   TRUE:  15927   PRED:  15934
  Q:     980+5556   TRUE:   6536   PRED:  66948
  Q:    1911-2754   TRUE:   -843   PRED:  -8794
  Q:    1702+1297   TRUE:   2999   PRED:  30944
  Q:    6529+7415   TRUE:  13944   PRED:  14094

Epoch 21/50  |  train loss=1.3523 acc=0.4781  |  val loss=1.3861 acc=0.4568

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13094
  Q:    2565+6526   TRUE:   9091   PRED:  90944
  Q:     801-3219   TRUE:  -2418   PRED:  -2498
  Q:    3984+1770   TRUE:   5754   PRED:  58444
  Q:    3735+2615   TRUE:   6350   PRED:  64084
  Q:    5688+7759   TRUE:  13447   PRED:  13404
  Q:    2025+3260   TRUE:   5285   PRED:  54084
  Q:    8524+7403   TRUE:  15927   PRED:  15944
  Q:     980+5556   TRUE:   6536   PRED:  66655
  Q:    1911-2754   TRUE:   -843   PRED:  -8444
  Q:    1702+1297   TRUE:   2999   PRED:  30965
  Q:    6529+7415   TRUE:  13944   PRED:  13865

Epoch 22/50  |  train loss=1.3560 acc=0.4729  |  val loss=1.3663 acc=0.4673

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13055
  Q:    2565+6526   TRUE:   9091   PRED:  90167
  Q:     801-3219   TRUE:  -2418   PRED:  -2418
  Q:    3984+1770   TRUE:   5754   PRED:  57791
  Q:    3735+2615   TRUE:   6350   PRED:  63057
  Q:    5688+7759   TRUE:  13447   PRED:  13405
  Q:    2025+3260   TRUE:   5285   PRED:  52770
  Q:    8524+7403   TRUE:  15927   PRED:  15777
  Q:     980+5556   TRUE:   6536   PRED:  65777
  Q:    1911-2754   TRUE:   -843   PRED:  -9500
  Q:    1702+1297   TRUE:   2999   PRED:  31391
  Q:    6529+7415   TRUE:  13944   PRED:  13994

Epoch 23/50  |  train loss=1.3483 acc=0.4776  |  val loss=1.3757 acc=0.4569

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13094
  Q:    2565+6526   TRUE:   9091   PRED:  90149
  Q:     801-3219   TRUE:  -2418   PRED:  -2594
  Q:    3984+1770   TRUE:   5754   PRED:  55717
  Q:    3735+2615   TRUE:   6350   PRED:  63044
  Q:    5688+7759   TRUE:  13447   PRED:  13404
  Q:    2025+3260   TRUE:   5285   PRED:  52094
  Q:    8524+7403   TRUE:  15927   PRED:  15830
  Q:     980+5556   TRUE:   6536   PRED:  64994
  Q:    1911-2754   TRUE:   -843   PRED:  -8439
  Q:    1702+1297   TRUE:   2999   PRED:  30399
  Q:    6529+7415   TRUE:  13944   PRED:  13994

Epoch 24/50  |  train loss=1.3368 acc=0.4834  |  val loss=1.3622 acc=0.4639

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13209
  Q:    2565+6526   TRUE:   9091   PRED:  92879
  Q:     801-3219   TRUE:  -2418   PRED:  -2499
  Q:    3984+1770   TRUE:   5754   PRED:  57799
  Q:    3735+2615   TRUE:   6350   PRED:  64047
  Q:    5688+7759   TRUE:  13447   PRED:  13500
  Q:    2025+3260   TRUE:   5285   PRED:  53099
  Q:    8524+7403   TRUE:  15927   PRED:  15965
  Q:     980+5556   TRUE:   6536   PRED:  66999
  Q:    1911-2754   TRUE:   -843   PRED:  -8240
  Q:    1702+1297   TRUE:   2999   PRED:  29650
  Q:    6529+7415   TRUE:  13944   PRED:  14090

Epoch 25/50  |  train loss=1.3303 acc=0.4860  |  val loss=1.3377 acc=0.4814

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13094
  Q:    2565+6526   TRUE:   9091   PRED:  90945
  Q:     801-3219   TRUE:  -2418   PRED:  -2442
  Q:    3984+1770   TRUE:   5754   PRED:  56605
  Q:    3735+2615   TRUE:   6350   PRED:  64265
  Q:    5688+7759   TRUE:  13447   PRED:  13498
  Q:    2025+3260   TRUE:   5285   PRED:  52955
  Q:    8524+7403   TRUE:  15927   PRED:  15932
  Q:     980+5556   TRUE:   6536   PRED:  66695
  Q:    1911-2754   TRUE:   -843   PRED:  -7452
  Q:    1702+1297   TRUE:   2999   PRED:  30565
  Q:    6529+7415   TRUE:  13944   PRED:  13994

Epoch 26/50  |  train loss=1.3270 acc=0.4869  |  val loss=1.3476 acc=0.4740

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13191
  Q:    2565+6526   TRUE:   9091   PRED:  90177
  Q:     801-3219   TRUE:  -2418   PRED:  -2418
  Q:    3984+1770   TRUE:   5754   PRED:  57177
  Q:    3735+2615   TRUE:   6350   PRED:  63917
  Q:    5688+7759   TRUE:  13447   PRED:  13477
  Q:    2025+3260   TRUE:   5285   PRED:  52770
  Q:    8524+7403   TRUE:  15927   PRED:  15877
  Q:     980+5556   TRUE:   6536   PRED:  66357
  Q:    1911-2754   TRUE:   -843   PRED:  -9777
  Q:    1702+1297   TRUE:   2999   PRED:  30277
  Q:    6529+7415   TRUE:  13944   PRED:  14017

Epoch 27/50  |  train loss=1.3234 acc=0.4878  |  val loss=1.3420 acc=0.4775

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13091
  Q:    2565+6526   TRUE:   9091   PRED:  91110
  Q:     801-3219   TRUE:  -2418   PRED:  -2441
  Q:    3984+1770   TRUE:   5754   PRED:  57745
  Q:    3735+2615   TRUE:   6350   PRED:  64918
  Q:    5688+7759   TRUE:  13447   PRED:  13477
  Q:    2025+3260   TRUE:   5285   PRED:  52000
  Q:    8524+7403   TRUE:  15927   PRED:  15899
  Q:     980+5556   TRUE:   6536   PRED:  66770
  Q:    1911-2754   TRUE:   -843   PRED:  -8745
  Q:    1702+1297   TRUE:   2999   PRED:  29167
  Q:    6529+7415   TRUE:  13944   PRED:  13994

Epoch 28/50  |  train loss=1.3168 acc=0.4908  |  val loss=1.3276 acc=0.4844

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13194
  Q:    2565+6526   TRUE:   9091   PRED:  90941
  Q:     801-3219   TRUE:  -2418   PRED:  -2441
  Q:    3984+1770   TRUE:   5754   PRED:  57799
  Q:    3735+2615   TRUE:   6350   PRED:  63999
  Q:    5688+7759   TRUE:  13447   PRED:  13497
  Q:    2025+3260   TRUE:   5285   PRED:  52000
  Q:    8524+7403   TRUE:  15927   PRED:  15930
  Q:     980+5556   TRUE:   6536   PRED:  66777
  Q:    1911-2754   TRUE:   -843   PRED:  -9307
  Q:    1702+1297   TRUE:   2999   PRED:  30999
  Q:    6529+7415   TRUE:  13944   PRED:  14000

Epoch 29/50  |  train loss=1.3120 acc=0.4929  |  val loss=1.3519 acc=0.4666

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  12987
  Q:    2565+6526   TRUE:   9091   PRED:  91100
  Q:     801-3219   TRUE:  -2418   PRED:  -2445
  Q:    3984+1770   TRUE:   5754   PRED:  57748
  Q:    3735+2615   TRUE:   6350   PRED:  64377
  Q:    5688+7759   TRUE:  13447   PRED:  13477
  Q:    2025+3260   TRUE:   5285   PRED:  53774
  Q:    8524+7403   TRUE:  15927   PRED:  15837
  Q:     980+5556   TRUE:   6536   PRED:  66770
  Q:    1911-2754   TRUE:   -843   PRED:  -7745
  Q:    1702+1297   TRUE:   2999   PRED:  31167
  Q:    6529+7415   TRUE:  13944   PRED:  13994

Epoch 30/50  |  train loss=1.3047 acc=0.4960  |  val loss=1.3326 acc=0.4802

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13055
  Q:    2565+6526   TRUE:   9091   PRED:  90824
  Q:     801-3219   TRUE:  -2418   PRED:  -2682
  Q:    3984+1770   TRUE:   5754   PRED:  58026
  Q:    3735+2615   TRUE:   6350   PRED:  63988
  Q:    5688+7759   TRUE:  13447   PRED:  13406
  Q:    2025+3260   TRUE:   5285   PRED:  52302
  Q:    8524+7403   TRUE:  15927   PRED:  15882
  Q:     980+5556   TRUE:   6536   PRED:  66686
  Q:    1911-2754   TRUE:   -843   PRED:  -8828
  Q:    1702+1297   TRUE:   2999   PRED:  30268
  Q:    6529+7415   TRUE:  13944   PRED:  13855

Epoch 31/50  |  train loss=1.3007 acc=0.4985  |  val loss=1.3269 acc=0.4823

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13200
  Q:    2565+6526   TRUE:   9091   PRED:  91052
  Q:     801-3219   TRUE:  -2418   PRED:  -2490
  Q:    3984+1770   TRUE:   5754   PRED:  56799
  Q:    3735+2615   TRUE:   6350   PRED:  63049
  Q:    5688+7759   TRUE:  13447   PRED:  13339
  Q:    2025+3260   TRUE:   5285   PRED:  52000
  Q:    8524+7403   TRUE:  15927   PRED:  15900
  Q:     980+5556   TRUE:   6536   PRED:  64995
  Q:    1911-2754   TRUE:   -843   PRED:  -7100
  Q:    1702+1297   TRUE:   2999   PRED:  31990
  Q:    6529+7415   TRUE:  13944   PRED:  13850

Epoch 32/50  |  train loss=1.2984 acc=0.4989  |  val loss=1.3234 acc=0.4821

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13118
  Q:    2565+6526   TRUE:   9091   PRED:  91839
  Q:     801-3219   TRUE:  -2418   PRED:  -2593
  Q:    3984+1770   TRUE:   5754   PRED:  57799
  Q:    3735+2615   TRUE:   6350   PRED:  63999
  Q:    5688+7759   TRUE:  13447   PRED:  13419
  Q:    2025+3260   TRUE:   5285   PRED:  53757
  Q:    8524+7403   TRUE:  15927   PRED:  15937
  Q:     980+5556   TRUE:   6536   PRED:  64565
  Q:    1911-2754   TRUE:   -843   PRED:  -8999
  Q:    1702+1297   TRUE:   2999   PRED:  30999
  Q:    6529+7415   TRUE:  13944   PRED:  13909

Epoch 33/50  |  train loss=1.2921 acc=0.5015  |  val loss=1.3341 acc=0.4766

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13118
  Q:    2565+6526   TRUE:   9091   PRED:  91830
  Q:     801-3219   TRUE:  -2418   PRED:  -2455
  Q:    3984+1770   TRUE:   5754   PRED:  57855
  Q:    3735+2615   TRUE:   6350   PRED:  63995
  Q:    5688+7759   TRUE:  13447   PRED:  13431
  Q:    2025+3260   TRUE:   5285   PRED:  53535
  Q:    8524+7403   TRUE:  15927   PRED:  15935
  Q:     980+5556   TRUE:   6536   PRED:  66635
  Q:    1911-2754   TRUE:   -843   PRED:  -8934
  Q:    1702+1297   TRUE:   2999   PRED:  30398
  Q:    6529+7415   TRUE:  13944   PRED:  13965

Epoch 34/50  |  train loss=1.2865 acc=0.5039  |  val loss=1.3126 acc=0.4867

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13118
  Q:    2565+6526   TRUE:   9091   PRED:  91804
  Q:     801-3219   TRUE:  -2418   PRED:  -2345
  Q:    3984+1770   TRUE:   5754   PRED:  57900
  Q:    3735+2615   TRUE:   6350   PRED:  64377
  Q:    5688+7759   TRUE:  13447   PRED:  13476
  Q:    2025+3260   TRUE:   5285   PRED:  53616
  Q:    8524+7403   TRUE:  15927   PRED:  15894
  Q:     980+5556   TRUE:   6536   PRED:  64664
  Q:    1911-2754   TRUE:   -843   PRED:  -8944
  Q:    1702+1297   TRUE:   2999   PRED:  30266
  Q:    6529+7415   TRUE:  13944   PRED:  13917

Epoch 35/50  |  train loss=1.2914 acc=0.5019  |  val loss=1.3133 acc=0.4883

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13099
  Q:    2565+6526   TRUE:   9091   PRED:  90180
  Q:     801-3219   TRUE:  -2418   PRED:  -2610
  Q:    3984+1770   TRUE:   5754   PRED:  57770
  Q:    3735+2615   TRUE:   6350   PRED:  63071
  Q:    5688+7759   TRUE:  13447   PRED:  13499
  Q:    2025+3260   TRUE:   5285   PRED:  52000
  Q:    8524+7403   TRUE:  15927   PRED:  15967
  Q:     980+5556   TRUE:   6536   PRED:  66777
  Q:    1911-2754   TRUE:   -843   PRED:  -8998
  Q:    1702+1297   TRUE:   2999   PRED:  30910
  Q:    6529+7415   TRUE:  13944   PRED:  14011

Epoch 36/50  |  train loss=1.2815 acc=0.5070  |  val loss=1.3028 acc=0.4934

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13096
  Q:    2565+6526   TRUE:   9091   PRED:  91830
  Q:     801-3219   TRUE:  -2418   PRED:  -2493
  Q:    3984+1770   TRUE:   5754   PRED:  56260
  Q:    3735+2615   TRUE:   6350   PRED:  63307
  Q:    5688+7759   TRUE:  13447   PRED:  13506
  Q:    2025+3260   TRUE:   5285   PRED:  52900
  Q:    8524+7403   TRUE:  15927   PRED:  15966
  Q:     980+5556   TRUE:   6536   PRED:  66635
  Q:    1911-2754   TRUE:   -843   PRED:  -8339
  Q:    1702+1297   TRUE:   2999   PRED:  30360
  Q:    6529+7415   TRUE:  13944   PRED:  14094

Epoch 37/50  |  train loss=1.2771 acc=0.5080  |  val loss=1.3034 acc=0.4906

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13022
  Q:    2565+6526   TRUE:   9091   PRED:  91102
  Q:     801-3219   TRUE:  -2418   PRED:  -2452
  Q:    3984+1770   TRUE:   5754   PRED:  56237
  Q:    3735+2615   TRUE:   6350   PRED:  63486
  Q:    5688+7759   TRUE:  13447   PRED:  13492
  Q:    2025+3260   TRUE:   5285   PRED:  52592
  Q:    8524+7403   TRUE:  15927   PRED:  15894
  Q:     980+5556   TRUE:   6536   PRED:  66169
  Q:    1911-2754   TRUE:   -843   PRED:  -8934
  Q:    1702+1297   TRUE:   2999   PRED:  29552
  Q:    6529+7415   TRUE:  13944   PRED:  14036

Epoch 38/50  |  train loss=1.2734 acc=0.5100  |  val loss=1.3005 acc=0.4947

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13096
  Q:    2565+6526   TRUE:   9091   PRED:  91082
  Q:     801-3219   TRUE:  -2418   PRED:  -2652
  Q:    3984+1770   TRUE:   5754   PRED:  57720
  Q:    3735+2615   TRUE:   6350   PRED:  63770
  Q:    5688+7759   TRUE:  13447   PRED:  13476
  Q:    2025+3260   TRUE:   5285   PRED:  52000
  Q:    8524+7403   TRUE:  15927   PRED:  15966
  Q:     980+5556   TRUE:   6536   PRED:  66635
  Q:    1911-2754   TRUE:   -843   PRED:  -8230
  Q:    1702+1297   TRUE:   2999   PRED:  30377
  Q:    6529+7415   TRUE:  13944   PRED:  14036

Epoch 39/50  |  train loss=1.2783 acc=0.5066  |  val loss=1.3347 acc=0.4745

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13001
  Q:    2565+6526   TRUE:   9091   PRED:  90048
  Q:     801-3219   TRUE:  -2418   PRED:  -2739
  Q:    3984+1770   TRUE:   5754   PRED:  57200
  Q:    3735+2615   TRUE:   6350   PRED:  63398
  Q:    5688+7759   TRUE:  13447   PRED:  13439
  Q:    2025+3260   TRUE:   5285   PRED:  52000
  Q:    8524+7403   TRUE:  15927   PRED:  15966
  Q:     980+5556   TRUE:   6536   PRED:  66639
  Q:    1911-2754   TRUE:   -843   PRED:  -1048
  Q:    1702+1297   TRUE:   2999   PRED:  28600
  Q:    6529+7415   TRUE:  13944   PRED:  13989

Epoch 40/50  |  train loss=1.2678 acc=0.5115  |  val loss=1.3164 acc=0.4803

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13209
  Q:    2565+6526   TRUE:   9091   PRED:  91100
  Q:     801-3219   TRUE:  -2418   PRED:  -2451
  Q:    3984+1770   TRUE:   5754   PRED:  57624
  Q:    3735+2615   TRUE:   6350   PRED:  64304
  Q:    5688+7759   TRUE:  13447   PRED:  13498
  Q:    2025+3260   TRUE:   5285   PRED:  52909
  Q:    8524+7403   TRUE:  15927   PRED:  15966
  Q:     980+5556   TRUE:   6536   PRED:  66696
  Q:    1911-2754   TRUE:   -843   PRED:  -9309
  Q:    1702+1297   TRUE:   2999   PRED:  29169
  Q:    6529+7415   TRUE:  13944   PRED:  14006

Epoch 41/50  |  train loss=1.2607 acc=0.5155  |  val loss=1.2989 acc=0.4943

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13098
  Q:    2565+6526   TRUE:   9091   PRED:  90044
  Q:     801-3219   TRUE:  -2418   PRED:  -2490
  Q:    3984+1770   TRUE:   5754   PRED:  57200
  Q:    3735+2615   TRUE:   6350   PRED:  64047
  Q:    5688+7759   TRUE:  13447   PRED:  13476
  Q:    2025+3260   TRUE:   5285   PRED:  52900
  Q:    8524+7403   TRUE:  15927   PRED:  15967
  Q:     980+5556   TRUE:   6536   PRED:  66044
  Q:    1911-2754   TRUE:   -843   PRED:  -9700
  Q:    1702+1297   TRUE:   2999   PRED:  29189
  Q:    6529+7415   TRUE:  13944   PRED:  13989

Epoch 42/50  |  train loss=1.2595 acc=0.5160  |  val loss=1.2747 acc=0.5084

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13098
  Q:    2565+6526   TRUE:   9091   PRED:  90988
  Q:     801-3219   TRUE:  -2418   PRED:  -2451
  Q:    3984+1770   TRUE:   5754   PRED:  58087
  Q:    3735+2615   TRUE:   6350   PRED:  63775
  Q:    5688+7759   TRUE:  13447   PRED:  13476
  Q:    2025+3260   TRUE:   5285   PRED:  52860
  Q:    8524+7403   TRUE:  15927   PRED:  15966
  Q:     980+5556   TRUE:   6536   PRED:  65655
  Q:    1911-2754   TRUE:   -843   PRED:  -8235
  Q:    1702+1297   TRUE:   2999   PRED:  29555
  Q:    6529+7415   TRUE:  13944   PRED:  13987

Epoch 43/50  |  train loss=1.2627 acc=0.5138  |  val loss=1.2918 acc=0.4969

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13240
  Q:    2565+6526   TRUE:   9091   PRED:  91104
  Q:     801-3219   TRUE:  -2418   PRED:  -2494
  Q:    3984+1770   TRUE:   5754   PRED:  56266
  Q:    3735+2615   TRUE:   6350   PRED:  63406
  Q:    5688+7759   TRUE:  13447   PRED:  13439
  Q:    2025+3260   TRUE:   5285   PRED:  50464
  Q:    8524+7403   TRUE:  15927   PRED:  16037
  Q:     980+5556   TRUE:   6536   PRED:  66666
  Q:    1911-2754   TRUE:   -843   PRED:  -8122
  Q:    1702+1297   TRUE:   2999   PRED:  29555
  Q:    6529+7415   TRUE:  13944   PRED:  13954

Epoch 44/50  |  train loss=1.2544 acc=0.5177  |  val loss=1.2875 acc=0.5003

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13096
  Q:    2565+6526   TRUE:   9091   PRED:  91130
  Q:     801-3219   TRUE:  -2418   PRED:  -2439
  Q:    3984+1770   TRUE:   5754   PRED:  57228
  Q:    3735+2615   TRUE:   6350   PRED:  63338
  Q:    5688+7759   TRUE:  13447   PRED:  13383
  Q:    2025+3260   TRUE:   5285   PRED:  52305
  Q:    8524+7403   TRUE:  15927   PRED:  15933
  Q:     980+5556   TRUE:   6536   PRED:  66635
  Q:    1911-2754   TRUE:   -843   PRED:  -8338
  Q:    1702+1297   TRUE:   2999   PRED:  30398
  Q:    6529+7415   TRUE:  13944   PRED:  13983

Epoch 45/50  |  train loss=1.2469 acc=0.5214  |  val loss=1.3088 acc=0.4831

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13073
  Q:    2565+6526   TRUE:   9091   PRED:  91100
  Q:     801-3219   TRUE:  -2418   PRED:  -2451
  Q:    3984+1770   TRUE:   5754   PRED:  57572
  Q:    3735+2615   TRUE:   6350   PRED:  63375
  Q:    5688+7759   TRUE:  13447   PRED:  13400
  Q:    2025+3260   TRUE:   5285   PRED:  52750
  Q:    8524+7403   TRUE:  15927   PRED:  15873
  Q:     980+5556   TRUE:   6536   PRED:  66673
  Q:    1911-2754   TRUE:   -843   PRED:  -7795
  Q:    1702+1297   TRUE:   2999   PRED:  30375
  Q:    6529+7415   TRUE:  13944   PRED:  13850

Epoch 46/50  |  train loss=1.2503 acc=0.5187  |  val loss=1.2850 acc=0.4962

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13091
  Q:    2565+6526   TRUE:   9091   PRED:  90169
  Q:     801-3219   TRUE:  -2418   PRED:  -2451
  Q:    3984+1770   TRUE:   5754   PRED:  55901
  Q:    3735+2615   TRUE:   6350   PRED:  63046
  Q:    5688+7759   TRUE:  13447   PRED:  13476
  Q:    2025+3260   TRUE:   5285   PRED:  52060
  Q:    8524+7403   TRUE:  15927   PRED:  15901
  Q:     980+5556   TRUE:   6536   PRED:  66666
  Q:    1911-2754   TRUE:   -843   PRED:  -7596
  Q:    1702+1297   TRUE:   2999   PRED:  30398
  Q:    6529+7415   TRUE:  13944   PRED:  13984

Epoch 47/50  |  train loss=1.2419 acc=0.5238  |  val loss=1.2826 acc=0.5018

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13096
  Q:    2565+6526   TRUE:   9091   PRED:  91105
  Q:     801-3219   TRUE:  -2418   PRED:  -2559
  Q:    3984+1770   TRUE:   5754   PRED:  57209
  Q:    3735+2615   TRUE:   6350   PRED:  63777
  Q:    5688+7759   TRUE:  13447   PRED:  13476
  Q:    2025+3260   TRUE:   5285   PRED:  52416
  Q:    8524+7403   TRUE:  15927   PRED:  15877
  Q:     980+5556   TRUE:   6536   PRED:  66169
  Q:    1911-2754   TRUE:   -843   PRED:  -8242
  Q:    1702+1297   TRUE:   2999   PRED:  29189
  Q:    6529+7415   TRUE:  13944   PRED:  13969

Epoch 48/50  |  train loss=1.2455 acc=0.5219  |  val loss=1.3041 acc=0.4920

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13096
  Q:    2565+6526   TRUE:   9091   PRED:  90655
  Q:     801-3219   TRUE:  -2418   PRED:  -2453
  Q:    3984+1770   TRUE:   5754   PRED:  57850
  Q:    3735+2615   TRUE:   6350   PRED:  63775
  Q:    5688+7759   TRUE:  13447   PRED:  13499
  Q:    2025+3260   TRUE:   5285   PRED:  52753
  Q:    8524+7403   TRUE:  15927   PRED:  15901
  Q:     980+5556   TRUE:   6536   PRED:  64995
  Q:    1911-2754   TRUE:   -843   PRED:  -8337
  Q:    1702+1297   TRUE:   2999   PRED:  30377
  Q:    6529+7415   TRUE:  13944   PRED:  14093

Epoch 49/50  |  train loss=1.2396 acc=0.5240  |  val loss=1.3154 acc=0.4870

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13096
  Q:    2565+6526   TRUE:   9091   PRED:  91144
  Q:     801-3219   TRUE:  -2418   PRED:  -2551
  Q:    3984+1770   TRUE:   5754   PRED:  57216
  Q:    3735+2615   TRUE:   6350   PRED:  63994
  Q:    5688+7759   TRUE:  13447   PRED:  13499
  Q:    2025+3260   TRUE:   5285   PRED:  52022
  Q:    8524+7403   TRUE:  15927   PRED:  15802
  Q:     980+5556   TRUE:   6536   PRED:  64864
  Q:    1911-2754   TRUE:   -843   PRED:  -8167
  Q:    1702+1297   TRUE:   2999   PRED:  30360
  Q:    6529+7415   TRUE:  13944   PRED:  13984

Epoch 50/50  |  train loss=1.2388 acc=0.5258  |  val loss=1.2732 acc=0.5077

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13091
  Q:    2565+6526   TRUE:   9091   PRED:  91100
  Q:     801-3219   TRUE:  -2418   PRED:  -2442
  Q:    3984+1770   TRUE:   5754   PRED:  57799
  Q:    3735+2615   TRUE:   6350   PRED:  64286
  Q:    5688+7759   TRUE:  13447   PRED:  13418
  Q:    2025+3260   TRUE:   5285   PRED:  52750
  Q:    8524+7403   TRUE:  15927   PRED:  15899
  Q:     980+5556   TRUE:   6536   PRED:  65695
  Q:    1911-2754   TRUE:   -843   PRED:  -8122
  Q:    1702+1297   TRUE:   2999   PRED:  29100
  Q:    6529+7415   TRUE:  13944   PRED:  13944

Final sanity check (greedy):
Q:       54-7   PRED:  77733
Q:      10+20   PRED:  15942
Q:  9999+9999   PRED:  19744
Q:     0-9999   PRED:  -9962
Q:  1234-9999   PRED:  -8733
Q:    777+888   PRED:  16944
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.2</p>
<p>a) Overall, the model does not perform well on the task.
Although the training loss decreases and the token-level accuracy improves, the model rarely produces completely correct answers. Most predictions are only partially correct (some digits match, but the final number is wrong), which means the exact-match accuracy is very low.</p>
<p></p>
<p>b) The main limitations are:
	The model does not truly learn arithmetic rules such as carry and borrow; it only learns statistical patterns over characters.
	There is a gap between training and inference because of teacher forcing.
	The encoder compresses the entire input into a single hidden state, which limits its ability to handle longer sequences.
	Greedy decoding makes early mistakes hard to recover from.</p>
<p></p>
<p>c) I would:
	Use curriculum learning (start with fewer digits and gradually increase).
	Reverse the input sequence to reduce long-range dependencies.
	Reduce teacher forcing over time.
	Increase model capacity or switch to a more suitable architecture such as a Transformer.</p>
<p></p>
<p>d)
Yes.
Adding attention would allow the decoder to focus on relevant parts of the input instead of relying on a single encoder state. This would likely improve performance, although it still may not fully solve the arithmetic reasoning problem.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">"""Seq2Seq Arithmetic (PyTorch)  Attention Only (Bahdanau/additive)</span>

<span class="sd">Task:</span>
<span class="sd">  Input:  string like "54-7" or "10+20" (operands up to `config['digits']` digits)</span>
<span class="sd">  Output: string answer like "47" or "30" (string, padded)</span>

<span class="sd">Model:</span>
<span class="sd">  LSTM encoderdecoder WITH additive attention (Bahdanau-style)</span>

<span class="sd">Evaluation:</span>
<span class="sd">  - token accuracy (ignoring PAD)</span>
<span class="sd">  - exact-match accuracy (full output string must match)</span>
<span class="sd">"""</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Read required params from notebook-provided config</span>
<span class="c1"># -----------------------------</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"seed"</span><span class="p">,</span> <span class="mi">123</span><span class="p">))</span>
<span class="n">TRAIN_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">])</span>  <span class="c1"># e.g., 40000</span>
<span class="n">VAL_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"val_size"</span><span class="p">,</span> <span class="mi">10000</span><span class="p">))</span>
<span class="n">DIGITS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">])</span>             <span class="c1"># e.g., 4</span>
<span class="n">HIDDEN_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"hidden_size"</span><span class="p">])</span>   <span class="c1"># e.g., 128</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">])</span>     <span class="c1"># e.g., 128</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"iterations"</span><span class="p">],</span> <span class="mi">50</span><span class="p">))</span>  <span class="c1"># cap at 50</span>

<span class="c1"># optional knobs</span>
<span class="n">EMB_DIM</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"emb_dim"</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
<span class="n">LR</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"lr"</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">))</span>
<span class="n">PRINT_SAMPLES</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"print_samples"</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>

<span class="c1"># reproducibility</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Task constants</span>
<span class="c1"># -----------------------------</span>
<span class="n">MAX_INT</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">DIGITS</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">MAX_QUERY_LEN</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">DIGITS</span> <span class="o">+</span> <span class="mi">1</span>   <span class="c1"># e.g., "9999+9999" length 9</span>
<span class="n">MAX_ANS_LEN</span> <span class="o">=</span> <span class="n">DIGITS</span> <span class="o">+</span> <span class="mi">1</span>         <span class="c1"># e.g., "19998" len 5 OR "-9999" len 5</span>

<span class="n">PAD</span> <span class="o">=</span> <span class="s2">" "</span>
<span class="n">SOS</span> <span class="o">=</span> <span class="s2">"^"</span>  <span class="c1"># start token (internal)</span>

<span class="c1"># Use the notebook's chars and add SOS internally</span>
<span class="n">CHARS</span> <span class="o">=</span> <span class="n">chars</span> <span class="o">+</span> <span class="n">SOS</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Vocab</span>
<span class="c1"># -----------------------------</span>
<span class="k">class</span> <span class="nc">CharVocab</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chars_</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chars</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">chars_</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">itos</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">c</span> <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">PAD</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sos_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">SOS</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">s</span><span class="p">[:</span><span class="n">maxlen</span><span class="p">]]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">maxlen</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">maxlen</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">)</span>


<span class="n">vocab</span> <span class="o">=</span> <span class="n">CharVocab</span><span class="p">(</span><span class="n">CHARS</span><span class="p">)</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Dataset</span>
<span class="c1"># -----------------------------</span>
<span class="k">class</span> <span class="nc">ArithmeticSeq2SeqDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Returns (x, dec_in, y) as index tensors.</span>

<span class="sd">    x:      (T_in,) query</span>
<span class="sd">    dec_in: (T_out,) decoder input = SOS + y[:-1]</span>
<span class="sd">    y:      (T_out,) target</span>

<span class="sd">    Loss ignores PAD positions.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">questions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">answers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">seen</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">questions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">MAX_INT</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">b</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">MAX_INT</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">op</span> <span class="o">=</span> <span class="s2">"+"</span> <span class="k">if</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="s2">"-"</span>

            <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>  <span class="c1"># do NOT sort</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">seen</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

            <span class="n">ans</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="s2">"+"</span> <span class="k">else</span> <span class="n">a</span> <span class="o">-</span> <span class="n">b</span>
            <span class="n">q</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">a</span><span class="si">}{</span><span class="n">op</span><span class="si">}{</span><span class="n">b</span><span class="si">}</span><span class="s2">"</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">MAX_QUERY_LEN</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">MAX_ANS_LEN</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">questions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">answers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">questions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">answers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">MAX_QUERY_LEN</span><span class="p">)</span>
        <span class="n">y_tgt</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">MAX_ANS_LEN</span><span class="p">)</span>

        <span class="n">dec_in_str</span> <span class="o">=</span> <span class="p">(</span><span class="n">SOS</span> <span class="o">+</span> <span class="n">y</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">MAX_ANS_LEN</span><span class="p">)</span>
        <span class="n">dec_in</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">dec_in_str</span><span class="p">,</span> <span class="n">MAX_ANS_LEN</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">,</span> <span class="n">y_tgt</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Metrics</span>
<span class="c1"># -----------------------------</span>
<span class="k">def</span> <span class="nf">token_acc_ignore_pad</span><span class="p">(</span><span class="n">pred</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">pad_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">!=</span> <span class="n">pad_idx</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
    <span class="k">return</span> <span class="p">(((</span><span class="n">pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="o">/</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">exact_match_rate</span><span class="p">(</span><span class="n">pred</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">pad_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Exact match on the full answer string (ignoring PAD at the end).</span>

<span class="sd">    pred,y: (B,T)</span>
<span class="sd">    We compare after trimming trailing PAD from the TRUE sequence length.</span>
<span class="sd">    """</span>
    <span class="n">B</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="n">true_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">pad_idx</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">true_mask</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="n">L</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">true_mask</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">L</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">L</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">L</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">L</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">B</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">print_samples</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">ArithmeticSeq2SeqDataset</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">SEED</span> <span class="o">+</span> <span class="mi">999</span><span class="p">)</span>
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">xs</span><span class="p">,</span> <span class="n">qs</span><span class="p">,</span> <span class="n">ys_true</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idxs</span><span class="p">:</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">questions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">answers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">MAX_QUERY_LEN</span><span class="p">))</span>
        <span class="n">qs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
        <span class="n">ys_true</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>

    <span class="n">x_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">y_pred_idx</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">greedy_decode</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">MAX_ANS_LEN</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Samples from validation (greedy decode)"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"="</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">q</span><span class="p">,</span> <span class="n">y_t</span><span class="p">,</span> <span class="n">y_p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">ys_true</span><span class="p">,</span> <span class="n">y_pred_idx</span><span class="p">):</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">y_p</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">SOS</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">ok</span> <span class="o">=</span> <span class="s2">""</span> <span class="k">if</span> <span class="n">pred</span> <span class="o">==</span> <span class="n">y_t</span> <span class="k">else</span> <span class="s2">""</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">ok</span><span class="si">}</span><span class="s2">  Q: </span><span class="si">{</span><span class="n">q</span><span class="si">:</span><span class="s2">&gt;12</span><span class="si">}</span><span class="s2">   TRUE: </span><span class="si">{</span><span class="n">y_t</span><span class="si">:</span><span class="s2">&gt;6</span><span class="si">}</span><span class="s2">   PRED: </span><span class="si">{</span><span class="n">pred</span><span class="si">:</span><span class="s2">&gt;6</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Attention model (Bahdanau additive attention)</span>
<span class="c1"># -----------------------------</span>
<span class="k">class</span> <span class="nc">AdditiveAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_enc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_dec</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_out</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dec_h</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Compute context vector.</span>

<span class="sd">        enc_out: (B, T_in, H)</span>
<span class="sd">        dec_h:   (B, H)</span>
<span class="sd">        returns context: (B, H)</span>
<span class="sd">        """</span>
        <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_enc</span><span class="p">(</span><span class="n">enc_out</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_dec</span><span class="p">(</span><span class="n">dec_h</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>  <span class="c1"># (B,T,1)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">score</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>                                  <span class="c1"># (B,T)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">alpha</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">enc_out</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>                       <span class="c1"># (B,H)</span>
        <span class="k">return</span> <span class="n">context</span>


<span class="k">class</span> <span class="nc">Seq2SeqLSTMAttn</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_cell</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">emb_dim</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">AdditiveAttention</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">+</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>  <span class="c1"># [dec_h ; context]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Teacher-forcing forward.</span>

<span class="sd">        x: (B,T_in), dec_in: (B,T_out)</span>
<span class="sd">        returns logits: (B,T_out,V)</span>
<span class="sd">        """</span>
        <span class="n">x_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">enc_out</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x_emb</span><span class="p">)</span>  <span class="c1"># enc_out: (B,T_in,H)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">T_out</span> <span class="o">=</span> <span class="n">dec_in</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">logits_all</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">h_t</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (B,H)</span>
        <span class="n">c_t</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (B,H)</span>

        <span class="n">dec_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">dec_in</span><span class="p">)</span>  <span class="c1"># (B,T_out,E)</span>

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T_out</span><span class="p">):</span>
            <span class="n">h_t</span><span class="p">,</span> <span class="n">c_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_cell</span><span class="p">(</span><span class="n">dec_emb</span><span class="p">[:,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:],</span> <span class="p">(</span><span class="n">h_t</span><span class="p">,</span> <span class="n">c_t</span><span class="p">))</span>
            <span class="n">ctx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">enc_out</span><span class="p">,</span> <span class="n">h_t</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">h_t</span><span class="p">,</span> <span class="n">ctx</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">logits_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">logits_all</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">greedy_decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">x_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">enc_out</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x_emb</span><span class="p">)</span>

        <span class="n">B</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">B</span><span class="p">,</span> <span class="n">max_len</span><span class="p">),</span> <span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">h_t</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">c_t</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">B</span><span class="p">,),</span> <span class="n">vocab</span><span class="o">.</span><span class="n">sos_idx</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">):</span>
            <span class="n">prev_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">prev</span><span class="p">)</span>
            <span class="n">h_t</span><span class="p">,</span> <span class="n">c_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_cell</span><span class="p">(</span><span class="n">prev_emb</span><span class="p">,</span> <span class="p">(</span><span class="n">h_t</span><span class="p">,</span> <span class="n">c_t</span><span class="p">))</span>
            <span class="n">ctx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">enc_out</span><span class="p">,</span> <span class="n">h_t</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">h_t</span><span class="p">,</span> <span class="n">ctx</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="n">next_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">next_idx</span>
            <span class="n">prev</span> <span class="o">=</span> <span class="n">next_idx</span>

        <span class="k">return</span> <span class="n">y_pred</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Train &amp; eval</span>
<span class="c1"># -----------------------------</span>
<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">)</span>

    <span class="n">total_loss</span><span class="p">,</span> <span class="n">total_tok</span><span class="p">,</span> <span class="n">total_em</span><span class="p">,</span> <span class="n">n_batches</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">dec_in</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">total_tok</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">token_acc_ignore_pad</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">))</span>
        <span class="n">total_em</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">exact_match_rate</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">))</span>
        <span class="n">n_batches</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">total_tok</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">total_em</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">val_ds</span><span class="p">:</span> <span class="n">ArithmeticSeq2SeqDataset</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">===== Training: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> ====="</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">run_loss</span><span class="p">,</span> <span class="n">run_tok</span><span class="p">,</span> <span class="n">run_em</span><span class="p">,</span> <span class="n">n_batches</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">dec_in</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">run_loss</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">run_tok</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">token_acc_ignore_pad</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">))</span>
            <span class="n">run_em</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">exact_match_rate</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">))</span>
            <span class="n">n_batches</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">tr_loss</span> <span class="o">=</span> <span class="n">run_loss</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">tr_tok</span> <span class="o">=</span> <span class="n">run_tok</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">tr_em</span> <span class="o">=</span> <span class="n">run_em</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">va_loss</span><span class="p">,</span> <span class="n">va_tok</span><span class="p">,</span> <span class="n">va_em</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">EPOCHS</span><span class="si">}</span><span class="s2"> | "</span>
            <span class="sa">f</span><span class="s2">"train loss=</span><span class="si">{</span><span class="n">tr_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> tok=</span><span class="si">{</span><span class="n">tr_tok</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> em=</span><span class="si">{</span><span class="n">tr_em</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | "</span>
            <span class="sa">f</span><span class="s2">"val loss=</span><span class="si">{</span><span class="n">va_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> tok=</span><span class="si">{</span><span class="n">va_tok</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> em=</span><span class="si">{</span><span class="n">va_em</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span><span class="p">):</span>
            <span class="n">print_samples</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_ds</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">PRINT_SAMPLES</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_ds</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">run_attention_only</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"chars:  </span><span class="si">{</span><span class="n">chars</span><span class="si">!r}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Vocab size: </span><span class="si">{</span><span class="n">vocab</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2"> | Vocab: </span><span class="si">{</span><span class="n">vocab</span><span class="o">.</span><span class="n">chars</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"MAX_QUERY_LEN=</span><span class="si">{</span><span class="n">MAX_QUERY_LEN</span><span class="si">}</span><span class="s2">, MAX_ANS_LEN=</span><span class="si">{</span><span class="n">MAX_ANS_LEN</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"TRAIN_SIZE=</span><span class="si">{</span><span class="n">TRAIN_SIZE</span><span class="si">}</span><span class="s2">, VAL_SIZE=</span><span class="si">{</span><span class="n">VAL_SIZE</span><span class="si">}</span><span class="s2">, BATCH_SIZE=</span><span class="si">{</span><span class="n">BATCH_SIZE</span><span class="si">}</span><span class="s2">, EPOCHS=</span><span class="si">{</span><span class="n">EPOCHS</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">ArithmeticSeq2SeqDataset</span><span class="p">(</span><span class="n">TRAIN_SIZE</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">val_ds</span> <span class="o">=</span> <span class="n">ArithmeticSeq2SeqDataset</span><span class="p">(</span><span class="n">VAL_SIZE</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Attention only</span>
    <span class="n">attn</span> <span class="o">=</span> <span class="n">Seq2SeqLSTMAttn</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">EMB_DIM</span><span class="p">,</span> <span class="n">HIDDEN_SIZE</span><span class="p">)</span>
    <span class="n">train_model</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"Attention (additive/Bahdanau)"</span><span class="p">,</span> <span class="n">val_ds</span><span class="o">=</span><span class="n">val_ds</span><span class="p">)</span>

    <span class="c1"># final sanity check</span>
    <span class="n">tests</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"54-7"</span><span class="p">,</span> <span class="s2">"10+20"</span><span class="p">,</span> <span class="s2">"9999+9999"</span><span class="p">,</span> <span class="s2">"0-9999"</span><span class="p">,</span> <span class="s2">"1234-9999"</span><span class="p">,</span> <span class="s2">"777+888"</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Final sanity check (greedy):"</span><span class="p">)</span>
    <span class="n">attn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">--- attention ---"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tests</span><span class="p">:</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">MAX_QUERY_LEN</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">MAX_QUERY_LEN</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">attn</span><span class="o">.</span><span class="n">greedy_decode</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">MAX_ANS_LEN</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">SOS</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Q: </span><span class="si">{</span><span class="n">t</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2">   PRED: </span><span class="si">{</span><span class="n">pred</span><span class="si">:</span><span class="s2">&gt;6</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>


<span class="c1"># Run in notebook:</span>
<span class="n">run_attention_only</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Device: cpu
config: {'training_size': 40000, 'digits': 4, 'hidden_size': 128, 'batch_size': 128, 'iterations': 50}
chars:  '0123456789-+ '
Vocab size: 14 | Vocab: [' ', '+', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '^']
MAX_QUERY_LEN=9, MAX_ANS_LEN=5
TRAIN_SIZE=40000, VAL_SIZE=10000, BATCH_SIZE=128, EPOCHS=50

===== Training: Attention (additive/Bahdanau) =====
Epoch 01/50 | train loss=2.0829 tok=0.2150 em=0.0004 | val loss=1.9440 tok=0.2552 em=0.0008

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  11448
  Q:    2565+6526   TRUE:   9091   PRED:  81042
  Q:     801-3219   TRUE:  -2418   PRED:  -1086
  Q:    3984+1770   TRUE:   5754   PRED:  69999
  Q:    3735+2615   TRUE:   6350   PRED:  54299
  Q:    5688+7759   TRUE:  13447   PRED:  14484
  Q:    2025+3260   TRUE:   5285   PRED:  54222
  Q:    8524+7403   TRUE:  15927   PRED:  14848
  Q:     980+5556   TRUE:   6536   PRED:  98888
  Q:    1911-2754   TRUE:   -843   PRED:  -1072
  Q:    1702+1297   TRUE:   2999   PRED:  54287
  Q:    6529+7415   TRUE:  13944   PRED:  14484
Epoch 02/50 | train loss=1.8533 tok=0.2930 em=0.0008 | val loss=1.7827 tok=0.3226 em=0.0017
Epoch 03/50 | train loss=1.7410 tok=0.3338 em=0.0012 | val loss=1.7123 tok=0.3384 em=0.0010
Epoch 04/50 | train loss=1.6708 tok=0.3576 em=0.0015 | val loss=1.6559 tok=0.3590 em=0.0008
Epoch 05/50 | train loss=1.6174 tok=0.3760 em=0.0021 | val loss=1.6078 tok=0.3744 em=0.0025
Epoch 06/50 | train loss=1.5772 tok=0.3888 em=0.0025 | val loss=1.5523 tok=0.3925 em=0.0024
Epoch 07/50 | train loss=1.5346 tok=0.4025 em=0.0024 | val loss=1.5786 tok=0.3824 em=0.0018
Epoch 08/50 | train loss=1.5059 tok=0.4131 em=0.0026 | val loss=1.5078 tok=0.4073 em=0.0022
Epoch 09/50 | train loss=1.4781 tok=0.4230 em=0.0032 | val loss=1.4750 tok=0.4194 em=0.0032
Epoch 10/50 | train loss=1.4634 tok=0.4276 em=0.0035 | val loss=1.4473 tok=0.4348 em=0.0033
Epoch 11/50 | train loss=1.4408 tok=0.4378 em=0.0044 | val loss=1.4404 tok=0.4290 em=0.0028
Epoch 12/50 | train loss=1.4250 tok=0.4421 em=0.0046 | val loss=1.4409 tok=0.4240 em=0.0024
Epoch 13/50 | train loss=1.4082 tok=0.4490 em=0.0049 | val loss=1.3993 tok=0.4525 em=0.0035
Epoch 14/50 | train loss=1.4023 tok=0.4511 em=0.0046 | val loss=1.4232 tok=0.4382 em=0.0031
Epoch 15/50 | train loss=1.3947 tok=0.4553 em=0.0055 | val loss=1.3690 tok=0.4683 em=0.0050
Epoch 16/50 | train loss=1.3669 tok=0.4678 em=0.0062 | val loss=1.4122 tok=0.4437 em=0.0044
Epoch 17/50 | train loss=1.3734 tok=0.4638 em=0.0052 | val loss=1.4115 tok=0.4399 em=0.0038
Epoch 18/50 | train loss=1.3572 tok=0.4697 em=0.0069 | val loss=1.3736 tok=0.4550 em=0.0039
Epoch 19/50 | train loss=1.3400 tok=0.4781 em=0.0076 | val loss=1.3500 tok=0.4688 em=0.0043
Epoch 20/50 | train loss=1.3386 tok=0.4795 em=0.0080 | val loss=1.3820 tok=0.4489 em=0.0031
Epoch 21/50 | train loss=1.3303 tok=0.4821 em=0.0068 | val loss=1.3326 tok=0.4756 em=0.0055
Epoch 22/50 | train loss=1.3253 tok=0.4833 em=0.0073 | val loss=1.3552 tok=0.4666 em=0.0042
Epoch 23/50 | train loss=1.3206 tok=0.4852 em=0.0071 | val loss=1.3200 tok=0.4849 em=0.0057
Epoch 24/50 | train loss=1.3141 tok=0.4880 em=0.0082 | val loss=1.3421 tok=0.4687 em=0.0041
Epoch 25/50 | train loss=1.3019 tok=0.4946 em=0.0095 | val loss=1.3451 tok=0.4715 em=0.0057
Epoch 26/50 | train loss=1.2997 tok=0.4959 em=0.0084 | val loss=1.3045 tok=0.4899 em=0.0066
Epoch 27/50 | train loss=1.2941 tok=0.4967 em=0.0080 | val loss=1.3829 tok=0.4588 em=0.0044
Epoch 28/50 | train loss=1.2868 tok=0.5017 em=0.0093 | val loss=1.3565 tok=0.4658 em=0.0045
Epoch 29/50 | train loss=1.2854 tok=0.5001 em=0.0086 | val loss=1.3009 tok=0.4906 em=0.0062
Epoch 30/50 | train loss=1.2866 tok=0.5017 em=0.0102 | val loss=1.2964 tok=0.4924 em=0.0050
Epoch 31/50 | train loss=1.2652 tok=0.5118 em=0.0104 | val loss=1.2781 tok=0.5023 em=0.0065
Epoch 32/50 | train loss=1.2686 tok=0.5086 em=0.0101 | val loss=1.3201 tok=0.4774 em=0.0047
Epoch 33/50 | train loss=1.2575 tok=0.5148 em=0.0112 | val loss=1.2843 tok=0.4963 em=0.0062
Epoch 34/50 | train loss=1.2695 tok=0.5078 em=0.0109 | val loss=1.3727 tok=0.4593 em=0.0036
Epoch 35/50 | train loss=1.2506 tok=0.5175 em=0.0113 | val loss=1.2663 tok=0.5069 em=0.0078
Epoch 36/50 | train loss=1.2703 tok=0.5087 em=0.0104 | val loss=1.2825 tok=0.4988 em=0.0064
Epoch 37/50 | train loss=1.2506 tok=0.5175 em=0.0127 | val loss=1.2869 tok=0.4971 em=0.0063
Epoch 38/50 | train loss=1.2496 tok=0.5178 em=0.0115 | val loss=1.2895 tok=0.4966 em=0.0069
Epoch 39/50 | train loss=1.2428 tok=0.5209 em=0.0130 | val loss=1.2777 tok=0.4981 em=0.0054
Epoch 40/50 | train loss=1.2423 tok=0.5200 em=0.0117 | val loss=1.2801 tok=0.4996 em=0.0060
Epoch 41/50 | train loss=1.2391 tok=0.5234 em=0.0132 | val loss=1.2863 tok=0.4982 em=0.0066
Epoch 42/50 | train loss=1.2222 tok=0.5309 em=0.0138 | val loss=1.2588 tok=0.5107 em=0.0084
Epoch 43/50 | train loss=1.2354 tok=0.5241 em=0.0124 | val loss=1.2508 tok=0.5122 em=0.0053
Epoch 44/50 | train loss=1.2261 tok=0.5277 em=0.0133 | val loss=1.2390 tok=0.5197 em=0.0077
Epoch 45/50 | train loss=1.2241 tok=0.5287 em=0.0141 | val loss=1.2686 tok=0.5041 em=0.0081
Epoch 46/50 | train loss=1.2163 tok=0.5317 em=0.0144 | val loss=1.2343 tok=0.5245 em=0.0091
Epoch 47/50 | train loss=1.2164 tok=0.5323 em=0.0144 | val loss=1.3174 tok=0.4856 em=0.0048
Epoch 48/50 | train loss=1.2110 tok=0.5355 em=0.0150 | val loss=1.2632 tok=0.5111 em=0.0067
Epoch 49/50 | train loss=1.2096 tok=0.5361 em=0.0152 | val loss=1.2816 tok=0.5007 em=0.0070
Epoch 50/50 | train loss=1.2197 tok=0.5305 em=0.0151 | val loss=1.2736 tok=0.5023 em=0.0051

================================================================================
Samples from validation (greedy decode)
================================================================================
  Q:    3844+9270   TRUE:  13114   PRED:  13155
  Q:    2565+6526   TRUE:   9091   PRED:  91143
  Q:     801-3219   TRUE:  -2418   PRED:  -2351
  Q:    3984+1770   TRUE:   5754   PRED:  58537
  Q:    3735+2615   TRUE:   6350   PRED:  64445
  Q:    5688+7759   TRUE:  13447   PRED:  13400
  Q:    2025+3260   TRUE:   5285   PRED:  54484
  Q:    8524+7403   TRUE:  15927   PRED:  15957
  Q:     980+5556   TRUE:   6536   PRED:  65555
  Q:    1911-2754   TRUE:   -843   PRED:  -8948
  Q:    1702+1297   TRUE:   2999   PRED:  30443
  Q:    6529+7415   TRUE:  13944   PRED:  13942

Final sanity check (greedy):

--- attention ---
Q:       54-7   PRED:  49909
Q:      10+20   PRED:  14480
Q:  9999+9999   PRED:  19894
Q:     0-9999   PRED:  -8969
Q:  1234-9999   PRED:  -8733
Q:    777+888   PRED:  16666
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.4).                     What it changes vs 1.1/1.3
	LSTM seq2seq (even with attention) still struggles with algorithmic generalization and exposure bias.
	Transformer gives direct token-to-token interactions and typically learns digit alignment/carry rules better.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># -----------------------------</span>
<span class="c1"># Read required params</span>
<span class="c1"># -----------------------------</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"seed"</span><span class="p">,</span> <span class="mi">123</span><span class="p">))</span>
<span class="n">TRAIN_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"training_size"</span><span class="p">])</span>
<span class="n">VAL_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"val_size"</span><span class="p">,</span> <span class="mi">10000</span><span class="p">))</span>
<span class="n">DIGITS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"digits"</span><span class="p">])</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">])</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"iterations"</span><span class="p">],</span> <span class="mi">50</span><span class="p">))</span>

<span class="c1"># Transformer knobs (reasonable defaults)</span>
<span class="n">D_MODEL</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"d_model"</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
<span class="n">NHEAD</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"nhead"</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">NUM_LAYERS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"num_layers"</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">DIM_FF</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"dim_ff"</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
<span class="n">DROPOUT</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"dropout"</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">))</span>
<span class="n">LR</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"lr"</span><span class="p">,</span> <span class="mf">3e-4</span><span class="p">))</span>
<span class="n">PRINT_SAMPLES</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"print_samples"</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>

<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Task constants</span>
<span class="c1"># -----------------------------</span>
<span class="n">MAX_INT</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">DIGITS</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">MAX_QUERY_LEN</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">DIGITS</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">MAX_ANS_LEN</span> <span class="o">=</span> <span class="n">DIGITS</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">PAD</span> <span class="o">=</span> <span class="s2">" "</span>
<span class="n">SOS</span> <span class="o">=</span> <span class="s2">"^"</span>
<span class="n">EOS</span> <span class="o">=</span> <span class="s2">"$"</span>   <span class="c1"># add explicit end token (helps)</span>
<span class="n">CHARS</span> <span class="o">=</span> <span class="n">chars</span> <span class="o">+</span> <span class="n">SOS</span> <span class="o">+</span> <span class="n">EOS</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Vocab</span>
<span class="c1"># -----------------------------</span>
<span class="k">class</span> <span class="nc">CharVocab</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chars_</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chars</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">chars_</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">itos</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">c</span> <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">PAD</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sos_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">SOS</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eos_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">EOS</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">s</span><span class="p">[:</span><span class="n">maxlen</span><span class="p">]]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">maxlen</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">maxlen</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itos</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">)</span>

<span class="n">vocab</span> <span class="o">=</span> <span class="n">CharVocab</span><span class="p">(</span><span class="n">CHARS</span><span class="p">)</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Dataset (answers have EOS)</span>
<span class="c1"># -----------------------------</span>
<span class="k">class</span> <span class="nc">ArithmeticDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">questions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">answers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">seen</span><span class="p">:</span> <span class="nb">set</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span><span class="nb">int</span><span class="p">,</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">questions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">MAX_INT</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">b</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">MAX_INT</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">op</span> <span class="o">=</span> <span class="s2">"+"</span> <span class="k">if</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="s2">"-"</span>
            <span class="n">key</span> <span class="o">=</span> <span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">seen</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

            <span class="n">ans</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="s2">"+"</span> <span class="k">else</span> <span class="n">a</span> <span class="o">-</span> <span class="n">b</span>
            <span class="n">q</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">a</span><span class="si">}{</span><span class="n">op</span><span class="si">}{</span><span class="n">b</span><span class="si">}</span><span class="s2">"</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">MAX_QUERY_LEN</span><span class="p">)</span>

            <span class="c1"># target string: answer + EOS, then pad to MAX_ANS_LEN+1</span>
            <span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span> <span class="o">+</span> <span class="n">EOS</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">MAX_ANS_LEN</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">questions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">answers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">questions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">answers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">MAX_QUERY_LEN</span><span class="p">)</span>                <span class="c1"># (Tin,)</span>
        <span class="n">y_tgt</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">MAX_ANS_LEN</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>          <span class="c1"># (Tout,)</span>
        <span class="c1"># decoder input: SOS + y[:-1]</span>
        <span class="n">y_in</span> <span class="o">=</span> <span class="p">(</span><span class="n">SOS</span> <span class="o">+</span> <span class="n">y</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">MAX_ANS_LEN</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y_in</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">y_in</span><span class="p">,</span> <span class="n">MAX_ANS_LEN</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y_in</span><span class="p">,</span> <span class="n">y_tgt</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Positional encoding</span>
<span class="c1"># -----------------------------</span>
<span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">div</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">d_model</span><span class="p">))</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">pos</span> <span class="o">*</span> <span class="n">div</span><span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">pos</span> <span class="o">*</span> <span class="n">div</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"pe"</span><span class="p">,</span> <span class="n">pe</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>  <span class="c1"># (1, max_len, d_model)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># x: (B,T,d_model)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:,</span> <span class="p">:</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Transformer seq2seq</span>
<span class="c1"># -----------------------------</span>
<span class="k">class</span> <span class="nc">TransformerSeq2Seq</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">D_MODEL</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">D_MODEL</span><span class="p">,</span> <span class="n">DROPOUT</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tf</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Transformer</span><span class="p">(</span>
            <span class="n">d_model</span><span class="o">=</span><span class="n">D_MODEL</span><span class="p">,</span>
            <span class="n">nhead</span><span class="o">=</span><span class="n">NHEAD</span><span class="p">,</span>
            <span class="n">num_encoder_layers</span><span class="o">=</span><span class="n">NUM_LAYERS</span><span class="p">,</span>
            <span class="n">num_decoder_layers</span><span class="o">=</span><span class="n">NUM_LAYERS</span><span class="p">,</span>
            <span class="n">dim_feedforward</span><span class="o">=</span><span class="n">DIM_FF</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">DROPOUT</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">D_MODEL</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tgt_in</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># src: (B,Tin), tgt_in: (B,Tout)</span>
        <span class="n">src_key_padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">src</span> <span class="o">==</span> <span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">)</span>
        <span class="n">tgt_key_padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">tgt_in</span> <span class="o">==</span> <span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">)</span>

        <span class="n">B</span><span class="p">,</span> <span class="n">Tt</span> <span class="o">=</span> <span class="n">tgt_in</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># causal mask for decoder</span>
        <span class="n">causal</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">Tt</span><span class="p">,</span> <span class="n">Tt</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">src</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>

        <span class="n">src_e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">src</span><span class="p">))</span>
        <span class="n">tgt_e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">tgt_in</span><span class="p">))</span>

        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf</span><span class="p">(</span>
            <span class="n">src_e</span><span class="p">,</span> <span class="n">tgt_e</span><span class="p">,</span>
            <span class="n">src_key_padding_mask</span><span class="o">=</span><span class="n">src_key_padding</span><span class="p">,</span>
            <span class="n">tgt_key_padding_mask</span><span class="o">=</span><span class="n">tgt_key_padding</span><span class="p">,</span>
            <span class="n">tgt_mask</span><span class="o">=</span><span class="n">causal</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>  <span class="c1"># (B,Tout,V)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">greedy_decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">vocab</span><span class="o">.</span><span class="n">sos_idx</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">src</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">):</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>              <span class="c1"># (B, t, V)</span>
            <span class="n">next_tok</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B,)</span>
            <span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ys</span><span class="p">,</span> <span class="n">next_tok</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ys</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>  <span class="c1"># drop SOS</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Metrics</span>
<span class="c1"># -----------------------------</span>
<span class="k">def</span> <span class="nf">token_acc_ignore_pad</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">!=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">return</span> <span class="mf">0.0</span>
    <span class="k">return</span> <span class="p">(((</span><span class="n">pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="o">/</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">exact_match</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="c1"># compare until EOS in y</span>
    <span class="n">B</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">ok</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="n">y_i</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">eos_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_i</span> <span class="o">==</span> <span class="n">vocab</span><span class="o">.</span><span class="n">eos_idx</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">L</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">eos_pos</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">eos_pos</span><span class="p">)</span> <span class="k">else</span> <span class="n">T</span>
        <span class="n">ok</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">L</span><span class="p">],</span> <span class="n">y_i</span><span class="p">[:</span><span class="n">L</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">ok</span> <span class="o">/</span> <span class="n">B</span>

<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">eval_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">)</span>
    <span class="n">tot_loss</span> <span class="o">=</span> <span class="n">tot_tok</span> <span class="o">=</span> <span class="n">tot_em</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y_in</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y_in</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_in</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_in</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">tot_loss</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">tot_tok</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">token_acc_ignore_pad</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="n">tot_em</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">exact_match</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">tot_loss</span><span class="o">/</span><span class="n">n</span><span class="p">,</span> <span class="n">tot_tok</span><span class="o">/</span><span class="n">n</span><span class="p">,</span> <span class="n">tot_em</span><span class="o">/</span><span class="n">n</span>

<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">print_samples</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">SEED</span> <span class="o">+</span> <span class="mi">777</span><span class="p">)</span>
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ds</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">qs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idxs</span><span class="p">:</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">questions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">answers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">MAX_QUERY_LEN</span><span class="p">))</span>
        <span class="n">qs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
        <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">EOS</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">greedy_decode</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="n">MAX_ANS_LEN</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Samples:"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">q</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">EOS</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Q:</span><span class="si">{</span><span class="n">q</span><span class="si">:</span><span class="s2">&gt;12</span><span class="si">}</span><span class="s2">  TRUE:</span><span class="si">{</span><span class="n">y_true</span><span class="si">:</span><span class="s2">&gt;6</span><span class="si">}</span><span class="s2">  PRED:</span><span class="si">{</span><span class="n">s</span><span class="si">:</span><span class="s2">&gt;6</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Train</span>
<span class="c1"># -----------------------------</span>
<span class="k">def</span> <span class="nf">run_transformer</span><span class="p">():</span>
    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">ArithmeticDataset</span><span class="p">(</span><span class="n">TRAIN_SIZE</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">val_ds</span> <span class="o">=</span> <span class="n">ArithmeticDataset</span><span class="p">(</span><span class="n">VAL_SIZE</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">TransformerSeq2Seq</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="n">vocab</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">"Training Transformer seq2seq..."</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">tot</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">nb</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y_in</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y_in</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_in</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_in</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">tot</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">nb</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">va_loss</span><span class="p">,</span> <span class="n">va_tok</span><span class="p">,</span> <span class="n">va_em</span> <span class="o">=</span> <span class="n">eval_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">ep</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">EPOCHS</span><span class="si">}</span><span class="s2"> | train loss=</span><span class="si">{</span><span class="n">tot</span><span class="o">/</span><span class="n">nb</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | val loss=</span><span class="si">{</span><span class="n">va_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> tok=</span><span class="si">{</span><span class="n">va_tok</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> em=</span><span class="si">{</span><span class="n">va_em</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">ep</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span><span class="p">):</span>
            <span class="n">print_samples</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_ds</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">PRINT_SAMPLES</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_ds</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">model</span>

<span class="c1"># Run:</span>
<span class="n">model_tf</span> <span class="o">=</span> <span class="n">run_transformer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Training Transformer seq2seq...
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/netanelazran/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:505: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/NestedTensorImpl.cpp:182.)
  output = torch._nested_tensor_from_mask(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 01/50 | train loss=1.8769 | val loss=1.7263 tok=0.3610 em=0.0003

Samples:
Q:     45+7528  TRUE:  7573  PRED: 10000
Q:   9327-6960  TRUE:  2367  PRED:   100
Q:    1307+419  TRUE:  1726  PRED:  4005
Q:   2245+7017  TRUE:  9262  PRED: 10000
Q:   1117+8892  TRUE: 10009  PRED: 10000
Q:   5883-6613  TRUE:  -730  PRED: -1107
Q:   1116+6332  TRUE:  7448  PRED:  7005
Q:   5014-7456  TRUE: -2442  PRED:  -157
Q:   8517+5383  TRUE: 13900  PRED: 10455
Q:    619+7957  TRUE:  8576  PRED: 10455
Q:   1609+7288  TRUE:  8897  PRED:  9000
Q:   3841+8137  TRUE: 11978  PRED: 10405
Epoch 02/50 | train loss=1.6594 | val loss=1.6350 tok=0.4109 em=0.0005
Epoch 03/50 | train loss=1.5561 | val loss=1.6205 tok=0.4268 em=0.0002
Epoch 04/50 | train loss=1.5041 | val loss=1.6122 tok=0.4374 em=0.0011
Epoch 05/50 | train loss=1.4695 | val loss=1.6206 tok=0.4316 em=0.0001
Epoch 06/50 | train loss=1.4444 | val loss=1.6088 tok=0.4453 em=0.0010
Epoch 07/50 | train loss=1.4267 | val loss=1.6157 tok=0.4520 em=0.0012
Epoch 08/50 | train loss=1.4073 | val loss=1.6100 tok=0.4518 em=0.0009
Epoch 09/50 | train loss=1.3949 | val loss=1.6051 tok=0.4545 em=0.0006
Epoch 10/50 | train loss=1.3762 | val loss=1.5914 tok=0.4644 em=0.0014
Epoch 11/50 | train loss=1.3586 | val loss=1.5648 tok=0.4748 em=0.0017
Epoch 12/50 | train loss=1.3445 | val loss=1.5654 tok=0.4718 em=0.0017
Epoch 13/50 | train loss=1.3327 | val loss=1.5710 tok=0.4757 em=0.0014
Epoch 14/50 | train loss=1.3207 | val loss=1.5588 tok=0.4790 em=0.0015
Epoch 15/50 | train loss=1.3122 | val loss=1.5700 tok=0.4820 em=0.0025
Epoch 16/50 | train loss=1.3015 | val loss=1.5620 tok=0.4834 em=0.0027
Epoch 17/50 | train loss=1.2951 | val loss=1.5600 tok=0.4867 em=0.0016
Epoch 18/50 | train loss=1.2893 | val loss=1.5533 tok=0.4844 em=0.0021
Epoch 19/50 | train loss=1.2798 | val loss=1.5594 tok=0.4919 em=0.0022
Epoch 20/50 | train loss=1.2741 | val loss=1.5767 tok=0.4786 em=0.0010
Epoch 21/50 | train loss=1.2673 | val loss=1.5515 tok=0.4917 em=0.0018
Epoch 22/50 | train loss=1.2625 | val loss=1.5484 tok=0.4925 em=0.0025
Epoch 23/50 | train loss=1.2584 | val loss=1.5472 tok=0.4934 em=0.0022
Epoch 24/50 | train loss=1.2499 | val loss=1.5494 tok=0.4902 em=0.0020
Epoch 25/50 | train loss=1.2473 | val loss=1.5562 tok=0.4907 em=0.0009
Epoch 26/50 | train loss=1.2432 | val loss=1.5432 tok=0.4963 em=0.0028
Epoch 27/50 | train loss=1.2392 | val loss=1.5690 tok=0.4903 em=0.0019
Epoch 28/50 | train loss=1.2342 | val loss=1.5547 tok=0.4895 em=0.0014
Epoch 29/50 | train loss=1.2301 | val loss=1.5487 tok=0.5022 em=0.0019
Epoch 30/50 | train loss=1.2266 | val loss=1.5445 tok=0.4982 em=0.0024
Epoch 31/50 | train loss=1.2227 | val loss=1.5525 tok=0.5043 em=0.0036
Epoch 32/50 | train loss=1.2196 | val loss=1.5417 tok=0.5028 em=0.0037
Epoch 33/50 | train loss=1.2162 | val loss=1.5328 tok=0.5048 em=0.0034
Epoch 34/50 | train loss=1.2122 | val loss=1.5422 tok=0.5072 em=0.0020
Epoch 35/50 | train loss=1.2019 | val loss=1.5281 tok=0.5083 em=0.0030
Epoch 36/50 | train loss=1.1900 | val loss=1.5145 tok=0.5230 em=0.0054
Epoch 37/50 | train loss=1.1671 | val loss=1.4684 tok=0.5314 em=0.0046
Epoch 38/50 | train loss=1.1408 | val loss=1.4719 tok=0.5370 em=0.0040
Epoch 39/50 | train loss=1.1243 | val loss=1.4523 tok=0.5483 em=0.0046
Epoch 40/50 | train loss=1.1038 | val loss=1.4471 tok=0.5498 em=0.0059
Epoch 41/50 | train loss=1.0917 | val loss=1.4606 tok=0.5521 em=0.0047
Epoch 42/50 | train loss=1.0818 | val loss=1.4318 tok=0.5603 em=0.0048
Epoch 43/50 | train loss=1.0717 | val loss=1.4163 tok=0.5706 em=0.0062
Epoch 44/50 | train loss=1.0632 | val loss=1.4621 tok=0.5668 em=0.0059
Epoch 45/50 | train loss=1.0540 | val loss=1.4687 tok=0.5689 em=0.0074
Epoch 46/50 | train loss=1.0438 | val loss=1.4565 tok=0.5748 em=0.0072
Epoch 47/50 | train loss=1.0386 | val loss=1.4524 tok=0.5789 em=0.0076
Epoch 48/50 | train loss=1.0276 | val loss=1.4438 tok=0.5852 em=0.0075
Epoch 49/50 | train loss=1.0206 | val loss=1.4411 tok=0.5897 em=0.0089
Epoch 50/50 | train loss=1.0144 | val loss=1.4711 tok=0.5901 em=0.0098

Samples:
Q:     45+7528  TRUE:  7573  PRED:  8484
Q:   9327-6960  TRUE:  2367  PRED:  2439
Q:    1307+419  TRUE:  1726  PRED:  5494
Q:   2245+7017  TRUE:  9262  PRED:  9385
Q:   1117+8892  TRUE: 10009  PRED: 10004
Q:   5883-6613  TRUE:  -730  PRED:  -733
Q:   1116+6332  TRUE:  7448  PRED:  7444
Q:   5014-7456  TRUE: -2442  PRED: -2430
Q:   8517+5383  TRUE: 13900  PRED: 13983
Q:    619+7957  TRUE:  8576  PRED: 15504
Q:   1609+7288  TRUE:  8897  PRED:  8944
Q:   3841+8137  TRUE: 11978  PRED: 12024
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Model Comparison (1.1 vs 1.3 vs 1.4)</p>
<p>I compared three models on the arithmetic seq2seq task using validation results:
 Baseline LSTM (1.1, no attention)
 LSTM with additive attention (1.3)
 Transformer encoderdecoder (1.4)</p>
<p>The comparison was based on:
 Exact-match accuracy (EM)  main metric
 Token accuracy  secondary
 Validation loss  supporting</p>
<p>The baseline LSTM (1.1) achieved a validation loss of around 1.29 with approximately 50% token accuracy, but produced almost no exact-match outputs, indicating that it often predicts individual digits correctly but fails to generate a fully correct numerical result.</p>
<p>The LSTM with attention (1.3) showed a small improvement, reaching validation losses of about 1.251.28, token accuracy in the range of 5153%, and an exact-match accuracy of approximately 0.71.0%. This suggests that attention helps the model align input digits with output positions, but the improvement in full correctness remains limited.</p>
<p>The Transformer model (1.4) achieved the best performance overall, with token accuracy of around 60% and the highest exact-match accuracy of roughly 1.1%, despite having a higher validation loss (around 1.45). Since exact-match accuracy is the most meaningful metric for this task, this result indicates that the Transformer produces more fully correct answers than the LSTM-based models.</p>
<p>In conclusion, the Transformer outperforms the models from 1.1 and 1.3 on the metric that matters most for arithmetic reasoningexact-match accuracylikely due to its self-attention mechanism, which avoids the recurrent bottleneck and better models digit-level dependencies such as carry and borrow.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<hr/>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Part-2:-A-language-translation-model-with-attention">Part 2: A language translation model with attention<a class="anchor-link" href="#Part-2:-A-language-translation-model-with-attention"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>In this part of the problem set we are going to implement a translation with a Sequence to Sequence Network and Attention model.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol start="0">
<li>Please go over the NLP From Scratch: Translation with a Sequence to Sequence Network and Attention <a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html">tutorial</a>. This attention model is very similar to what was learned in class (Luong), but a bit different. What are the main differences between  Badahnau and Luong attention mechanisms?</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>solutions 0.)  The main differences between Bahdanau and Luong attention are:</p>
<p>Bahdanau (additive) attention computes alignment scores before generating the decoder output, using the previous decoder hidden state and a small feedforward network. This makes it more expressive but computationally heavier.
Luong attention computes attention after the decoder hidden state is produced and uses simpler multiplicative scoring functions (such as dot or general), which are more efficient.</p>
<p>In summary, Bahdanau attention is more flexible, while Luong attention is simpler and faster. The attention mechanism used in the tutorial is closer to Luong attention, with minor differences in how the context vector is combined with the decoder state.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>1.a) Using <code>!wget</code>, <code>!unzip</code> , download and extract the <a href="https://www.manythings.org/anki/">hebrew-english</a> sentence pairs text file to the Colab <code>content/</code>  folder (or local folder if not using Colab).
1.b) The <code>heb.txt</code> must be parsed and cleaned (see tutorial for requirements or change the code as you see fit).</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>2.a) Use the tutorial example to build  and train a Hebrew to English translation model with attention (using the parameters in the code cell below). Apply the same <code>eng_prefixes</code> filter to limit the train/test data.<br/>
2.b) Evaluate your trained model randomly on 20 sentences.<br/>
2.c) Show the attention plot for 5 random sentences.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol start="3">
<li>Do you think this model performs well? Why or why not? What are its limitations/disadvantages? What would you do to improve it?</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ol start="4">
<li>Using any neural network architecture of your liking, build  a model with the aim to beat the model in 2.a. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better.</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># use the following parameters:</span>
<span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>SOLUTION:</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">### MISSING</span>
<span class="o">!</span>curl<span class="w"> </span>-L<span class="w"> </span>-o<span class="w"> </span>heb-eng.zip<span class="w"> </span>http://www.manythings.org/anki/heb-eng.zip
<span class="o">!</span>unzip<span class="w"> </span>-o<span class="w"> </span>heb-eng.zip<span class="w"> </span>-d<span class="w"> </span>heb_eng
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 4636k  100 4636k    0     0  1636k      0  0:00:02  0:00:02 --:--:-- 1635k
Archive:  heb-eng.zip
  inflating: heb_eng/_about.txt      
  inflating: heb_eng/heb.txt         
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">## import part 2 ##</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">unicodedata</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"device:"</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>device: cpu
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">unicode_to_ascii</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="c1"># keep English side consistent with tutorial</span>
    <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="s2">"NFD"</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">category</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">"Mn"</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">normalize_en</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">unicode_to_ascii</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"([.!?])"</span><span class="p">,</span> <span class="sa">r</span><span class="s2">" \1"</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"[^a-zA-Z.!?]+"</span><span class="p">,</span> <span class="sa">r</span><span class="s2">" "</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"\s+"</span><span class="p">,</span> <span class="s2">" "</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">s</span>

<span class="k">def</span> <span class="nf">normalize_he</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="c1"># keep Hebrew letters, basic punctuation; normalize whitespace</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"\s+"</span><span class="p">,</span> <span class="s2">" "</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span>

<span class="k">def</span> <span class="nf">read_heb_eng_pairs</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">max_lines</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">"utf-8"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">max_lines</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">max_lines</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\t</span><span class="s2">"</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">en</span><span class="p">,</span> <span class="n">he</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">en_n</span> <span class="o">=</span> <span class="n">normalize_en</span><span class="p">(</span><span class="n">en</span><span class="p">)</span>
            <span class="n">he_n</span> <span class="o">=</span> <span class="n">normalize_he</span><span class="p">(</span><span class="n">he</span><span class="p">)</span>

            <span class="c1"># basic filtering</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">en_n</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">he_n</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">pairs</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">en_n</span><span class="p">,</span> <span class="n">he_n</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">pairs</span>

<span class="n">heb_path</span> <span class="o">=</span> <span class="s2">"heb_eng/heb.txt"</span>
<span class="n">pairs</span> <span class="o">=</span> <span class="n">read_heb_eng_pairs</span><span class="p">(</span><span class="n">heb_path</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Num pairs:"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Example:"</span><span class="p">,</span> <span class="n">pairs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Num pairs: 136845
Example: ('go .', '!')
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># =========================</span>
<span class="c1"># Hebrew -&gt; English Seq2Seq with Attention (Tutorial-style)</span>
<span class="c1"># -----------------------------</span>
<span class="c1"># Normalization</span>
<span class="c1"># -----------------------------</span>
<span class="k">def</span> <span class="nf">unicode_to_ascii</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="s2">"NFD"</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">category</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">"Mn"</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">normalize_en</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">unicode_to_ascii</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"([.!?])"</span><span class="p">,</span> <span class="sa">r</span><span class="s2">" \1"</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"[^a-zA-Z.!?]+"</span><span class="p">,</span> <span class="sa">r</span><span class="s2">" "</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"\s+"</span><span class="p">,</span> <span class="s2">" "</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">s</span>

<span class="k">def</span> <span class="nf">normalize_he</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"\s+"</span><span class="p">,</span> <span class="s2">" "</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span>

<span class="k">def</span> <span class="nf">read_heb_eng_pairs</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">max_lines</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
    <span class="c1"># returns pairs as (en, he) normalized</span>
    <span class="n">pairs_local</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">"utf-8"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">max_lines</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">max_lines</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\t</span><span class="s2">"</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">en</span><span class="p">,</span> <span class="n">he</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">en_n</span> <span class="o">=</span> <span class="n">normalize_en</span><span class="p">(</span><span class="n">en</span><span class="p">)</span>
            <span class="n">he_n</span> <span class="o">=</span> <span class="n">normalize_he</span><span class="p">(</span><span class="n">he</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">en_n</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">he_n</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">pairs_local</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">en_n</span><span class="p">,</span> <span class="n">he_n</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">pairs_local</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Filter (same eng_prefixes requirement)</span>
<span class="c1"># -----------------------------</span>
<span class="n">eng_prefixes</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">"i am "</span><span class="p">,</span> <span class="s2">"i m "</span><span class="p">,</span>
    <span class="s2">"he is"</span><span class="p">,</span> <span class="s2">"he s "</span><span class="p">,</span>
    <span class="s2">"she is"</span><span class="p">,</span> <span class="s2">"she s "</span><span class="p">,</span>
    <span class="s2">"you are"</span><span class="p">,</span> <span class="s2">"you re "</span><span class="p">,</span>
    <span class="s2">"we are"</span><span class="p">,</span> <span class="s2">"we re "</span><span class="p">,</span>
    <span class="s2">"they are"</span><span class="p">,</span> <span class="s2">"they re "</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">filter_pair</span><span class="p">(</span><span class="n">he</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">en</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="c1"># note: en already normalized to lowercase in normalize_en()</span>
    <span class="k">return</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">he</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span> <span class="ow">and</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">en</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span> <span class="ow">and</span>
            <span class="n">en</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">eng_prefixes</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">filter_pairs</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
    <span class="k">return</span> <span class="p">[(</span><span class="n">he</span><span class="p">,</span> <span class="n">en</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">he</span><span class="p">,</span> <span class="n">en</span><span class="p">)</span> <span class="ow">in</span> <span class="n">pairs_he_en</span> <span class="k">if</span> <span class="n">filter_pair</span><span class="p">(</span><span class="n">he</span><span class="p">,</span> <span class="n">en</span><span class="p">)]</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Load + flip to Hebrew-&gt;English + filter</span>
<span class="c1"># -----------------------------</span>
<span class="n">heb_path</span> <span class="o">=</span> <span class="s2">"heb_eng/heb.txt"</span>
<span class="n">pairs_en_he</span> <span class="o">=</span> <span class="n">read_heb_eng_pairs</span><span class="p">(</span><span class="n">heb_path</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Total raw pairs:"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs_en_he</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Raw example (en, he):"</span><span class="p">,</span> <span class="n">pairs_en_he</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Flip: (en, he) -&gt; (he, en)</span>
<span class="n">pairs_he_en</span> <span class="o">=</span> <span class="p">[(</span><span class="n">he</span><span class="p">,</span> <span class="n">en</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">en</span><span class="p">,</span> <span class="n">he</span><span class="p">)</span> <span class="ow">in</span> <span class="n">pairs_en_he</span><span class="p">]</span>

<span class="n">pairs_he_en</span> <span class="o">=</span> <span class="n">filter_pairs</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Filtered pairs:"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">))</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="s2">"No pairs matched eng_prefixes after filtering. "</span>
        <span class="s2">"This usually means the data does not contain the specified prefixes under MAX_LENGTH."</span>
    <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Filtered example (he, en):"</span><span class="p">,</span> <span class="n">pairs_he_en</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># random.shuffle(pairs_he_en)</span>
<span class="c1"># pairs_he_en = pairs_he_en[:50000]</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Lang vocab (according tutorial)</span>
<span class="c1"># -----------------------------</span>
<span class="n">SOS_token</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">EOS_token</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">class</span> <span class="nc">Lang</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">SOS_token</span><span class="p">:</span> <span class="s2">"SOS"</span><span class="p">,</span> <span class="n">EOS_token</span><span class="p">:</span> <span class="s2">"EOS"</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="k">def</span> <span class="nf">add_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">" "</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_word</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_words</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">indexes_from_sentence</span><span class="p">(</span><span class="n">lang</span><span class="p">:</span> <span class="n">Lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">lang</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">" "</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">tensor_from_sentence</span><span class="p">(</span><span class="n">lang</span><span class="p">:</span> <span class="n">Lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">indexes_from_sentence</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
    <span class="n">idxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EOS_token</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">idxs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">tensors_from_pair</span><span class="p">(</span><span class="n">pair</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">input_lang</span><span class="p">:</span> <span class="n">Lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">:</span> <span class="n">Lang</span><span class="p">):</span>
    <span class="n">he</span><span class="p">,</span> <span class="n">en</span> <span class="o">=</span> <span class="n">pair</span>
    <span class="k">return</span> <span class="n">tensor_from_sentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">he</span><span class="p">),</span> <span class="n">tensor_from_sentence</span><span class="p">(</span><span class="n">output_lang</span><span class="p">,</span> <span class="n">en</span><span class="p">)</span>

<span class="n">input_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="s2">"heb"</span><span class="p">)</span>
<span class="n">output_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="s2">"eng"</span><span class="p">)</span>

<span class="k">for</span> <span class="n">he</span><span class="p">,</span> <span class="n">en</span> <span class="ow">in</span> <span class="n">pairs_he_en</span><span class="p">:</span>
    <span class="n">input_lang</span><span class="o">.</span><span class="n">add_sentence</span><span class="p">(</span><span class="n">he</span><span class="p">)</span>
    <span class="n">output_lang</span><span class="o">.</span><span class="n">add_sentence</span><span class="p">(</span><span class="n">en</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Vocab sizes:"</span><span class="p">,</span> <span class="n">input_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">,</span> <span class="n">output_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Models (Encoder GRU + Attention Decoder GRU)</span>
<span class="c1"># -----------------------------</span>
<span class="k">class</span> <span class="nc">EncoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size_</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_token</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">input_token</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">hidden</span>

    <span class="k">def</span> <span class="nf">init_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">AttnDecoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size_</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_combine</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size_</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size_</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size_</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_token</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">input_token</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>

        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embedded</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hidden</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>  <span class="c1"># (1, MAX_LENGTH)</span>

        <span class="n">attn_applied</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span>
            <span class="n">attn_weights</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>      <span class="c1"># (1,1,MAX_LENGTH)</span>
            <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>    <span class="c1"># (1,MAX_LENGTH,H)</span>
        <span class="p">)</span>  <span class="c1"># (1,1,H)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embedded</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">attn_applied</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="mi">1</span><span class="p">)</span>      <span class="c1"># (1,2H)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_combine</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>            <span class="c1"># (1,1,H)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>     <span class="c1"># (1,V)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">attn_weights</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Training helpers</span>
<span class="c1"># -----------------------------</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">teacher_forcing_ratio</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">enc_opt</span><span class="p">,</span> <span class="n">dec_opt</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>
    <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">()</span>
    <span class="n">enc_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dec_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">input_length</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">target_length</span> <span class="o">=</span> <span class="n">target_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">ei</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_length</span><span class="p">):</span>
        <span class="n">enc_out</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">[</span><span class="n">ei</span><span class="p">],</span> <span class="n">encoder_hidden</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ei</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span><span class="p">:</span>
            <span class="n">encoder_outputs</span><span class="p">[</span><span class="n">ei</span><span class="p">]</span> <span class="o">=</span> <span class="n">enc_out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">SOS_token</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">use_teacher</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">teacher_forcing_ratio</span>

    <span class="k">if</span> <span class="n">use_teacher</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_length</span><span class="p">):</span>
            <span class="n">dec_out</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">dec_out</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">[</span><span class="n">di</span><span class="p">])</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">target_tensor</span><span class="p">[</span><span class="n">di</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_length</span><span class="p">):</span>
            <span class="n">dec_out</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
            <span class="n">topv</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">dec_out</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">dec_out</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">[</span><span class="n">di</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">decoder_input</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">EOS_token</span><span class="p">:</span>
                <span class="k">break</span>

    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">enc_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">dec_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">target_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">as_minutes</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">s</span> <span class="o">/</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">-=</span> <span class="n">m</span> <span class="o">*</span> <span class="mi">60</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s2">m </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="si">}</span><span class="s2">s"</span>

<span class="k">def</span> <span class="nf">time_since</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
    <span class="n">now</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">now</span> <span class="o">-</span> <span class="n">start</span>
    <span class="n">es</span> <span class="o">=</span> <span class="n">s</span> <span class="o">/</span> <span class="n">progress</span> <span class="k">if</span> <span class="n">progress</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">rs</span> <span class="o">=</span> <span class="n">es</span> <span class="o">-</span> <span class="n">s</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">as_minutes</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="si">}</span><span class="s2"> (- </span><span class="si">{</span><span class="n">as_minutes</span><span class="p">(</span><span class="n">rs</span><span class="p">)</span><span class="si">}</span><span class="s2">)"</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Train</span>
<span class="c1"># -----------------------------</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">EncoderRNN</span><span class="p">(</span><span class="n">input_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">AttnDecoderRNN</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">enc_opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">dec_opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs_he_en</span><span class="p">:</span>
        <span class="n">inp</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">=</span> <span class="n">tensors_from_pair</span><span class="p">(</span><span class="n">pair</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">enc_opt</span><span class="p">,</span> <span class="n">dec_opt</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>

    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">ep</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> | loss=</span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">time_since</span><span class="p">(</span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">ep</span><span class="o">/</span><span class="n">epochs</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Done."</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Total raw pairs: 136845
Raw example (en, he): ('go .', '!')
Filtered pairs: 9225
Filtered example (he, en): (' .', 'i m ok .')
Vocab sizes: 7359 3050
Epoch 01/50 | loss=2.8753 | 1m 51s (- 91m 19s)
Epoch 02/50 | loss=2.4817 | 3m 42s (- 89m 5s)
Epoch 03/50 | loss=2.2554 | 5m 31s (- 86m 37s)
Epoch 04/50 | loss=2.0626 | 7m 23s (- 85m 4s)
Epoch 05/50 | loss=1.9041 | 9m 21s (- 84m 14s)
Epoch 06/50 | loss=1.7618 | 11m 18s (- 82m 52s)
Epoch 07/50 | loss=1.6348 | 13m 12s (- 81m 8s)
Epoch 08/50 | loss=1.5161 | 15m 7s (- 79m 25s)
Epoch 09/50 | loss=1.4053 | 16m 57s (- 77m 13s)
Epoch 10/50 | loss=1.3155 | 18m 58s (- 75m 55s)
Epoch 11/50 | loss=1.2337 | 20m 54s (- 74m 7s)
Epoch 12/50 | loss=1.1753 | 22m 43s (- 71m 58s)
Epoch 13/50 | loss=1.1012 | 24m 25s (- 69m 32s)
Epoch 14/50 | loss=1.0534 | 26m 14s (- 67m 28s)
Epoch 15/50 | loss=1.0193 | 28m 4s (- 65m 30s)
Epoch 16/50 | loss=0.9681 | 29m 56s (- 63m 36s)
Epoch 17/50 | loss=1.0654 | 31m 43s (- 61m 35s)
Epoch 18/50 | loss=1.1829 | 33m 31s (- 59m 35s)
Epoch 19/50 | loss=1.0981 | 35m 18s (- 57m 37s)
Epoch 20/50 | loss=1.0880 | 37m 4s (- 55m 37s)
Epoch 21/50 | loss=1.0441 | 38m 53s (- 53m 42s)
Epoch 22/50 | loss=1.1176 | 40m 37s (- 51m 42s)
Epoch 23/50 | loss=1.1178 | 42m 28s (- 49m 51s)
Epoch 24/50 | loss=1.0696 | 44m 17s (- 47m 58s)
Epoch 25/50 | loss=1.0698 | 46m 18s (- 46m 18s)
Epoch 26/50 | loss=1.2108 | 48m 20s (- 44m 37s)
Epoch 27/50 | loss=1.2562 | 50m 17s (- 42m 50s)
Epoch 28/50 | loss=1.6356 | 52m 11s (- 41m 0s)
Epoch 29/50 | loss=2.1992 | 54m 3s (- 39m 8s)
Epoch 30/50 | loss=2.6474 | 55m 52s (- 37m 14s)
Epoch 31/50 | loss=2.5006 | 57m 45s (- 35m 23s)
Epoch 32/50 | loss=2.4214 | 59m 37s (- 33m 32s)
Epoch 33/50 | loss=2.2804 | 61m 25s (- 31m 38s)
Epoch 34/50 | loss=2.1888 | 63m 16s (- 29m 46s)
Epoch 35/50 | loss=2.0915 | 65m 7s (- 27m 54s)
Epoch 36/50 | loss=2.0317 | 67m 0s (- 26m 3s)
Epoch 37/50 | loss=1.9680 | 68m 55s (- 24m 13s)
Epoch 38/50 | loss=1.9461 | 70m 51s (- 22m 22s)
Epoch 39/50 | loss=1.8671 | 72m 41s (- 20m 30s)
Epoch 40/50 | loss=1.8152 | 74m 28s (- 18m 37s)
Epoch 41/50 | loss=1.7699 | 76m 9s (- 16m 42s)
Epoch 42/50 | loss=1.7101 | 77m 51s (- 14m 49s)
Epoch 43/50 | loss=1.6571 | 79m 36s (- 12m 57s)
Epoch 44/50 | loss=1.6281 | 81m 17s (- 11m 5s)
Epoch 45/50 | loss=1.5804 | 83m 2s (- 9m 13s)
Epoch 46/50 | loss=1.5651 | 84m 49s (- 7m 22s)
Epoch 47/50 | loss=1.5663 | 86m 30s (- 5m 31s)
Epoch 48/50 | loss=1.5118 | 88m 17s (- 3m 40s)
Epoch 49/50 | loss=1.4827 | 90m 11s (- 1m 50s)
Epoch 50/50 | loss=1.4346 | 92m 2s (- 0m 0s)
Done.
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># =========================</span>
<span class="c1"># 2.b) Evaluate on 20 random sentences</span>
<span class="c1"># =========================</span>
<span class="c1"># - pairs_he_en : list of (he, en) after filter_pairs</span>
<span class="c1"># - input_lang, output_lang</span>
<span class="c1"># - encoder, decoder (trained)</span>

<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">evaluate_sentence</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">sentence_he</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">max_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">MAX_LENGTH</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Returns:</span>
<span class="sd">      decoded_words: list[str] (predicted English tokens, without EOS)</span>
<span class="sd">      attn_matrix: torch.Tensor shape (out_len, MAX_LENGTH)  (attention weights per output step)</span>
<span class="sd">    """</span>
    <span class="n">encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">decoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># to tensor</span>
    <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tensor_from_sentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">sentence_he</span><span class="p">)</span>  <span class="c1"># (L,1)</span>
    <span class="n">input_length</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">()</span>
    <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">ei</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_length</span><span class="p">):</span>
        <span class="n">enc_out</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">[</span><span class="n">ei</span><span class="p">],</span> <span class="n">encoder_hidden</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ei</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span><span class="p">:</span>
            <span class="n">encoder_outputs</span><span class="p">[</span><span class="n">ei</span><span class="p">]</span> <span class="o">=</span> <span class="n">enc_out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">SOS_token</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span>

    <span class="n">decoded_words</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">attn_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># (max_out, MAX_LENGTH)</span>

    <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
        <span class="n">dec_out</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
        <span class="n">attn_matrix</span><span class="p">[</span><span class="n">di</span><span class="p">]</span> <span class="o">=</span> <span class="n">attn_weights</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">topv</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">dec_out</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">next_idx</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">next_idx</span> <span class="o">==</span> <span class="n">EOS_token</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="n">decoded_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_lang</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="n">next_idx</span><span class="p">])</span>
        <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># (1,1)</span>

    <span class="k">return</span> <span class="n">decoded_words</span><span class="p">,</span> <span class="n">attn_matrix</span><span class="p">[:</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">decoded_words</span><span class="p">),</span> <span class="mi">1</span><span class="p">)]</span>  <span class="c1"># trim rows</span>


<span class="k">def</span> <span class="nf">evaluate_random_20</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">123</span><span class="p">):</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">Random</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">)))</span>

    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">=== Random evaluation (20 sentences) ===</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">he</span><span class="p">,</span> <span class="n">en_true</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">pred_words</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate_sentence</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">he</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">)</span>
        <span class="n">en_pred</span> <span class="o">=</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pred_words</span><span class="p">)</span>

        <span class="c1"># exact string match (same tokenization as your training data)</span>
        <span class="n">is_ok</span> <span class="o">=</span> <span class="p">(</span><span class="n">en_pred</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="n">en_true</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="n">is_ok</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[</span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">] HE:   </span><span class="si">{</span><span class="n">he</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"     TRUE: </span><span class="si">{</span><span class="n">en_true</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"     PRED: </span><span class="si">{</span><span class="n">en_pred</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"     OK:   </span><span class="si">{</span><span class="n">is_ok</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">acc</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span> <span class="k">if</span> <span class="n">sample</span> <span class="k">else</span> <span class="mf">0.0</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Exact-match on these </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples: </span><span class="si">{</span><span class="n">correct</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">acc</span>


<span class="c1"># Run 2.b:</span>
<span class="n">evaluate_random_20</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
=== Random evaluation (20 sentences) ===

[01] HE:    .
     TRUE: you re back again .
     PRED: you are a good .
     OK:   False

[02] HE:      .
     TRUE: i m looking forward to getting your letter .
     PRED: i m impressed with my friends .
     OK:   False

[03] HE:      .
     TRUE: i m depending on your help .
     PRED: i m depending on .
     OK:   False

[04] HE:        .
     TRUE: you re in quite a mood today .
     PRED: you re quite today .
     OK:   False

[05] HE:      .
     TRUE: we re not staying here .
     PRED: we re not here .
     OK:   False

[06] HE:     , ?
     TRUE: you re not happy are you ?
     PRED: you re not aren t you ?
     OK:   False

[07] HE:      .
     TRUE: you re all over the road .
     PRED: you re doing the .
     OK:   False

[08] HE:    .
     TRUE: you re babbling .
     PRED: you re babbling .
     OK:   True

[09] HE:      .
     TRUE: he s now studying .
     PRED: he s studying now .
     OK:   False

[10] HE:      .
     TRUE: i m just getting back to basics .
     PRED: i m just getting just a . . . .
     OK:   False

[11] HE:    .
     TRUE: we re going to be fine .
     PRED: we re going to be .
     OK:   False

[12] HE:     .
     TRUE: i m unprejudiced .
     PRED: i m not .
     OK:   False

[13] HE:    .
     TRUE: they re idiots .
     PRED: they re fools .
     OK:   False

[14] HE:      .
     TRUE: i m very good at it .
     PRED: i m very good at this .
     OK:   False

[15] HE:      .
     TRUE: he is always looking for praise .
     PRED: he s looking for a .
     OK:   False

[16] HE:      .
     TRUE: you re not very well informed .
     PRED: you re not very good a .
     OK:   False

[17] HE:      .
     TRUE: i m still waiting for a reply .
     PRED: i m still waiting for for for for for for
     OK:   False

[18] HE:       .
     TRUE: she is pigeon toed .
     PRED: he is an .
     OK:   False

[19] HE:    .
     TRUE: i m reliable .
     PRED: i m reliable .
     OK:   True

[20] HE:      .
     TRUE: i m not that surprised by it .
     PRED: i m not able .
     OK:   False

Exact-match on these 20 samples: 2/20 = 0.100
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[29]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>0.1</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>(b) The evaluation shows that the model produces exact translations for only a small number of sentences . This suggests that while the model has begun to learn basic sourcetarget correspondences, its overall translation performance is still limited, especially under greedy decoding and a strict exact-match evaluation criterion</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[30]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">show_attention</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">,</span> <span class="n">output_words</span><span class="p">,</span> <span class="n">attn_matrix</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    input_sentence: str (Hebrew)</span>
<span class="sd">    output_words: list[str] (predicted English tokens)</span>
<span class="sd">    attn_matrix: Tensor (out_len, MAX_LENGTH)</span>
<span class="sd">    """</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>

    <span class="n">attn</span> <span class="o">=</span> <span class="n">attn_matrix</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">output_words</span><span class="p">)]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"bone"</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="p">)</span>

    <span class="c1"># ticks</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_words</span><span class="p">)))</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">input_sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(),</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">output_words</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Input (Hebrew)"</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"Output (English)"</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">attention_random_5</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">):</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">Random</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">he</span><span class="p">,</span> <span class="n">en_true</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">pred_words</span><span class="p">,</span> <span class="n">attn</span> <span class="o">=</span> <span class="n">evaluate_sentence</span><span class="p">(</span>
            <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">he</span><span class="p">,</span> <span class="n">MAX_LENGTH</span>
        <span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">[</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">]"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"HE:   "</span><span class="p">,</span> <span class="n">he</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"TRUE: "</span><span class="p">,</span> <span class="n">en_true</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"PRED: "</span><span class="p">,</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pred_words</span><span class="p">))</span>

        <span class="n">show_attention</span><span class="p">(</span><span class="n">he</span><span class="p">,</span> <span class="n">pred_words</span><span class="p">,</span> <span class="n">attn</span><span class="p">)</span>


<span class="c1"># Run 2.c:</span>
<span class="n">attention_random_5</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
[1]
HE:     .
TRUE:  you re back again .
PRED:  you are a good .
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
[2]
HE:       .
TRUE:  i m looking forward to getting your letter .
PRED:  i m impressed with my friends .
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
[3]
HE:       .
TRUE:  i m depending on your help .
PRED:  i m depending on .
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
[4]
HE:         .
TRUE:  you re in quite a mood today .
PRED:  you re quite today .
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
[5]
HE:       .
TRUE:  we re not staying here .
PRED:  we re not here .
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAucAAAJNCAYAAACSgNtAAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARKRJREFUeJzt3Xt8FPW9//H3kpCEWxYwkIBELoISwICQakEhiMhFq1KpUKlcvBRToQgoKiAQEUTxRlXAGxe1ilQUof3FS0RAELwhKEoUCsGkmBi5JSCSQHZ+f8TscUyCu2FnZzb7euYxj5OdnZ3vZ6QHPnnnO99xGYZhCAAAAIDtatldAAAAAIAyNOcAAACAQ9CcAwAAAA5Bcw4AAAA4BM05AAAA4BA05wAAAIBD0JwDAAAADkFzDgAAADgEzTkAAADgEDTnAAAAgEPQnAMAAAC/8v777+vKK69U8+bN5XK59MYbb/zmZ9avX69u3bopJiZGbdq00VNPPeX3uDTnAAAAwK/8+OOP6ty5s5588kmfjs/Oztbll1+unj17auvWrZoyZYrGjRun1157za9xXYZhGNUpGAAAAAgHLpdLK1eu1KBBg6o85q677tLq1auVlZXl3ZeWlqbPP/9cmzdv9nmsyNMpFAAAAKiu48ePq6SkJChjGYYhl8tl2hcdHa3o6OiAnH/z5s3q16+faV///v21aNEinThxQrVr1/bpPDTnAAAACLrjx4+rdevWys/PD8p49evX19GjR037ZsyYofT09ICcPz8/X/Hx8aZ98fHxOnnypPbv369mzZr5dB6acwAAAARdSUmJ8vPzlZubq9jYWEvHKioqUmJiYoWxApWal/t1Ml8+e/zX+0+F5hwAAAC2adCggRo0aGDpGOVNcmxsrGU/CCQkJFT4LUBBQYEiIyN1xhln+HweVmsBAAAATlP37t2VmZlp2vfOO+8oJSXF5/nmEs05AAAAbOQxjKBs/jp69Ki2bdumbdu2SSpbKnHbtm3KycmRJE2ePFkjRozwHp+WlqZvv/1WEydOVFZWlhYvXqxFixbpjjvu8GtcprUAAAAAv/Lpp5/qkksu8b6eOHGiJGnkyJFaunSp8vLyvI26JLVu3VoZGRmaMGGC5s+fr+bNm+vxxx/X4MGD/RqXdc4BAAAQdEVFRXK73Tpw8GBQbgg9o3FjFRYWWj7W6WJaCwAAAOAQTGsBAACAbYyfv6weI1SQnAMAAAAOQXIOAAAA23iMss3qMUIFyTkAAADgEDTnAAAAgEMwrQUAAAC2MQxDVq/sHUorh5OcAwAAAA5Bcg4AAADbeAxDHouTbavPH0gk5wAAAIBDkJwDAADANsw5NyM5BwAAAByC5BwAAAC2ITk3IzkHAAAAHILkHAAAALZhtRYzknMAAADAIUjOAQAAYBvmnJuRnAMAAAAOQXMOAAAAOATTWgAAAGAb4+cvq8cIFSTnAAAAgEOQnAMAAMA2HqNss3qMUEFyDgAAADgEyTkAAADsE4SlFMVSigAAAAD8RXIOAAAA23gMQx6Lk22rzx9IJOcAAACAQ5CcAwAAwDZGEOacWz6nPYBIzgEAAACHIDkHAACAbUjOzUjOAQAAAIegOQcAAAAcgmktAAAAsA1LKZqRnAMAAAAOQXIOAAAA23BDqBnJOQAAAOAQJOcAAACwjfHzl9VjhAqScwAAAMAhSM4BAABgG49Rtlk9RqggOQcAAAAcguQcAAAAtjFk/WoqIRSck5wDAAAATkFyDgAAANuwzrkZyTkAAADgEDTnAAAAgEMwrQUAAAC28RiGPBZPO7H6/IFEcg4AAAA4BMk5AAAAbMMNoWYk5wAAAIBDkJwDAADANsw5NyM5BwAAAByC5BwAAAD2CcKcc5GcAwAAAPAXyTkAAABsY/z8ZfUYoYLkHAAAAHAIknMAAADYxmOUbVaPESpIzgEAAACHoDkHAAAAHIJpLQAAALCNEYSlFC1fqjGASM4BAAAAhyA5BwAAgG1Izs1IzgEAAACHIDkHAACAbTyGIY/FybbV5w8kknMAAADAIUjOAQAAYBvmnJuRnAMAAAAOQXIOAAAA25Ccm5GcAwAAAA5Bcw4AAAA4BNNaAAAAYBuWUjQjOQcAAAAcguQcAAAAtjF+/rJ6jFBBcg4AAAA4BMk5AAAAbOMxyjarxwgVJOcAAACAQ5CcAwAAwDY8hMiM5BwAAABwCJJzAAAA2Ibk3IzmHDhNP/zwg1atWqWCggKdPHnS9N706dNtqgoAAIQimnPgNKxevVrDhg1TfHy8EhISVKvW/80U27x5M805AAC/wQjCE0JJzoEwMWPGDC1cuFDDhw+v8F6dOnVsqAgAAIQybggFTsPOnTv15z//udL3XC5XkKsBAAChjuQcOA2GYah27dp2lwEAQMjihlAzmnPgNFX2l0oo/SUAAACcg+YcOA3Hjx9XZCT/bwQAQHUZsj7UCqXIjK4COA1r1661uwQAAFCD0JwDpyE1NdXuEgAACGmeICylaPX5A4nmHDgNI0aMML0ePXq0Lr74YpuqAQAAoY6lFIHTEBERYdq+/vpru0sCACCkGEH6ChUk58BpWLJkid0lAACAGoTmHAiA77//XtnZ2Tp27Jhpf58+fWyqCACA0OAxyjarxwgVNOc26tmz5ymfIvn+++8HsRpUx+HDhzVy5Ej95z//qbAMlMvlUmlpqU2VAQCAUERzbqO+ffvaXQJO05QpU5Sfn6/NmzcrOTlZMTExdpcEAEBI4QmhZjTnNpoxY4bdJeA0vfnmm3rzzTfVvn17u0sBAAA1AM25Q3g8ngr7atViMR2nKygooDEHAAABQ/dno08++UQXXHCB6tatq9q1a5u2qKgou8uDDyr7oQoAAPiufFqL1VuoIDm30a233qrf/e53mj17tqkZNwxDAwYMsLEy+Kpfv352lwAAAGoQmnMbZWVl6aOPPqp0+sqpVnGBc6xatcruEgAACGkew5DH4mTb6vMHEs25jSZPnlzlvPJrrrkmyNWgOhYvXqzatWsrISFBv//979WgQQPve3l5eWrWrJmN1Vnr008/1bFjx9SrVy+7SwEAoMZwGaE0CQdwmNatW0sqW++8tLRUzz33nIYMGaIlS5bo9ttv18GDB22u0DpJSUnauXMna7kDAKqlqKhIbrdbqz78UPXq17d0rB+PHtXVv/+9CgsLFRsba+lYp4vk3GZ79+7V22+/re+//14nT540vTdz5kybqoKvsrOzvd+/9957uv7667V48WJt3LhRs2fPtrEy661Zs0YnTpywuwwAACyzYMECPfTQQ8rLy1PHjh01b9489ezZs8rjX3rpJc2dO1e7du2S2+3WgAED9PDDD+uMM87weUyacxu9/vrruu6669SmTRs1bdrUNMWFOeehZ9euXTpy5IhOnjyp7du3e1P1mqp58+Z2lwAAqAGc+hCi5cuXa/z48VqwYIEuuugiPf300xo4cKB27Nihs846q8LxGzdu1IgRI/TYY4/pyiuv1L59+5SWlqabb75ZK1eu9HlcprXYqEuXLpoyZYqGDBlidyk4DXv27NFNN92kzz77TI8++qhuuukmu0sKqD179vh8bJs2bSysBABQk5RPa3lj8+agTGsZ1L27X9NaLrzwQnXt2lULFy707ktKStKgQYM0Z86cCsc//PDDWrhwoXbv3u3d98QTT2ju3LnKzc31uVaScxvt2rWLGz9D3GOPPaZp06apV69eqlu3rs4++2y7Swq4tm3b/uZvcgzDkMvlYv45AMBvwVytpaioyLQ/Ojpa0dHRFY4vKSnRli1bdPfdd5v29+vXT5s2bap0jB49emjq1KnKyMjQwIEDVVBQoBUrVuiKK67wq1aacxsZhqHISP4IQtmsWbO0YMECjRgxQq+99pquvvpquVwu70/lOTk5Nld4+n45rx4AgFCWmJhoej1jxgylp6dXOG7//v0qLS1VfHy8aX98fLzy8/MrPXePHj300ksvaejQoTp+/LhOnjypq666Sk888YRfNdIZ2sjj8Wjt2rVVzoPq06dPkCsKLI/HU+VSkTXFV199pYSEBEnS4MGD1a9fP23evFk//PBDhRt8Q1XLli3tLgEAUIMZP39ZPYYk5ebmmqa1VJaa/9Kvf3Nc/pviyuzYsUPjxo3T9OnT1b9/f+Xl5WnSpElKS0vTokWLfK6V5txGJSUluvTSSyt9ryZMEYiMjFRERISaNm2qSy+9VA8++KCaNWum/fv3a8yYMVq+fLndJZ628sa8XIMGDWrcU0PDeS13AEDNEhsb69Oc87i4OEVERFRIyQsKCiqk6eXmzJmjiy66SJMmTZIkJScnq169eurZs6dmzZrl87+XNOc28ng8dpdgqbVr10qSDh06pJUrV2rAgAG6++67NW7cuBpz42C/fv3Upk0bderUSSkpKbrgggtq3G8L7rvvPknhuZY7ACA8RUVFqVu3bsrMzNQf//hH7/7MzExdffXVlX7m2LFjFaYrR0RESPJvtRiac1gmNTXV+/3vf/97de3aVTfffLNmzJihO+64w8bKAqdbt246fPiw3nzzTd1///0qLS3V6NGjNXnyZNWtW9fu8gIinNdyBwBYzzDKNqvH8NfEiRM1fPhwpaSkqHv37nrmmWeUk5OjtLQ0SWVPet+3b59eeOEFSdKVV16pv/71r1q4cKF3Wsv48eN1wQUX+LX8MM25zTIyMrR9+3b9+OOPFd6rKQ8hev755zVx4kR17NhRixYtUrt27ewuKWB+vZTSpk2bNGXKFGVmZmrt2rWqU6eOTZVZI9zWcgcAhK+hQ4fqwIEDmjlzpvLy8tSpUydlZGR478XKy8szLfwwatQoHTlyRE8++aRuv/12NWzYUH369NGDDz7o17isc26j8ePHa9GiRUpOTlZUVJTpvQ0bNoT8DYW5ubn661//qo0bN8rtdmv37t2KiYmxuyzLlZaWauDAgerbt6/uvPNOu8sJiJq+ljsAIPjK1zl/deNG1bV4nfNjR4/q2osv9mudc7vUrMmxIWb58uXasmWLPvjgA61du9a0/bpZD0UdO3bUyZMn9eWXX+qSSy5R586dNX78eE2fPl3Tp0+3u7yAiIyMVIMGDdS+fXtNmTJFx48fV0REhKZMmeLX08Cc7LHHHlNycrLq1KlTY9dyBwDAKZjWYqPDhw/rnHPOqfS9mvALjYceeki33HKLJOnFF1/U0qVLlZmZqa+++irkV6Ipt3fvXu3bt09ZWVmaP3++/ve//+mFF17QhRdeqG+++cbu8gIiHNZyBwDYxzAMy/ueUOqrmNZio1OtA56VlaWkpKQgV4TT8f3336tTp07au3evvvnmG/Xo0UPHjx+3u6zTlp+fb1oy8siRI6a13EeOHGljdQCAUFU+reVfGzYEZVrLkJ49Q2JaC8m5jU61Dnh6enrIrwN+zjnn6IorrtDo0aNr7A8aCxcu1N69e73bgQMHFBsbK8MwqlwHNdQkJCTo6NGj+te//qXPPvtMLpdL559/voYMGaL6Fv9lCgCo+TyGIY/FWbHV5w8k5pzbaO3atXr33Xc1f/58uVwuDRgwQMuWLVNSUpL27t1rd3mnLTs7W2vXrlWnTp3Us2dPvfTSSyouLra7rIBasGCBvv76azVr1kx/+ctftGrVKn3xxRc6evSo8vLy7C4vIPbs2aPzzjtPs2fPVl5envLy8nT//ffrvPPO03//+1+7ywMAoEZhWotD5Ofnq2vXriosLPSuAx7qD7OpW7eujh07po8//ljPPfecli9frsjISI0cOVKjR49W+/bt7S4xIA4dOqSdO3dWuhxmnz59bKgosK699lqdffbZeuCBB0z7p06dqh07dtSYG18BAMFVPq1l2fr1QZnWcl1qakhMa6E5d4Caug54eXNe7tixY3rllVe0aNEiffjhhzXiptAXXnhBaWlpKi4urnCzSa1atUJ+OUxJatasmXbs2KFGjRqZ9h8+fFjnnnuuvv/+e5sqAwCEMprzyoV2NBvicnNzNWDAAI0ZM0YxMTF65513akxjXpm6devqxhtv1AcffKAvv/zS7nIC4t5779WiRYt0/PhxeTwe01a7dm27ywuIoqKiCo25JDVs2FBHjhyxoSIAQE1SvlqL1Vuo4IZQG3Xs2FEXXHCBvvzyS91zzz3q3LmzBg4c6P2JLlSfEJqYmCiXy3XKY2rKDaJ5eXm67rrr7C7DUh6Pp8r3QukvOwAAQgHNuY1q6jrgs2bNkiRFRETYXIn13n777SrfmzdvXvAKsdCLL75YrfcAAID/mHMOAACAoCufc/7PtWuDMuf8+ksuYc45AAAAAN8xrQUAAAC2MX7+snqMUEFy7hDFxcVKT0+vcQ/p+aWafo01/fqk8LhGAADsxJxzhyifdxUKc6Gqq6ZfY02/Pik8rhEAEBzl/6a88N57QZlzPqJPn5D494vkHAAAAHAI5pwDAADANh7DkMfiiRxWnz+QaM6r4PF49N1336lBgwa/+UCdQCgqKjL935qopl9jTb8+KTyuEQBqKsMwdOTIETVv3ly1ajF5wqlozqvw3XffKTExMejj2jFmsNX0a6zp1yeFxzUCQE2Vm5urFi1a2F2GlyHrnzgdOrk5zXmVGjRoIKnsf8BOv3HgdLjdbrtLAAAAQVTe48CZaM6rUD6VJTY2tkY35wAAILwEY7ouqo/mHAAAALbhhlAz7gYAAAAAHILkHAAAALYxDMP6G0JJzgEAAAD4i+QcAAAAtiE5NyM5BwAAAByC5BwAAAD2MYyyzeoxQgTJOQAAAOAQJOcAAACwjeExZHgsnnNu8fkDieQcAAAAcAiScwAAANgnCFPOFTrBOck5AAAA4BQ05wAAAIBDMK0FAAAAtuEhRGYk5wAAAIBDkJwDAADANiTnZiTnAAAAgEOQnAMAAMA2JOdmJOcAAACAQ5CcAwAAwDaGx5DhsTg5t/j8gURyDgAAADgEyTkAAABsw5xzM5JzAAAAwCFCpjn/97//rYYNG8rj8UiStm3bJpfLpUmTJnmPueWWW3TddddJkjZt2qRevXqpTp06SkxM1Lhx4/Tjjz/aUjsAAAAqV56cW72FipBpznv16qUjR45o69atkqT169crLi5O69ev9x6zbt06paamavv27erfv7+uueYaffHFF1q+fLk2btyosWPHVnn+4uJiFRUVmTYAAAAgmEKmOXe73erSpYvWrVsnqawRnzBhgj7//HMdOXJE+fn52rlzp3r37q2HHnpIw4YN0/jx49WuXTv16NFDjz/+uF544QUdP3680vPPmTNHbrfbuyUmJgbx6gAAAIAQas4lqXfv3lq3bp0Mw9CGDRt09dVXq1OnTtq4caPWrl2r+Ph4tW/fXlu2bNHSpUtVv35979a/f395PB5lZ2dXeu7JkyersLDQu+Xm5gb56gAAAMKQYQRnCxEhtVpL7969tWjRIn3++eeqVauWOnTooNTUVK1fv16HDh1SamqqJMnj8eiWW27RuHHjKpzjrLPOqvTc0dHRio6OtrR+AAAA4FRCqjkvn3c+b948paamyuVyKTU1VXPmzNGhQ4d02223SZK6du2qr776Sm3btrW5YgAAAJxKMILtEArOQ2taS/m883/+85/q3bu3pLKG/bPPPvPON5eku+66S5s3b9aYMWO0bds27dq1S6tXr9bf//53+4oHAAAAfkNINeeSdMkll6i0tNTbiDdq1EgdOnRQkyZNlJSUJElKTk7W+vXrtWvXLvXs2VPnn3++pk2bpmbNmtlYOQAAAH7NMAwZHou3EIrOXUYoVRtERUVFcrvdKiwsVGxsrN3lWMblctldAgAACCKn9DblvdbjK95Qnbr1LB3rp2M/atyfBjnm2k8lpOacAwAAoGYJxkOCQimLDrlpLQAAAEBNRXIOAAAA25Ccm5GcAwAAAA5Bcg4AAADbkJybkZwDAAAADkFzDgAAADgE01oAAABgG6a1mJGcAwAAAA5Bcg4AAAD7eCR5LE62PdaePpBIzgEAAACHIDkHAACAbZhzbkZyDgAAADgEyTkAAABsYxhlm9VjhAqScwAAAMAhSM4BAABgG+acm5GcAwAAAA5Bcg4AAADbkJybkZwDAAAADkFzDgAAADgE01oAAABgG8NjyPBYPK3F4vMHEs35b3C73XaXACAMhNJ8yOpyuVx2lwAAjkdzDgAAAPsE4YbQUHoKEXPOAQAAAIcgOQcAAIBtWErRjOQcAAAAcAiScwAAANiG5NyM5BwAAABwCJJzAAAA2McwrF9NheQcAAAAgL9IzgEAAGAbw1O2WT1GqCA5BwAAAByC5hwAAABwCKa1AAAAwDaGgrCUorghFAAAAICfSM4BAABgGx5CZEZyDgAAADgEyTkAAABsQ3JuRnIOAAAAOATJOQAAAGxDcm5Gcg4AAAA4BMk5AAAAbGN4DBkei5Nzi88fSCTnAAAAgEPQnAMAAAAOwbQWAAAA2McwyjarxwgRJOcAAACAQ5CcAwAAwDYspWhW45LzkpISu0sAAABADbBgwQK1bt1aMTEx6tatmzZs2HDK44uLizV16lS1bNlS0dHROvvss7V48WK/xgz55rx3794aO3asJk6cqLi4OF122WXasWOHLr/8ctWvX1/x8fEaPny49u/fb3epAAAA+JXyKedWb/5avny5xo8fr6lTp2rr1q3q2bOnBg4cqJycnCo/M2TIEK1Zs0aLFi3SN998o2XLlql9+/Z+jRvyzbkkPf/884qMjNQHH3ygBx54QKmpqerSpYs+/fRTvfXWW/r+++81ZMiQU56juLhYRUVFpg0AAADh6dFHH9VNN92km2++WUlJSZo3b54SExO1cOHCSo9/6623tH79emVkZKhv375q1aqVLrjgAvXo0cOvcWtEc962bVvNnTtX5557rt5880117dpV999/v9q3b6/zzz9fixcv1tq1a7Vz584qzzFnzhy53W7vlpiYGMQrAAAACE/lc86t3iRVCGKLi4srramkpERbtmxRv379TPv79eunTZs2VfqZ1atXKyUlRXPnztWZZ56pc845R3fccYd++uknv/571IjmPCUlxfv9li1btHbtWtWvX9+7lf86Yffu3VWeY/LkySosLPRuubm5ltcNAACA4ElMTDSFsXPmzKn0uP3796u0tFTx8fGm/fHx8crPz6/0M3v27NHGjRv15ZdfauXKlZo3b55WrFihMWPG+FVjtVZryc3N1d69e3Xs2DE1adJEHTt2VHR0dHVOFRD16tXzfu/xeHTllVfqwQcfrHBcs2bNqjxHdHS0rdcAAAAQjgyPIcNj8WotP58/NzdXsbGx3v2/1fu5XC7zeQyjwr5yHo9HLpdLL730ktxut6SyqTF/+tOfNH/+fNWpU8enWn1uzr/99ls99dRTWrZsmXJzc01L0kRFRalnz54aPXq0Bg8erFq17Avku3btqtdee02tWrVSZCQrRQIAAKBMbGysqTmvSlxcnCIiIiqk5AUFBRXS9HLNmjXTmWee6W3MJSkpKUmGYeh///uf2rVr51ONPnXRt912m8477zzt2rVLM2fO1FdffaXCwkKVlJQoPz9fGRkZuvjiizVt2jQlJyfrk08+8WlwK4wZM0YHDx7Uddddp48//lh79uzRO++8oxtvvFGlpaW21QUAAICKgjnn3FdRUVHq1q2bMjMzTfszMzOrvMHzoosu0nfffaejR4969+3cuVO1atVSixYtfB7bp+Y8KipKu3fv1ooVKzRixAi1b99eDRo0UGRkpJo2bao+ffpoxowZ+vrrrzV37lx9++23PhcQaM2bN9cHH3yg0tJS9e/fX506ddJtt90mt9tta6IPAACA0DFx4kQ999xzWrx4sbKysjRhwgTl5OQoLS1NUtn9iiNGjPAeP2zYMJ1xxhm64YYbtGPHDr3//vuaNGmSbrzxRp+ntEg+Tmt56KGHfD7h5Zdf7vOxgbBu3boK+9q1a6fXX389qHUAAACg5hg6dKgOHDigmTNnKi8vT506dVJGRoZatmwpScrLyzOteV6/fn1lZmbq73//u1JSUnTGGWdoyJAhmjVrll/juoxQep5pEBUVFZnmDAGAlcLhr+KqbqICEFyFhYU+zbu2WnmvNfWRZxTjR7JcHcd/+kmzbx/tmGs/Fb/neXz//fcaPny4mjdvrsjISEVERJg2AAAAANXj93Imo0aNUk5OjqZNm6ZmzZqRhAAAAKDaqnPDZnXGCBV+N+cbN27Uhg0b1KVLFwvKAQAAAMKX3815YmJiSP30AQAAAOciOTfze875vHnzdPfdd2vv3r0WlAMAAACEL5+S80aNGpnmlv/44486++yzVbduXdWuXdt07MGDBwNbIQAAAGouj1G2WT1GiPCpOZ83b57FZQAAAADwqTkfOXKk1XUAAAAgDBmSrJ4SHjq5eTXmnH/22Wfavn279/WqVas0aNAgTZkyRSUlJQEtDgAAAAgnfjfnt9xyi3bu3ClJ2rNnj4YOHaq6devq1Vdf1Z133hnwAgEAAFCD/bxai5Wb5dF8APndnO/cudO7xvmrr76q1NRUvfzyy1q6dKlee+21QNcHAAAAhA2/m3PDMOTxeCRJ7777ri6//HJJZeuf79+/P7DVAQAAAGHE74cQpaSkaNasWerbt6/Wr1+vhQsXSpKys7MVHx8f8AIBAABQc/EQIrNqPYTos88+09ixYzV16lS1bdtWkrRixQr16NEj4AUCAAAA4cLv5Dw5Odm0Wku5hx56SBEREQEpCgAAAOHB8BgyLH5IkNXnDyS/m/OqxMTEBOpUAAAAQFjyqTlv3Lixdu7cqbi4ODVq1Egul6vKYw8ePBiw4gAAAFCzMefczKfm/LHHHlODBg0klc05BwAAABB4PjXnI0eOrPR7AAAA4HSQnJv51JwXFRX5fMLY2NhqFwMAAACEM5+a84YNG55ynrlU9hOJy+VSaWlpQAoDAABAGDCMss3qMUKET8352rVrra4DAAAACHs+NeepqalW1wEAAIAwxJxzM7/XOf/iiy8q3e9yuRQTE6OzzjpL0dHRp10YAAAAEG78bs67dOlyyvnntWvX1tChQ/X000/zYCIAAADAD7X8/cDKlSvVrl07PfPMM9q2bZu2bt2qZ555Rueee65efvllLVq0SO+9957uueceK+oFAABADWJ4grOFCr+T89mzZ+sf//iH+vfv792XnJysFi1aaNq0afr4449Vr1493X777Xr44YcDWiwAAABQk/ndnG/fvl0tW7assL9ly5bavn27pLKpL3l5eadfHQAAAGo0bgg183taS/v27fXAAw+opKTEu+/EiRN64IEH1L59e0nSvn37FB8fH7gqAQAAgDDgd3I+f/58XXXVVWrRooWSk5Plcrn0xRdfqLS0VP/5z38kSXv27NGtt94a8GIBAABQs5Ccm/ndnPfo0UN79+7VP//5T+3cuVOGYehPf/qThg0bpgYNGkiShg8fHvBCAQAAgJrO7+ZckurXr6+0tLRA1wIAAIAwQ3JuVq3mfOfOnVq3bp0KCgrk8ZjXppk+fXpACgMAAADCjd/N+bPPPqu//e1viouLU0JCgumBRC6Xi+YcAAAAPiM5N/O7OZ81a5Zmz56tu+66y4p6AAAAgLDld3N+6NAhXXvttVbUAgAAgDBjeAwZHouTc4vPH0h+r3N+7bXX6p133rGiFgAAACCs+Z2ct23bVtOmTdOHH36o8847T7Vr1za9P27cuIAVBwAAAIQTv5vzZ555RvXr19f69eu1fv1603sul4vmHAAAAD7jhlAzv5vz7OxsK+oAAAAAwl611jkHAAAAAsOQLE+2Qyc59/mG0A4dOujgwYPe16NHj9YPP/zgfV1QUKC6desGtjoAAAAgjPjcnH/99dc6efKk9/Urr7yiI0eOeF8bhqHjx48HtjoAAADUaIYRnC1U+L2UYrnKJtb/8mmhAAAAAPzDnHMAAADYpizZtnq1FktPH1A+J+cul6tCMu70pDw9PV1dunSxuwwAAADAJz4n54Zh6NJLL1VkZNlHfvrpJ1155ZWKioqSJNN8dAAAAMAXhseQ4bE4Obf4/IHkc3M+Y8YM0+urr766wjGDBw8+/Yp+oXfv3kpOTlZMTIyee+45RUVFKS0tTenp6ZKknJwc/f3vf9eaNWtUq1YtDRgwQE888YTi4+O1dOlS3XvvvZL+L+FfsmSJRo0aFdAaAQAAgECpdnMeLM8//7wmTpyojz76SJs3b9aoUaN00UUXqW/fvho0aJDq1aun9evX6+TJk7r11ls1dOhQrVu3TkOHDtWXX36pt956S++++64kye12VzlOcXGxiouLva+LioosvzYAAADglxx/Q2hycrL3B4N27drpySef1Jo1ayRJX3zxhbKzs5WYmChJevHFF9WxY0d98skn+t3vfqf69esrMjJSCQkJvznOnDlzvEk7AAAAgsMwjCDcEBo601p8uiF0wIAB2rRp028ed+TIET344IOaP3/+aRdWLjk52fS6WbNmKigoUFZWlhITE72NuVT2oKSGDRsqKyvL73EmT56swsJC75abm3vatQMAAAD+8Ck5v/baazVkyBA1aNBAV111lVJSUtS8eXPFxMTo0KFD2rFjhzZu3KiMjAz94Q9/0EMPPRSwAmvXrm167XK55PF4ZBhGpavFVLX/t0RHRys6OrradQIAAMB/JOdmPjXnN910k4YPH64VK1Zo+fLlevbZZ3X48GFJZc1yhw4d1L9/f23ZskXnnnuulfV6dejQQTk5OcrNzfWm5zt27FBhYaGSkpIkSVFRUSotLQ1KPQAAAMDp8nnOeVRUlIYNG6Zhw4ZJkgoLC/XTTz/pjDPOqJBuB0Pfvn2VnJysv/zlL5o3b573htDU1FSlpKRIklq1aqXs7Gxt27ZNLVq0UIMGDUjHAQAAnCQIyXkoPYXI54cQ/Zrb7VZCQoItjblUlti/8cYbatSokXr16qW+ffuqTZs2Wr58ufeYwYMHa8CAAbrkkkvUpEkTLVu2zJZaAQAAAF84erWWdevWVdj3xhtveL8/66yztGrVqio/Hx0drRUrVlhQGQAAAALCMKxPtsMhOQcAAAAQWI5OzgEAAFCzGR5Dhsfi1VosPn8gkZwDAAAADuF3c96mTRsdOHCgwv7Dhw+rTZs2ASkKAAAA4aF8yrnVW6jwuznfu3dvpWuHFxcXa9++fQEpCgAAAAhHPs85X716tff7t99+W2632/u6tLRUa9asUatWrQJaHAAAABBOfG7OBw0aJKlsffGRI0ea3qtdu7ZatWqlRx55JKDFAQAAoGYzgvAQIssfchRAPjfnHo9HktS6dWt98skniouLs6woAAAAIBz5vZRidna2FXUAAAAgDJGcm/ndnM+cOfOU70+fPr3axQAAAADhzO/mfOXKlabXJ06cUHZ2tiIjI3X22WfTnAMAAMBnJOdmfjfnW7durbCvqKhIo0aN0h//+MeAFAUAAACEo4A8ITQ2NlYzZ87UtGnTAnE6AAAAhAnDYwRlCxUBac6lsieEFhYWBup0AAAAQNjxe1rL448/bnptGIby8vL04osvasCAAQErDAAAADUfc87N/G7OH3vsMdPrWrVqqUmTJho5cqQmT54csMIAAACAcMM65wAAALCRIVmebIdOcn5ac85zc3P1v//9L1C1AAAAAGHN7+b85MmTmjZtmtxut1q1aqWWLVvK7Xbrnnvu0YkTJ6yoEQAAAAgLfk9rGTt2rFauXKm5c+eqe/fukqTNmzcrPT1d+/fv11NPPRXwIgEAAFAzcUOomd/N+bJly/TKK69o4MCB3n3Jyck666yz9Oc//5nmHEDAhdJfqtXlcrnsLgEA4AB+N+cxMTFq1apVhf2tWrVSVFRUIGoCAABAmDCCcD9oKGU8fs85HzNmjO677z4VFxd79xUXF2v27NkaO3ZsQIsDAAAAwonfyfnWrVu1Zs0atWjRQp07d5Ykff755yopKdGll16qa665xnvs66+/HrhKAQAAUOMYHkOGx+I55xafP5D8bs4bNmyowYMHm/YlJiYGrCAAAAAgXPndnC9ZssSKOgAAABCGWK3FzO8553369NHhw4cr7C8qKlKfPn0CURMAAAAQlvxOztetW6eSkpIK+48fP64NGzYEpCgAAACEB5JzM5+b8y+++ML7/Y4dO5Sfn+99XVpaqrfeektnnnlmYKsDAAAAwojPzXmXLl3kcrnkcrkqnb5Sp04dPfHEEwEtDgAAADUbybmZz815dna2DMNQmzZt9PHHH6tJkybe96KiotS0aVNFRERYUiQAAAAQDnxuzlu2bClJ8ng8lhUDAAAAhDO/bwh94YUXTvn+iBEjql0MAAAAwothWD/tJIRmtfjfnN92222m1ydOnNCxY8cUFRWlunXr0pwDAAAA1eR3c37o0KEK+3bt2qW//e1vmjRpUkCKAgAAQHgwPIYMj8XJucXnDyS/H0JUmXbt2umBBx6okKoDAAAA8J3fyXlVIiIi9N133wXqdAAAAAgHZZPOrR8jRPjdnK9evdr02jAM5eXl6cknn9RFF10UsMIAAACAcON3cz5o0CDTa5fLpSZNmqhPnz565JFHAlUXAAAAwgDBuZnfzTnrnAMAAADWqPac8/3798vlcumMM84IZD0AAAAII4ZhBGGd89CJzv1areXw4cMaM2aM4uLiFB8fr6ZNmyouLk5jx47V4cOHLSoRAAAACA8+J+cHDx5U9+7dtW/fPv3lL39RUlKSDMNQVlaWli5dqjVr1mjTpk1q1KiRlfUCAACgJglCch5Kk859bs5nzpypqKgo7d69W/Hx8RXe69evn2bOnKnHHnss4EUCAAAA4cDnaS1vvPGGHn744QqNuSQlJCRo7ty5WrlyZUCLAwAAAMKJz815Xl6eOnbsWOX7nTp1Un5+vl+D9+7dW+PHj/frMwAAAKg5DI8RlK06FixYoNatWysmJkbdunXThg0bfPrcBx98oMjISHXp0sXvMX1uzuPi4rR3794q38/OzmblFgAAANQIy5cv1/jx4zV16lRt3bpVPXv21MCBA5WTk3PKzxUWFmrEiBG69NJLqzWuz835gAEDNHXqVJWUlFR4r7i4WNOmTdOAAQOqVUSgnDhxwtbxAQAA4J/ypRSt3iSpqKjItBUXF1dZ16OPPqqbbrpJN998s5KSkjRv3jwlJiZq4cKFp7yeW265RcOGDVP37t2r9d/D5+b83nvv1TfffKN27dpp7ty5Wr16tVavXq0HHnhA7dq1U1ZWltLT0/0uwOPx6M4771Tjxo2VkJBgOkdhYaFGjx6tpk2bKjY2Vn369NHnn3/ufT89PV1dunTR4sWL1aZNG0VHR8swjN/8XGWKi4sr/IEBAACg5khMTJTb7fZuc+bMqfS4kpISbdmyRf369TPt79evnzZt2lTl+ZcsWaLdu3drxowZ1a7R59VaWrRooc2bN+vWW2/V5MmTvT+BuFwuXXbZZXryySeVmJjodwHPP/+8Jk6cqI8++kibN2/WqFGjdNFFF6lv37664oor1LhxY2VkZMjtduvpp5/WpZdeqp07d6px48aSpP/+97/617/+pddee00RERGS5NPnfm3OnDm69957/a4fAAAA1WcoCA8hUtn5c3NzFRsb690fHR1d6fH79+9XaWlphYVQ4uPjq7zHcteuXbr77ru1YcMGRUZW+zmf/j0htHXr1nrzzTd16NAh7dq1S5LUtm3bKhteXyQnJ3t/umjXrp2efPJJrVmzRhEREdq+fbsKCgq8/+EefvhhvfHGG1qxYoVGjx4tqewnmxdffFFNmjSRJL333ns+fe7XJk+erIkTJ3pfFxUVVeuHDQAAADhTbGysqTn/LS6Xy/TaMIwK+ySptLRUw4YN07333qtzzjnntGqsVlvfqFEjXXDBBac1cLnk5GTT62bNmqmgoEBbtmzR0aNHK9xk+tNPP2n37t3e1y1btvQ25pJ8/tyvRUdHV/nTEwAAAKzxyznhVo7hj7i4OEVERFRIyQsKCipdVvzIkSP69NNPtXXrVo0dO1ZS2dRtwzAUGRmpd955R3369PFp7Opn7gFSu3Zt02uXyyWPxyOPx6NmzZpp3bp1FT7TsGFD7/f16tUzvefr5wAAAIDKREVFqVu3bsrMzNQf//hH7/7MzExdffXVFY6PjY3V9u3bTfsWLFig9957TytWrFDr1q19Htv25rwqXbt2VX5+viIjI9WqVSvLPwcAAAAbGEbZZvUYfpo4caKGDx+ulJQUde/eXc8884xycnKUlpYmqWxK9L59+/TCCy+oVq1a6tSpk+nzTZs2VUxMTIX9v8WxzXnfvn3VvXt3DRo0SA8++KDOPfdcfffdd8rIyNCgQYOUkpIS0M8BAAAA5YYOHaoDBw5o5syZysvLU6dOnZSRkaGWLVtKKntA52+teV4djm3OXS6XMjIyNHXqVN1444364YcflJCQoF69elU61+d0PwcAAIDgMzxlm9VjVMett96qW2+9tdL3li5desrPpqenV2uZcZdh9Qz8EFVUVCS32213GQDk/408oaiyu/8BwAqFhYV+rVhilfJe64/X3Kbata1dlOPEiWKtfP0fjrn2U/H5IUQAAAAArOXYaS0AAACo+Zy4lKKdSM4BAAAAhyA5BwAAgG1Izs1IzgEAAACHIDkHAACAbUjOzUjOAQAAAIcgOQcAAIBtSM7NSM4BAAAAhyA5BwAAgG0MjyHDY3FybvH5A4nkHAAAAHAImnMAAADAIZjWAgAAAPsYRtlm9RghguQcAAAAcAiScwAAANjG+PnL6jFCBck5AAAA4BAk5wAAALANDyEyIzkHAAAAHILkHAAAALYpS849lo8RKkjOAQAAAIcgOQfgeC6Xy+4SLBdKqU51hcOfIwD/MefcjOQcAAAAcAiScwAAANiG5NyM5BwAAABwCJpzAAAAwCGY1gIAAADbMK3FjOQcAAAAcAiScwAAANjGMDxBeAiRtecPJJJzAAAAwCFIzgEAAGAfwyjbrB4jRJCcAwAAAA5Bcg4AAADbGD9/WT1GqCA5BwAAAByC5BwAAAA2sn6dc5GcAwAAAPAXyTkAAABswxNCzUjOAQAAAIegOQcAAAAcgmktAAAAsI1heGQYHsvHCBUk5wAAAIBDkJwDAADANtwQakZyDgAAADgEyTkAAABsQ3JuRnIOAAAAOATJOQAAAGxDcm5Gcg4AAAA4BMk5AAAA7GMYZZvVY4QIknMAAADAIUjOf1ZcXKzi4mLv66KiIhurAQAACA+GDBmy+AmhIjkPOXPmzJHb7fZuiYmJdpcEAACAMENz/rPJkyersLDQu+Xm5tpdEgAAAMIM01p+Fh0drejoaLvLAAAACCsspWhGcg4AAAA4BMk5AAAAbENybhY2yfmTTz6pSy+91O4yAAAAgCqFTXK+f/9+7d692+4yAAAA8Ask52Zhk5ynp6dr7969dpcBAAAAVClsknMAAAA4j2F4ZBgWP4TI4vMHUtgk5wAAAIDTkZwDAADANsw5NyM5BwAAAByC5BwAAAC2ITk3IzkHAAAAHILmHAAAAHAIprUAAADAPoZRtlk9RoggOQcAAAAcguQcAAAAtjF+/rJ6jFBBcg4AAAA4BMk5AAAAbGMYHhmGx/IxQgXJOQAAAOAQJOcAAACwDQ8hMiM5BwAAAByC5BwAAAC2ITk3IzkHAAAAHILmHAAAAHAIprUAAADANkxrMaM5r0Io/SECCH1FRUV2lwAgTNDjOBvNeRWOHDlidwkAwojb7ba7BABh4siRIw77O8f6hxBJofMQIprzKjRv3ly5ublq0KCBXC6X5eMVFRUpMTFRubm5io2NtXw8O9T0a6zp1yeFxzUCQE1lGIaOHDmi5s2b210KToHmvAq1atVSixYtgj5ubGxsjW96avo11vTrk8LjGgGgJnJWYl6GOedmrNYCAAAAOATJOQAAAOxjGGWb1WOECJJzh4iOjtaMGTMUHR1tdymWqenXWNOvTwqPawQAwE4uI5Qm4QAAAKBGKCoqktvt1vnn91VEhLWTOUpLT2rr1ndVWFjo+HumSM4BAAAAh2DOOQAAAGzDai1mJOcAAACAQ9CcAwAAAA7BtBYAAADYxjA8MgyP5WOECpJzALBQr1699PLLLwf8vHv37pXL5dK2bdsCfm5//e53v9Prr79udxkAUCPQnAMISaNGjdKgQYOCPu7SpUvVsGFDn479z3/+o/z8fP35z3/27mvVqpXmzZtX4dj09HR16dIlMEUG2bRp03T33XfL4wmdZAqAc5TfEGr1FipozgHAIo8//rhuuOEG1arljL9qDcPQyZMnA37eK664QoWFhXr77bcDfm4ACDfO+BcDAE5T7969NW7cON15551q3LixEhISlJ6ebjrG5XJp4cKFGjhwoOrUqaPWrVvr1Vdf9b6/bt06uVwuHT582Ltv27Ztcrlc2rt3r9atW6cbbrhBhYWFcrlccrlcFcYot3//fr377ru66qqrqn1NS5YsUVJSkmJiYtS+fXstWLCgwjFff/21evTooZiYGHXs2FHr1q2rcD1vv/22UlJSFB0drQ0bNsgwDM2dO1dt2rRRnTp11LlzZ61YscL7uW7duumRRx7xvh40aJAiIyNVVFQkScrPz5fL5dI333wjSYqIiNDll1+uZcuWVftaAYQvknMzmnMANcbzzz+vevXq6aOPPtLcuXM1c+ZMZWZmmo6ZNm2aBg8erM8//1zXX3+9rrvuOmVlZfl0/h49emjevHmKjY1VXl6e8vLydMcdd1R67MaNG1W3bl0lJSVV61qeffZZTZ06VbNnz1ZWVpbuv/9+TZs2Tc8//7zpuEmTJun222/X1q1b1aNHD1111VU6cOCA6Zg777xTc+bMUVZWlpKTk3XPPfdoyZIlWrhwob766itNmDBB119/vdavXy+p7Aed8ibfMAxt2LBBjRo10saNGyVJa9euVUJCgs4991zvGBdccIE2bNhQrWsFAPwfmnMANUZycrJmzJihdu3aacSIEUpJSdGaNWtMx1x77bW6+eabdc455+i+++5TSkqKnnjiCZ/OHxUVJbfbLZfLpYSEBCUkJKh+/fqVHrt3717Fx8dXOqXlrrvuUv369U3b/fffbzrmvvvu0yOPPKJrrrlGrVu31jXXXKMJEybo6aefNh03duxYDR48WElJSVq4cKHcbrcWLVpkOmbmzJm67LLLdPbZZysmJkaPPvqoFi9erP79+6tNmzYaNWqUrr/+eu+5e/furQ0bNsjj8eiLL75QRESEhg8f7m3Y161bp9TUVNMYZ555pnJycph3DsBvJOdmLKUIoMZITk42vW7WrJkKCgpM+7p3717htRUrnvz000+KiYmp9L1JkyZp1KhRpn2PP/643n//fUnSDz/8oNzcXN10003661//6j3m5MmTcrvdps/98noiIyOVkpJS4TcBKSkp3u937Nih48eP67LLLjMdU1JSovPPP19S2QozR44c0datW/XBBx8oNTVVl1xyiWbNmiWprDkfP3686fN16tSRx+NRcXGx6tSpU9V/FgDAb6A5B1Bj1K5d2/Ta5XL5lOS6XC5J8qbcv0xYTpw4Ua1a4uLidOjQoSrfa9u2rWlf48aNvd+X1/zss8/qwgsvNB0XERHxm2OXX0+5evXqVTj3//t//09nnnmm6bjo6GhJktvtVpcuXbRu3Tpt2rRJffr0Uc+ePbVt2zbt2rVLO3fuVO/evU2fPXjwoOrWrUtjDsBvwUi2Qyk5Z1oLgLDy4YcfVnjdvn17SVKTJk0kSXl5ed73f52qR0VFqbS09DfHOf/885Wfn19lg34q8fHxOvPMM7Vnzx61bdvWtLVu3brK6zl58qS2bNnivZ7KdOjQQdHR0crJyalw7sTERO9xvXv31tq1a/X++++rd+/eatiwoTp06KBZs2apadOmFebSf/nll+ratavf1woAMCM5BxBWXn31VaWkpOjiiy/WSy+9pI8//tg7R7u8QU1PT9esWbO0a9cu06olUtk65UePHtWaNWvUuXNn1a1bV3Xr1q0wzvnnn68mTZrogw8+0B/+8Ae/60xPT9e4ceMUGxurgQMHqri4WJ9++qkOHTqkiRMneo+bP3++2rVrp6SkJD322GM6dOiQbrzxxirP26BBA91xxx2aMGGCPB6PLr74YhUVFWnTpk2qX7++Ro4cKamsOf/HP/6hxo0bq0OHDt59TzzxhK655poK592wYYP69evn93UCgAxP2Wb1GCGC5BxAWLn33nv1yiuvKDk5Wc8//7xeeuklb/NZu3ZtLVu2TF9//bU6d+6sBx980DvPulyPHj2UlpamoUOHqkmTJpo7d26l40REROjGG2/USy+9VK06b775Zj333HNaunSpzjvvPKWmpmrp0qUVkvMHHnhADz74oDp37qwNGzZo1apViouLO+W577vvPk2fPl1z5sxRUlKS+vfvr3//+9+mc/fq1UuSlJqa6p0mk5qaqtLS0go3g+7bt0+bNm3SDTfcUK1rBQCnWrBggVq3bq2YmBh169btlKtSvf7667rsssvUpEkTxcbGqnv37tV6/oPLCKVJOABwGlwul1auXBm0J4t+//336tixo7Zs2aKWLVsGZUw7TJo0SYWFhXrmmWfsLgVACCkqKpLb7VbHDhcpIsLayRylpSf11Y4PVFhYqNjYWJ8+s3z5cg0fPlwLFizQRRddpKefflrPPfecduzYobPOOqvC8ePHj1fz5s11ySWXqGHDhlqyZIkefvhhffTRR94b7n1Bcw4gbAS7OZekVatWqXHjxurZs2fQxgy2hx56SCNGjFB8fLzdpQAIIeXNeYcOPYLSnO/YsUm5ubmm5jw6Otp7M/yvXXjhheratasWLlzo3ZeUlKRBgwZpzpw5Po3bsWNHDR06VNOnT/e5Vqa1AICFrr766hrdmEtlyTmNOYBQkJiYKLfb7d2qarJLSkq0ZcuWCvfS9OvXT5s2bfJpLI/HoyNHjphW4/IFN4QCCBv8ohAAnCeYSylWlpxXZv/+/SotLa0QPMTHxys/P9+nMR955BH9+OOPGjJkiF+10pwDAAAgLMTGxvo851yq+NwIwzAq7KvMsmXLlJ6erlWrVqlp06Z+1UhzDgAAANs48SFEcXFxioiIqJCSFxQU/OY0vuXLl+umm27Sq6++qr59+/pdK3POAQAAgF+IiopSt27dlJmZadqfmZmpHj16VPm5ZcuWadSoUXr55Zd1xRVXVGtsknMAAADYxjA8Mix+SFB1zj9x4kQNHz5cKSkp6t69u5555hnl5OQoLS1NkjR58mTt27dPL7zwgqSyxnzEiBH6xz/+od///vfe1L1OnTpyu90+j0tzDgAAAPzK0KFDdeDAAc2cOVN5eXnq1KmTMjIyvM+tyMvLU05Ojvf4p59+WidPntSYMWM0ZswY7/6RI0dq6dKlPo/LOucAAAAIuvJ1zs8553dBWed8585P/HoIkV2Ycw4AAAA4BNNaAAAAYBsnrtZiJ5JzAAAAwCFozgEAAACHYFoLAAAAbMO0FjOScwAAAMAhSM4BAABgH0OS1cl26ATnJOcAAACAU5CcAwAAwDaGPDLksnyMUEFyDgAAADgEyTkAAABsw2otZiTnAAAAgEOQnAMAAMBG1ifnobRcC8k5AAAA4BAk5wAAALANc87NSM4BAAAAh6A5BwAAAByCaS0AAACwjWF4ZBgWP4TI4CFEAAAAAPxEcg4AAADbcEOoGck5AAAA4BAk5wAAALANybkZyTkAAADgECTnAAAAsI9hlG1WjxEiSM4BAAAAhyA5BwAAgG2Mn7+sHiNUkJwDAAAADkFyDgAAANvwhFAzknMAAADAIWjOAQAAAIdgWgsAAABsw0OIzEjOAQAAAIcgOQcAAIBtSM7NSM4BAAAAhyA5BwAAgG1Izs1IzgEAAACHIDkHAACAbUjOzUjOAQAAAIcgOQcAAIBtypJzj+VjhAqScwAAAMAhaM4BAAAAh2BaCwAAAOxjGGWb1WOECJJzAAAAwCFIzgEAAGAb4+cvq8cIFSTnAAAAgEOQnAMAAMA2PITIjOQcAAAAcAiScwAAANjGMDxBWKzF2occBRLJOQAAAOAQJOcAAACwDXPOzUjOAQAAAIcgOQcAAIBtSM7NSM4BAAAAh6A5BwAAAByCaS0AAACwDdNazEjOAQAAAIcgOQcAAICNrE/OJZJzAAAAAH4iOQcAAIB9DE/NGCNASM4BAAAAhyA5BwAAgG0MGbJ6TrjBnHMAAAAA/iI5BwAAgG3KVmphnfNyJOcAAACAQ5CcAwAAwDYk52Yk5wAAAIBD0JwDAAAADsG0FgAAANjGCMIDgoIxRqCQnAMAAAAOQXIOAAAA25Tdq2n1DaGWnj6gSM4BAAAAhyA5BwAAgG2CscwhSykCAAAA8BvJOQAAAGxDcm5Gcg4AAAA4BMk5AAAA7BOMVJvkHAAAAIC/SM4BAABgG0MeSS6LxyA5BwAAAOAnmnMAAADAIZjWAgAAANuwlKIZyTkAAADgECTnAAAAsA3JuRnJOQAAAOAQJOcAAACwDcm5Gck5AAAA4BAk5wAAALANybkZyTkAAADgECTnAAAAsI1heCS5LB6D5BwAAACAn0jOAQAAYBvmnJuRnAMAAAAOQXMOAAAAOATTWgAAAGCfYEw5YVoLAAAAAH+RnAMAAMA2hoJwQ2gQxggUknMAAADAIUjOAQAAYBseQmRGcg4AAAA4BMk5AAAAbMNDiMxIzgEAAIBKLFiwQK1bt1ZMTIy6deumDRs2nPL49evXq1u3boqJiVGbNm301FNP+T0mzTkAAABsZRiGpVt1LF++XOPHj9fUqVO1detW9ezZUwMHDlROTk6lx2dnZ+vyyy9Xz549tXXrVk2ZMkXjxo3Ta6+95te4LiOUcn4AAADUCEVFRXK73UEds7CwULGxsT4de+GFF6pr165auHChd19SUpIGDRqkOXPmVDj+rrvu0urVq5WVleXdl5aWps8//1ybN2/2uUaScwAAAISFoqIi01ZcXFzpcSUlJdqyZYv69etn2t+vXz9t2rSp0s9s3ry5wvH9+/fXp59+qhMnTvhcI805AAAAgi4qKkoJCQlBG69+/fpKTEyU2+32bpUl4JK0f/9+lZaWKj4+3rQ/Pj5e+fn5lX4mPz+/0uNPnjyp/fv3+1wnq7UAAAAg6GJiYpSdna2SkpKgjGcYhlwu83rq0dHRp/zMr4+v7By/dXxl+0+F5hwAAAC2iImJUUxMjN1lVBAXF6eIiIgKKXlBQUGFdLxcQkJCpcdHRkbqjDPO8HlsprUAAAAAvxAVFaVu3bopMzPTtD8zM1M9evSo9DPdu3evcPw777yjlJQU1a5d2+exac4BAACAX5k4caKee+45LV68WFlZWZowYYJycnKUlpYmSZo8ebJGjBjhPT4tLU3ffvutJk6cqKysLC1evFiLFi3SHXfc4de4TGsBAAAAfmXo0KE6cOCAZs6cqby8PHXq1EkZGRlq2bKlJCkvL8+05nnr1q2VkZGhCRMmaP78+WrevLkef/xxDR482K9xWeccAAAAcAimtQAAAAAOQXMOAAAAOATNOQAAAOAQNOcAAACAQ9CcAwAAAA5Bcw4AAAA4BM05AAAA4BA05wAAAIBD0JwDAAAADkFzDgAAADgEzTkAAADgEP8fxEv91WCNdt4AAAAASUVORK5CYII="/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>(c) For five randomly selected examples, we visualized the attention weights as a heatmap over source (Hebrew) and target (English) tokens. Each row corresponds to a decoded English token and each column corresponds to an input Hebrew token; darker cells indicate higher attention weight. The plots provide an interpretable alignment showing which Hebrew tokens the decoder relied on when generating each English token, which is expected behavior for an attention-based seq2seq model.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># -----------------------------</span>
<span class="c1"># Reproducibility</span>
<span class="c1"># -----------------------------</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"device:"</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Data download</span>
<span class="c1"># -----------------------------</span>

<span class="c1"># IMPORTANT: this matches your unzip command: `-d heb_eng`</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">"heb_eng/heb.txt"</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Downloading dataset..."</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">"curl -L -o heb-eng.zip http://www.manythings.org/anki/heb-eng.zip"</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">"unzip -o -q heb-eng.zip -d heb_eng"</span><span class="p">)</span>

<span class="n">heb_path</span> <span class="o">=</span> <span class="s2">"heb_eng/heb.txt"</span>
<span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">heb_path</span><span class="p">),</span> <span class="sa">f</span><span class="s2">"File not found: </span><span class="si">{</span><span class="n">heb_path</span><span class="si">}</span><span class="s2">"</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Normalization</span>
<span class="c1"># -----------------------------</span>

<span class="k">def</span> <span class="nf">unicode_to_ascii</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="c1"># keep English side consistent with the tutorial</span>
    <span class="k">return</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="s2">"NFD"</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">category</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">"Mn"</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">normalize_en</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">unicode_to_ascii</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"([.!?])"</span><span class="p">,</span> <span class="sa">r</span><span class="s2">" </span><span class="se">\\</span><span class="s2">1"</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"[^a-zA-Z.!?]+"</span><span class="p">,</span> <span class="sa">r</span><span class="s2">" "</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"</span><span class="se">\\</span><span class="s2">s+"</span><span class="p">,</span> <span class="s2">" "</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">s</span>


<span class="k">def</span> <span class="nf">normalize_he</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>

    <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"</span><span class="se">\\</span><span class="s2">s+"</span><span class="p">,</span> <span class="s2">" "</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span>


<span class="k">def</span> <span class="nf">read_heb_eng_pairs</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">max_lines</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
    <span class="c1"># file format: en \t he</span>
    <span class="n">pairs_local</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">"utf-8-sig"</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">"replace"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">max_lines</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">max_lines</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\t</span><span class="s2">"</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">en_raw</span><span class="p">,</span> <span class="n">he_raw</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">en</span> <span class="o">=</span> <span class="n">normalize_en</span><span class="p">(</span><span class="n">en_raw</span><span class="p">)</span>
            <span class="n">he</span> <span class="o">=</span> <span class="n">normalize_he</span><span class="p">(</span><span class="n">he_raw</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">en</span> <span class="ow">and</span> <span class="n">he</span><span class="p">:</span>
                <span class="n">pairs_local</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">he</span><span class="p">,</span> <span class="n">en</span><span class="p">))</span>  <span class="c1"># Hebrew -&gt; English</span>
    <span class="k">return</span> <span class="n">pairs_local</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Filter (eng_prefixes requirement)</span>
<span class="c1"># -----------------------------</span>
<span class="n">eng_prefixes</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">"i am "</span><span class="p">,</span> <span class="s2">"i m "</span><span class="p">,</span>
    <span class="s2">"he is "</span><span class="p">,</span> <span class="s2">"he s "</span><span class="p">,</span>
    <span class="s2">"she is "</span><span class="p">,</span> <span class="s2">"she s "</span><span class="p">,</span>
    <span class="s2">"you are "</span><span class="p">,</span> <span class="s2">"you re "</span><span class="p">,</span>
    <span class="s2">"we are "</span><span class="p">,</span> <span class="s2">"we re "</span><span class="p">,</span>
    <span class="s2">"they are "</span><span class="p">,</span> <span class="s2">"they re "</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">filter_pair</span><span class="p">(</span><span class="n">he</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">en</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">he</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span>
        <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">en</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">MAX_LENGTH</span>
        <span class="ow">and</span> <span class="n">en</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">eng_prefixes</span><span class="p">)</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">filter_pairs</span><span class="p">(</span><span class="n">pairs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
    <span class="k">return</span> <span class="p">[(</span><span class="n">he</span><span class="p">,</span> <span class="n">en</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">he</span><span class="p">,</span> <span class="n">en</span><span class="p">)</span> <span class="ow">in</span> <span class="n">pairs</span> <span class="k">if</span> <span class="n">filter_pair</span><span class="p">(</span><span class="n">he</span><span class="p">,</span> <span class="n">en</span><span class="p">)]</span>


<span class="n">pairs_he_en</span> <span class="o">=</span> <span class="n">read_heb_eng_pairs</span><span class="p">(</span><span class="n">heb_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Total raw pairs:"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Raw example (he, en):"</span><span class="p">,</span> <span class="n">pairs_he_en</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">pairs_he_en</span> <span class="o">=</span> <span class="n">filter_pairs</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Filtered pairs:"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Filtered example (he, en):"</span><span class="p">,</span> <span class="n">pairs_he_en</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="s2">"No pairs matched eng_prefixes after filtering. "</span>
        <span class="s2">"Try increasing MAX_LENGTH or removing eng_prefixes filter to verify data loading."</span>
    <span class="p">)</span>

<span class="c1"># random.shuffle(pairs_he_en)</span>
<span class="c1"># pairs_he_en = pairs_he_en[:50000]</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Vocabulary</span>
<span class="c1"># -----------------------------</span>
<span class="n">SOS_token</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">EOS_token</span> <span class="o">=</span> <span class="mi">1</span>


<span class="k">class</span> <span class="nc">Lang</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">SOS_token</span><span class="p">:</span> <span class="s2">"SOS"</span><span class="p">,</span> <span class="n">EOS_token</span><span class="p">:</span> <span class="s2">"EOS"</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="k">def</span> <span class="nf">add_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">" "</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_word</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_words</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>


<span class="k">def</span> <span class="nf">indexes_from_sentence</span><span class="p">(</span><span class="n">lang</span><span class="p">:</span> <span class="n">Lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">lang</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">" "</span><span class="p">)]</span>


<span class="k">def</span> <span class="nf">tensor_from_sentence</span><span class="p">(</span><span class="n">lang</span><span class="p">:</span> <span class="n">Lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">idxs</span> <span class="o">=</span> <span class="n">indexes_from_sentence</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span>
    <span class="n">idxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EOS_token</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">idxs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">tensors_from_pair</span><span class="p">(</span><span class="n">pair</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">input_lang</span><span class="p">:</span> <span class="n">Lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">:</span> <span class="n">Lang</span><span class="p">):</span>
    <span class="n">he</span><span class="p">,</span> <span class="n">en</span> <span class="o">=</span> <span class="n">pair</span>
    <span class="k">return</span> <span class="n">tensor_from_sentence</span><span class="p">(</span><span class="n">input_lang</span><span class="p">,</span> <span class="n">he</span><span class="p">),</span> <span class="n">tensor_from_sentence</span><span class="p">(</span><span class="n">output_lang</span><span class="p">,</span> <span class="n">en</span><span class="p">)</span>


<span class="n">input_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="s2">"heb"</span><span class="p">)</span>
<span class="n">output_lang</span> <span class="o">=</span> <span class="n">Lang</span><span class="p">(</span><span class="s2">"eng"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">he</span><span class="p">,</span> <span class="n">en</span> <span class="ow">in</span> <span class="n">pairs_he_en</span><span class="p">:</span>
    <span class="n">input_lang</span><span class="o">.</span><span class="n">add_sentence</span><span class="p">(</span><span class="n">he</span><span class="p">)</span>
    <span class="n">output_lang</span><span class="o">.</span><span class="n">add_sentence</span><span class="p">(</span><span class="n">en</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Vocab sizes:"</span><span class="p">,</span> <span class="n">input_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">,</span> <span class="n">output_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">)</span>

<span class="c1"># -----------------------------</span>
<span class="c1"># Models (GRU encoder + Attention decoder)</span>
<span class="c1"># -----------------------------</span>


<span class="k">class</span> <span class="nc">EncoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size_</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_token</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">input_token</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">hidden</span>

    <span class="k">def</span> <span class="nf">init_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">AttnDecoderRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size_</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_combine</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size_</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size_</span><span class="p">,</span> <span class="n">hidden_size_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size_</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_token</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">input_token</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>

        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embedded</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hidden</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>  <span class="c1"># (1, MAX_LENGTH)</span>

        <span class="n">attn_applied</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span>
            <span class="n">attn_weights</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
            <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
        <span class="p">)</span>  <span class="c1"># (1, 1, H)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embedded</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">attn_applied</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="mi">1</span><span class="p">)</span>      <span class="c1"># (1, 2H)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_combine</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>            <span class="c1"># (1, 1, H)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>     <span class="c1"># (1, V)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">attn_weights</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Training helpers</span>
<span class="c1"># -----------------------------</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>          <span class="c1"># more stable than 0.01 for this setup</span>
<span class="n">teacher_forcing_ratio</span> <span class="o">=</span> <span class="mf">0.7</span>    <span class="c1"># higher helps early convergence</span>
<span class="n">clip</span> <span class="o">=</span> <span class="mf">1.0</span>                     <span class="c1"># gradient clipping</span>


<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">enc_opt</span><span class="p">,</span> <span class="n">dec_opt</span><span class="p">,</span> <span class="n">criterion</span><span class="p">):</span>
    <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">()</span>
    <span class="n">enc_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dec_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">input_length</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">target_length</span> <span class="o">=</span> <span class="n">target_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Encode</span>
    <span class="k">for</span> <span class="n">ei</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">input_length</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">)):</span>
        <span class="n">enc_out</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">[</span><span class="n">ei</span><span class="p">],</span> <span class="n">encoder_hidden</span><span class="p">)</span>
        <span class="n">encoder_outputs</span><span class="p">[</span><span class="n">ei</span><span class="p">]</span> <span class="o">=</span> <span class="n">enc_out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Decode</span>
    <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">SOS_token</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">use_teacher</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">teacher_forcing_ratio</span>

    <span class="k">if</span> <span class="n">use_teacher</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_length</span><span class="p">):</span>
            <span class="n">dec_out</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">dec_out</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">[</span><span class="n">di</span><span class="p">])</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">target_tensor</span><span class="p">[</span><span class="n">di</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_length</span><span class="p">):</span>
            <span class="n">dec_out</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
            <span class="n">topv</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">dec_out</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">topi</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">dec_out</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">[</span><span class="n">di</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">decoder_input</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">EOS_token</span><span class="p">:</span>
                <span class="k">break</span>

    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Clip gradients (stability)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>

    <span class="n">enc_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">dec_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">target_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">as_minutes</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">s</span> <span class="o">/</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">-=</span> <span class="n">m</span> <span class="o">*</span> <span class="mi">60</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s2">m </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="si">}</span><span class="s2">s"</span>


<span class="k">def</span> <span class="nf">time_since</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
    <span class="n">now</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">now</span> <span class="o">-</span> <span class="n">start</span>
    <span class="n">es</span> <span class="o">=</span> <span class="n">s</span> <span class="o">/</span> <span class="n">progress</span> <span class="k">if</span> <span class="n">progress</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">rs</span> <span class="o">=</span> <span class="n">es</span> <span class="o">-</span> <span class="n">s</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">as_minutes</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="si">}</span><span class="s2"> (- </span><span class="si">{</span><span class="n">as_minutes</span><span class="p">(</span><span class="n">rs</span><span class="p">)</span><span class="si">}</span><span class="s2">)"</span>


<span class="c1"># -----------------------------</span>
<span class="c1"># Train</span>
<span class="c1"># -----------------------------</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">EncoderRNN</span><span class="p">(</span><span class="n">input_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">AttnDecoderRNN</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_lang</span><span class="o">.</span><span class="n">n_words</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Adam generally converges much faster/more stably than SGD here</span>
<span class="n">enc_opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">dec_opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs_he_en</span><span class="p">:</span>
        <span class="n">inp</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">=</span> <span class="n">tensors_from_pair</span><span class="p">(</span><span class="n">pair</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">enc_opt</span><span class="p">,</span> <span class="n">dec_opt</span><span class="p">,</span> <span class="n">criterion</span><span class="p">)</span>

    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">ep</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> | loss=</span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">time_since</span><span class="p">(</span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">ep</span><span class="o">/</span><span class="n">epochs</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Done."</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>device: cpu
Total raw pairs: 136845
Raw example (he, en): ('!', 'go')
Filtered pairs: 9615
Filtered example (he, en): (' .', 'i m ok')
Vocab sizes: 7769 3184
Epoch 01/50 | loss=2.9631 | 2m 51s (- 140m 25s)
Epoch 02/50 | loss=2.3815 | 5m 47s (- 138m 52s)
Epoch 03/50 | loss=2.0432 | 8m 38s (- 135m 23s)
Epoch 04/50 | loss=1.7775 | 11m 28s (- 132m 0s)
Epoch 05/50 | loss=1.5751 | 14m 18s (- 128m 48s)
Epoch 06/50 | loss=1.4014 | 17m 8s (- 125m 43s)
Epoch 07/50 | loss=1.2593 | 19m 56s (- 122m 31s)
Epoch 08/50 | loss=1.1527 | 22m 42s (- 119m 13s)
Epoch 09/50 | loss=1.0550 | 25m 25s (- 115m 51s)
Epoch 10/50 | loss=0.9793 | 28m 11s (- 112m 44s)
Epoch 11/50 | loss=0.9223 | 30m 59s (- 109m 52s)
Epoch 12/50 | loss=0.8579 | 33m 51s (- 107m 11s)
Epoch 13/50 | loss=0.8245 | 36m 36s (- 104m 12s)
Epoch 14/50 | loss=0.7907 | 39m 21s (- 101m 11s)
Epoch 15/50 | loss=0.7582 | 42m 6s (- 98m 16s)
Epoch 16/50 | loss=0.7317 | 44m 58s (- 95m 33s)
Epoch 17/50 | loss=0.7043 | 47m 46s (- 92m 44s)
Epoch 18/50 | loss=0.6899 | 50m 37s (- 90m 0s)
Epoch 19/50 | loss=0.6712 | 53m 29s (- 87m 17s)
Epoch 20/50 | loss=0.6772 | 56m 15s (- 84m 23s)
Epoch 21/50 | loss=0.6574 | 59m 1s (- 81m 31s)
Epoch 22/50 | loss=0.6439 | 61m 46s (- 78m 37s)
Epoch 23/50 | loss=0.6446 | 64m 30s (- 75m 44s)
Epoch 24/50 | loss=0.6295 | 67m 6s (- 72m 41s)
Epoch 25/50 | loss=0.6199 | 69m 38s (- 69m 38s)
Epoch 26/50 | loss=0.6166 | 72m 20s (- 66m 46s)
Epoch 27/50 | loss=0.6249 | 74m 54s (- 63m 48s)
Epoch 28/50 | loss=0.6176 | 77m 27s (- 60m 51s)
Epoch 29/50 | loss=0.6197 | 79m 59s (- 57m 55s)
Epoch 30/50 | loss=0.6111 | 88m 4s (- 58m 43s)
Epoch 31/50 | loss=0.6109 | 105m 45s (- 64m 49s)
Epoch 32/50 | loss=0.5887 | 123m 24s (- 69m 25s)
Epoch 33/50 | loss=0.6062 | 141m 3s (- 72m 40s)
Epoch 34/50 | loss=0.5943 | 158m 44s (- 74m 41s)
Epoch 35/50 | loss=0.5834 | 171m 23s (- 73m 27s)
Epoch 36/50 | loss=0.5909 | 178m 54s (- 69m 34s)
Epoch 37/50 | loss=0.5818 | 196m 35s (- 69m 4s)
Epoch 38/50 | loss=0.5853 | 204m 7s (- 64m 27s)
Epoch 39/50 | loss=0.5841 | 221m 46s (- 62m 33s)
Epoch 40/50 | loss=0.5870 | 224m 14s (- 56m 3s)
Epoch 41/50 | loss=0.5861 | 226m 43s (- 49m 46s)
Epoch 42/50 | loss=0.5843 | 229m 10s (- 43m 39s)
Epoch 43/50 | loss=0.5686 | 231m 37s (- 37m 42s)
Epoch 44/50 | loss=0.5874 | 234m 5s (- 31m 55s)
Epoch 45/50 | loss=0.5732 | 236m 35s (- 26m 17s)
Epoch 46/50 | loss=0.5879 | 239m 6s (- 20m 47s)
Epoch 47/50 | loss=0.5736 | 241m 38s (- 15m 25s)
Epoch 48/50 | loss=0.5822 | 244m 12s (- 10m 10s)
Epoch 49/50 | loss=0.5731 | 246m 46s (- 5m 2s)
Epoch 50/50 | loss=0.5783 | 249m 20s (- 0m 0s)
Done.
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[37]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">evaluate_random_20</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
=== Random evaluation (20 sentences) ===

[01] HE:      .
     TRUE: i m definitely not on your side
     PRED: i m definitely not on
     OK:   False

[02] HE:      .
     TRUE: you re as handsome as ever
     PRED: you re as handsome as ever
     OK:   True

[03] HE:      .
     TRUE: we re pretty much finished
     PRED: we re much finished
     OK:   False

[04] HE:    .
     TRUE: i m strict
     PRED: i m strict
     OK:   True

[05] HE:      .
     TRUE: i m not comfortable
     PRED: i m not comfortable
     OK:   True

[06] HE:    .
     TRUE: i m selfish
     PRED: i m selfish
     OK:   True

[07] HE:     .
     TRUE: we re unenthusiastic
     PRED: we re unenthusiastic
     OK:   True

[08] HE:       .
     TRUE: i m really concerned about your future
     PRED: i m really concerned about your future
     OK:   True

[09] HE:    .
     TRUE: you re up early
     PRED: you re up early
     OK:   True

[10] HE:      .
     TRUE: i m just a little confused
     PRED: i m just a little confused
     OK:   True

[11] HE:    .
     TRUE: i m working
     PRED: i m working
     OK:   True

[12] HE:    .
     TRUE: you re babbling
     PRED: you re decisive
     OK:   False

[13] HE:    .
     TRUE: he s a comedian
     PRED: he s a comedian
     OK:   True

[14] HE:     .
     TRUE: you re being irrational
     PRED: you re being irrational
     OK:   True

[15] HE:      .
     TRUE: he is absorbed in reading detective novels
     PRED: he is absorbed about her way
     OK:   False

[16] HE:       .
     TRUE: i m not interested in modern art
     PRED: i m not interested in a bad mood
     OK:   False

[17] HE:       .
     TRUE: you re the one i ve been waiting for
     PRED: you re the one who do that
     OK:   False

[18] HE:        .
     TRUE: i m really glad to hear it
     PRED: i m really glad to hear it
     OK:   True

[19] HE:    .
     TRUE: we re paramedics
     PRED: we re paramedics
     OK:   True

[20] HE:      .
     TRUE: we re not going to boston
     PRED: we re not going to boston
     OK:   True

Exact-match on these 20 samples: 14/20 = 0.700
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[37]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>0.7</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[38]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">attention_random_5</span><span class="p">(</span><span class="n">pairs_he_en</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
[1]
HE:      .
TRUE:  i m completely over it
PRED:  i m completely over it
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
[2]
HE:       .
TRUE:  he s in bed with the flu
PRED:  he s in bed with the flu
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
[3]
HE:     .
TRUE:  you re adorable
PRED:  you re adorable
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
[4]
HE:     .
TRUE:  we re famous
PRED:  we re famous
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>
[5]
HE:        .
TRUE:  i m definitely feeling better
PRED:  i m definitely feeling better
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Model Improvement Summary (Compared to 2.a)</p>
<p>Quantitative evaluation.
In the baseline model (Section 2.a), the exact-match accuracy on 20 randomly selected sentences was low (only 2 correct translations out of 20, corresponding to 10% accuracy). After improving the training strategy, the model achieves 14 correct translations out of 20, corresponding to an exact-match accuracy of 70%. This represents a large absolute improvement of more than +60 percentage points, demonstrating a substantial gain in translation quality.</p>
<p>Training behavior.
The improved model also shows significantly better optimization dynamics. The training loss decreases smoothly from approximately 2.96 at the beginning of training to about 0.58 at the final epoch and remains stable in later epochs. In contrast, the baseline model converged more slowly and to a higher final loss, indicating less effective optimization.</p>
<p>Attention visualization.
The attention heatmaps further support this improvement. In the baseline model, attention was often diffuse and poorly aligned, while in the improved model the attention maps exhibit clearer and more concentrated alignments between Hebrew input tokens and English output tokens (visible as stronger diagonal patterns). This indicates that the model learns more reliable inputoutput correspondences and produces more coherent translations.</p>
<p>Source of improvement.
Importantly, the architecture remains unchanged (the same GRU-based encoderdecoder with additive attention). The performance gains stem primarily from changes in the training procedure, including the use of the Adam optimizer, gradient clipping, and a higher teacher forcing ratio, which together improve stability and convergence.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
